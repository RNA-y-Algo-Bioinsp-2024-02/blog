---
title: "Construcción de un Generador de Contenido Educativo basado en LLM"
format: 
  html:
    toc: true
    toc-width: 250px
    main-container-width: 90%
    fig-width: 8
    fig-height: 6
    number-sections: true
    math: 
      method: mathjax
      options:
        TeX:
          equationNumbers: { autoNumber: "AMS" }
  
author:
  - name: "Julián Castaño Pineda"
  - name: "Luis Andrés Altamar Romero"
  - name: "Catalina Restrepo Salgado"
  - name: "Tomás Rodríguez Taborda"
date: "2025-03-06"
categories: [Large Language Model, Inteligencia Artificial]
image: "image.webp"
bibliography: ref.bib
execute:
  cache: true
---

Generación de contenido educativo basado en LLM para cursos universitarios.

## Introducción

Los Modelos de Lenguaje de Gran Escala (LLM, por sus siglas en inglés) han supuesto una revolución tanto para la industria como para la sociedad, en gran parte debido a su creciente accesibilidad. Un claro ejemplo de este fenómeno es el impacto de OpenAI con **ChatGPT**, que popularizó el uso de estos modelos a pesar de que su motor subyacente, **GPT**, ya existía desde hace tiempo. Sin embargo, en sus inicios, el entrenamiento de estos modelos era una tarea extremadamente costosa y limitada por los recursos computacionales disponibles.

El avance en **hardware especializado**, en particular el desarrollo de **tarjetas gráficas (GPU) y unidades de procesamiento tensorial (TPU) de nueva generación**, ha permitido acelerar significativamente el entrenamiento de los modelos. Esto ha facilitado la creación de versiones cada vez más avanzadas y accesibles, lo que ha impulsado la adopción masiva de los LLM en diversas aplicaciones, desde asistentes virtuales hasta generación de contenido y automatización de tareas complejas.

A medida que la tecnología sigue evolucionando, la combinación de mayor poder computacional y mejores algoritmos de entrenamiento promete expandir aún más las capacidades de estos modelos, consolidando su papel en la transformación digital de múltiples sectores.

![Imagen ilustrativa. Tomado de https://www.linkedin.com/pulse/so-much-talk-large-language-models-aibut-what-else-does-martin-hughes/](images/1695386064286.jpeg)

Lo anterior es una situación que puede llegar a generar preocupación debido a la capacidad de estos modelos, preocupación que se ve reflejada tanto en el mundo laboral, de ser reemplazado por un modelo de IA, y en el sistema educativo, no es fácil trazar una línea de hasta donde debe ser usada la inteligencia artificial en los trabajos y hasta donde es trabajo original, y a la vez tratar de cumplir con los mínimos establecidos en la educación. En este trabajo nos centraremos en la segunda situación, mostrando como los LLM son un apoyo para el sistema educativo y no una traba que debe superarse sino integrarse al mismo.

### Objetivos generales

Desarrollar un agente que integrando un LLM permita generar contenido basado en el programa resumen de un curso. Se busca que permita obtener notas detalladas para cada tema, ejercicios con soluciones, preguntas, objetivos de aprendizaje y lecturas sugeridas.

### Objetivos específicos

-   Generar material de aprendizaje basado en el programa del curso.

-   Evaluar la calidad de material del modelo.

## Arquitectura de los transformers

La aparición de los LLM (Large Language Models) se atribuye en gran medida al desarrollo de la arquitectura de Transformers, la cual introduce el mecanismo de *atención* (*self-attention*). Este mecanismo permite que los modelos procesen de manera integral el *prompt*, enriqueciendo su comprensión contextual y, por ende, mejorando la calidad de las respuestas que generan. A continuación, se ilustra la estructura básica de un Transformer:

![Arquitectura de un transformer con un encoder y un decoder. Tomado de <https://huggingface.co/learn/agents-course/unit1/what-are-llms>](images/transformer.jpg)

Esta arquitectura que se presente muestra como la red puede "prestar atención" a diferentes partes de la secuencia de entrada identificando las partes más relevantes. Estos resultados no se alcanzaban con arquitecturas más tradicionales como las LSTMs o las RNNs. Lo anterior también permite introducir el concepto de los encoders y los decoders

-   Encoder: Consiste en varias capas de atención que toman la secuencia de entrada y la transforman en una representación interna. Es útil para tareas de clasificación o búsqueda de información en textos. Un ejemplo de arquitectura de este tipo es el modelo BERT.

-   Decoder: Se centra en la generación de texto de forma autoregresiva, tomando como referencia lo que se ha generado hasta el momento para predecir el siguiente token. Gracias a su mecanismo de atención, puede “recordar” el contexto anterior y mantener coherencia en el flujo de la información. Un ejemplo de arquitectura de este tipo son los modelos GPT.

-   Encoder-Decoder: Combina un encoder que procesa la secuencia de entrada y un decoder que genera la salida, permitiendo una transformación de la información de forma completa. Es especialmente útil en tareas de traducción, resumen o cualquier proceso donde la entrada y la salida puedan diferir sustancialmente (p. ej., un texto original y su traducción). Un ejemplo de esta arquitectura es el modelo T5.

## **Agentes**

Utilizando la definición de Hugging Face, un agente es:

"Un sistema que utiliza un modelo de inteligencia artificial para interactuar con su entorno con el fin de cumplir un objetivo definido por el usuario. Combina razonamiento, planificación y la ejecución de acciones (a menudo mediante herramientas externas) para llevar a cabo sus tareas." Hugging Face. (s.f.)

![Analogía del funcionamiento de un agente. Tomado de https://huggingface.co/learn/agents-course/unit1/what-are-agents](images/agente.jpg)

Los agentes consisten en dos elementos principalmente:

-   Modelo de inteligencia artificial: Hace las veces de cerebro del agente, permite decidir que decisión tomar.

-   El cuerpo: Permite agregar funcionalidades al agente para mejorar su capacidad de responder y tomar acciones, como por ejemplo la capacidad de ChatGPT de generar imágenes.

## Desarrollo del Agente

### API Gemini

Se utilizará la API de Gemini como modelo LLM del agente, lo anterior debido a que se hicieron prueba con otros modelos pero requerían capacidades computacionales más altas de las que se tenían acceso, por lo que la API de Gemini termino siendo la mejor alternativa para generar el contendio.

### Funciones del agente

-   **Procesamiento del formato de archivo:** Se crearon funciones que mejoran la capacidad del agente para entender el documento segmentando la información relevante que irá en el prompt.

-   **Documento PDF:** Se crea la función que permite obtener el material como contenido PDF.

-   **Flashcards:** Se crearon flashcards que permiten sintetizar las preguntas y hacer más natural la forma de estudio a partir del material generado.

### Prompt utilizado

El prompt, es decir, el mensaje con el que se dan las instrucciones al agente, es de suma relevancia para permitir mejorar sus capacidades de entendimiento, lo cual hizo que surgieran además las técnicas de prompt engineering.

![Prompt agresivo con el usuario. Tomado de https://huggingface.co/learn/agents-course/unit1/what-are-llms](images/bad_agent.jpg)

![Prompt que hace enfásis en el respeto hacia el usuario. Tomado de https://huggingface.co/learn/agents-course/unit1/what-are-llms](images/good_agent.jpg)

Eres un asistente educativo experto en la creación de materiales didácticos de alta calidad para cursos universitarios. Tu tarea es generar contenido claro, preciso y bien estructurado, con rigor académico y ejemplos pertinentes, adaptado al nivel de profundidad que se solicita. Responde siempre de forma organizada y autoexplicativa, para que sea fácil de entender y aplicar.

Información del curso: - Título: {course_title} - Código: {course_code} - Descripción: {course_description}

Genera notas de clase completas y detalladas que cubran el tema a profundidad. Emplea rigor académico, definiciones precisas y ejemplos concretos para cada concepto. Asegúrate de explicar la relevancia práctica y posibles aplicaciones. Organiza la información de manera clara y estructurada, de modo que sea fácilmente entendible.

Genera notas de clase detalladas para el tema: {topic_title}. Incluye los siguientes subtemas: {subtopics}. Las notas deben incluir definiciones, explicaciones claras, ejemplos y casos de aplicación.

## Material Generado

Utilizando el contenido generado por el agente se crean dos tipos de archivos

-   **PDF:** Se genera un documento en formato PDF con todo el material obtenido por el agente de manera organizada, separando la teoría, los ejercicios, los consejos, el material extra como referencias y similares, etc. Se puede ver que el resultado es un documento extenso por lo que se introduce el segundo material entregable.

-   **Flashcards:** Utilizando el material de las preguntas creamos como material extra flash cards que permiten ver de manera más clara las preguntas formuladas y su respectiva respuesta.

## Métricas del modelo

### Evaluación por tema

Cada tema tiene puntajes individuales para su sección. Se evalúan cuatro aspectos clave:

-   **Relevancia:** Medida a través de la cobertura de subtemas en el contenido generado.\
    $$
    \text{Cobertura Subtemas} = \frac{\sum_{i=1}^{N} \mathbb{1}(\text{Subtema}_i \in \text{Contenido})}{N}
    $$

    donde $N$ es el número total de subtemas y la función indicadora $\mathbb{1}$ devuelve 1 si el subtema está presente y 0 si no.

-   **Consistencia:** Evaluada mediante la **similitud de coseno** entre las diferentes secciones del tema.\
    $$
    \text{Consistencia} = \frac{\sum_{i=1}^{N} \sum_{j=i+1}^{N} \text{SimilitudCoseno}(\text{Texto}_i, \text{Texto}_j)}{\frac{N (N-1)}{2}}
    $$

    donde $N$ es el número total de textos generados y se calcula la similitud de coseno entre cada par de textos.

-   **Legibilidad:** Basada en la **longitud promedio de las oraciones**, donde textos más cortos y claros obtienen una mejor puntuación.\
    $$
    \text{Legibilidad} = \max \left(0, \min \left(1, \frac{30 - \frac{\text{Total Palabras}}{\text{Total Oraciones}}}{15} \right) \right)
    $$

    Si las oraciones tienen menos de 15 palabras, la legibilidad es 1.0; si tienen más de 30, es 0.0.

-   **Uso de terminología:** Se mide utilizando **TF-IDF**, que identifica la presencia de términos clave del syllabus en el contenido.\
    $$
    \text{Terminología} = \min \left(1, \frac{\sum_{i=1}^{M} \mathbb{1}(\text{Término}_i \in \text{Contenido})}{\text{Total de Palabras} / 1000} \right)
    $$

    donde $M$ es el número total de términos clave y la función $\mathbb{1}$ devuelve 1 si el término está presente.

------------------------------------------------------------------------

### Evaluación por tipo de contenido

Se calculan puntuaciones agregadas para cada tipo de material generado (*lecture notes*, *practice problems*, *discussion questions*, *learning objectives*, *suggested resources*).

-   Se obtiene el **promedio de las evaluaciones individuales** en todos los temas para cada tipo de contenido: $$
    \text{Puntuación por tipo de contenido} = \frac{\sum_{t=1}^{T} \text{Puntuación de contenido}_{t}}{T}
    $$

    donde $T$ es el número total de temas.

-   Permite detectar cuáles secciones necesitan más mejoras en términos de profundidad, claridad y alineación con el syllabus.

------------------------------------------------------------------------

### Métricas globales

Se evalúan características generales del contenido en su conjunto:

-   **Consistencia temática:** Se usa **similitud de coseno y TF-IDF** para medir la coherencia semántica entre temas.

-   **Relevancia general:** Se calcula la **cobertura de subtemas** a nivel global: $$
    \text{Relevancia} = \frac{\sum_{t=1}^{T} \text{Cobertura Subtemas}_{t}}{T}
    $$

-   **Legibilidad promedio:** Se obtiene la **media de las longitudes de oraciones en todo el contenido**.

-   **Uso de terminología académica:** Se analiza la densidad de términos especializados extraídos del syllabus: $$
    \text{Terminología Global} = \frac{\sum_{t=1}^{T} \text{Terminología}_{t}}{T}
    $$

------------------------------------------------------------------------

### Puntuación global

Se obtiene como el **promedio de dos componentes principales**:

$$
\text{Puntuación Final} = \frac{\text{Promedio Tipo de Contenido} + \text{Promedio Métricas Globales}}{2}
$$

donde:

$$
\text{Promedio de Evaluación por Tipo de Contenido} = \frac{\sum_{\text{tipo}} \text{Puntuación por tipo de contenido}}{\text{Total de Tipos}}
$$

$$
\text{Promedio de Métricas Globales} = \frac{\sum_{\text{métrica}} \text{Métrica Global}}{\text{Total de Métricas}}
$$

La puntuación final proporciona una medida cuantitativa de la calidad del contenido generado.

### Métricas obtenidas por el modelo

#### **Puntuaciones por Tema**

| **Tema** | **Notas de Clase** | **Problemas de Práctica** | **Preguntas de Discusión** | **Objetivos de Aprendizaje** | **Recursos Sugeridos** | **Promedio** |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| **1** | 0.664 | 0.650 | 0.417 | 0.357 | 0.600 | 0.537 |
| **2** | 0.671 | 0.650 | 0.190 | 0.405 | 0.600 | 0.503 |
| **3** | 0.720 | 0.650 | 0.433 | 0.405 | 0.600 | 0.562 |
| **4** | 0.682 | 0.650 | 0.306 | 0.405 | 0.600 | 0.528 |

#### **Puntuaciones por Tipo de Contenido**

| **Tipo de Contenido**        | **Puntaje** |
|------------------------------|-------------|
| **Notas de Clase**           | 0.684       |
| **Problemas de Práctica**    | 0.650       |
| **Preguntas de Discusión**   | 0.337       |
| **Objetivos de Aprendizaje** | 0.393       |
| **Recursos Sugeridos**       | 0.600       |

#### **Métricas Globales**

| **Métrica**               | **Puntaje** |
|---------------------------|-------------|
| **Consistencia Temática** | 0.696       |
| **Legibilidad**           | 0.226       |
| **Uso de Terminología**   | 0.228       |

La puntuación final obtenida por el modelo es de

$$
\textbf{Puntuación Final} = 0.458
$$

## Contribuciones individuales

Las contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo de los ejercicios correspondientes al presente trabajo se muestran en el siguiente video.