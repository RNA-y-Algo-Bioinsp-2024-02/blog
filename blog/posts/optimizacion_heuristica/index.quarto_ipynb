{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Optimización Heurística\"\n",
        "format: \n",
        "  html:\n",
        "    fig-width: 8      # Ancho de las figuras en pulgadas para HTML\n",
        "    fig-height: 6     # Alto de las figuras en pulgadas para HTML\n",
        "    number-sections: true\n",
        "author:\n",
        "  - name: \"Julián Castaño Pineda\"\n",
        "  - name: \"Luis Andrés Altamar Romero\"\n",
        "  - name: \"Catalina Restrepo Salgado\"\n",
        "  - name: \"Tomás Rodríguez Taborda\"\n",
        "date: \"2024-11-29\"\n",
        "categories: [optimización, métodos heurísticos, python]\n",
        "image: \"image.jpg\"\n",
        "bibliography: ref.bib\n",
        "execute:\n",
        "  cache: true\n",
        "---"
      ],
      "id": "0196c1e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as IPImage\n",
        "import io\n",
        "from PIL import Image"
      ],
      "id": "24fbd187",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.\n",
        "\n",
        "Al final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas.\n",
        "\n",
        "# Funciones a optimizar\n",
        "\n",
        "Se seleccionaron seis funciones comúnmente empleadas para evaluar métodos de optimización, debido a sus características particulares. Estas funciones presentan desafíos como la existencia de un mínimo global acompañado de múltiples mínimos locales, así como valles que pueden dificultar la convergencia de los algoritmos. A continuación, se describen dichas funciones, incluyendo su forma funcional generalizada para $d$ dimensiones, su representación gráfica en 2 dimensiones, el valor del mínimo global, una breve descripción de cada función y el rango de evaluación sugerido por diversos autores. Las gráficas fueron generadas a partir de la funcion `plot_function()` que se muestra en la pestaña de `Code` sugerida.\n"
      ],
      "id": "7733b958"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None, elev=30, azim=45 ):\n",
        "    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n",
        "    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n",
        "    X1, X2 = np.meshgrid(x1, x2)\n",
        "    Z = f(np.array([X1,X2]))\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # 3D plot\n",
        "    ax1 = fig.add_subplot(121, projection='3d')\n",
        "    ax1.plot_surface(X1, X2, Z)\n",
        "    ax1.set_title(f'3D Plot of {title}')\n",
        "    ax1.set_xlabel('X1')\n",
        "    ax1.set_ylabel('X2')\n",
        "    ax1.set_zlabel('Z')\n",
        "\n",
        "    ax1.view_init(elev=elev, azim=azim)\n",
        "\n",
        "    if x1_point is not None and x2_point is not None:\n",
        "        z_point = f(np.array([x1_point, x2_point])[:, None, None])[0, 0]\n",
        "\n",
        "        ax1.plot([x1_point], [x2_point], [z_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n",
        "        ax1.legend()\n",
        "\n",
        "    # Contour plot\n",
        "    ax2 = fig.add_subplot(122)\n",
        "    contour = ax2.contour(X1, X2, Z, levels = 10)\n",
        "    ax2.set_title(f'Contour Plot of {title}')\n",
        "    ax2.set_xlabel('X1')\n",
        "    ax2.set_ylabel('X2')\n",
        "    fig.colorbar(contour, ax=ax2)\n",
        "\n",
        "    if x1_point is not None and x2_point is not None:\n",
        "        ax2.plot([x1_point], [x2_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n",
        "        ax2.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "id": "035e291c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: panel-tabset\n",
        "## Función de Rosenbrock\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n",
        "$$\n",
        "\n",
        "**Figura 1.**\n",
        "\n",
        "*Representación gráfica de la función de Rosenbrock.*\n"
      ],
      "id": "f63159ab"
    },
    {
      "cell_type": "code",
      "metadata": {
        "width": "100%",
        "height": "auto"
      },
      "source": [
        "# Función de Rosenbrock\n",
        "def rosenbrock(x, a=1, b=100):\n",
        "    \"\"\"\n",
        "    Calcula el valor de la función de Rosenbrock.\n",
        "    x: vector de entrada (numpy array)\n",
        "    a, b: parámetros de la función\n",
        "    \"\"\"\n",
        "    return (sum(b * (x[1:] - x[:-1]**2)**2 + (x[:-1] - a)**2))\n",
        "\n",
        "plot_function(rosenbrock, x1_range=(-2.048, 2.048), x2_range=(-2.048, 2.048), title=\"Función Rosenbrock\", x1_point=1, x2_point=1)"
      ],
      "id": "b3e61615",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elaboración propia.\n",
        "\n",
        "En 2 dimensiones se puede definir como se muestra en la Ecuación (2).\n",
        "\n",
        "$$ \n",
        "f(x_1, x_2) = (a - x_1)^2 + b(x_2 - x_1^2)^2 \\tag{2}\n",
        "$$\n",
        "\n",
        "La Función de Rosenbrock, también conocida como función del valle o del plátano, es ampliamente utilizada para evaluar algoritmos de optimización basados en gradientes. Esta función es unimodal y presenta su mínimo global en un valle parabólico estrecho, lo que facilita su localización. Sin embargo, según @simonfraser_rosenbrock citando a @picheny2012benchmark, la convergencia hacia este mínimo puede ser desafiante debido a la naturaleza del valle.\n",
        "\n",
        "La función se evalúa generalmente en el hipercubo $x_i \\in [-5, 10]$ y tiene un mínimo global en $f(1,...,1) = 0$\n",
        "\n",
        "## Función de Rastrigin\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n",
        "$$\n",
        "\n",
        "**Figura 2.**\n",
        "\n",
        "*Representación gráfica de la función de Rastrigin.*\n"
      ],
      "id": "166fc6f5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función de Rastrigin\n",
        "def rastrigin(x):\n",
        "    \"\"\"\n",
        "    Calcula el valor de la función de Rastrigin.\n",
        "    x: vector de entrada (numpy array)\n",
        "    \"\"\"\n",
        "    d = len(x)\n",
        "    return 10 * d + sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
        "plot_function(rastrigin, x1_range=(-5.12, 5.12), x2_range=(-5.12, 5.12), title=\"Función Rastrigin\", x1_point=0, x2_point=0)"
      ],
      "id": "f3c3442d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elaboración propia.\n",
        "\n",
        "Segun @simonfraser_rosenbrock, la función de Rastrigin tiene varios mínimos locales. Es altamente multimodal, pero las ubicaciones de los mínimos se distribuyen regularmente. La función generalmente se evalúa en el hipercubo $x_i \\in [-5.12, 5.12]$ y su mínimo local se encuentra en $f(0,...,0)=0$.\n",
        "\n",
        "## Función de Schwefel\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n",
        "$$\n",
        "\n",
        "**Figura 3.**\n",
        "\n",
        "*Representación gráfica de la función de Schwefel.*\n"
      ],
      "id": "d53394be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función de Schwefel\n",
        "def schwefel(x):\n",
        "    \"\"\"\n",
        "    Calcula el valor de la función de Schwefel.\n",
        "    x: vector de entrada (numpy array)\n",
        "    \"\"\"\n",
        "    d = len(x)\n",
        "    return 418.9829 * d - sum(x * np.sin(np.sqrt(np.abs(x))))\n",
        "plot_function(schwefel, x1_range=(-500, 500), x2_range=(-500, 500), title=\"Función Schwefel\", x1_point=420.9687, x2_point=420.9687)"
      ],
      "id": "cca428e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elaboración propia.\n",
        "\n",
        "Segun @simonfraser_rosenbrock La función de Schwefel es compleja, con muchos mínimos locales. Normalmente se evalpúa en el hipercubo $x_i \\in [-500,500]$. Su minimo global está en $f(420.9687,...,420.9687)=0$\n",
        "\n",
        "## Función de Griewank\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n",
        "$$\n",
        "\n",
        "**Figura 4.**\n",
        "\n",
        "*Representación gráfica de la función de Griewank.*\n"
      ],
      "id": "bf5da66b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función de Griewank\n",
        "def griewank(x):\n",
        "    \"\"\"\n",
        "    Calcula el valor de la función Griewank.\n",
        "    x: numpy array unidimensional (1D) o un array con forma (d, n1, n2) para evaluaciones vectorizadas.\n",
        "    \n",
        "    Retorna:\n",
        "    - Un valor escalar si `x` es 1D.\n",
        "    - Una matriz (n1, n2) si `x` tiene forma (d, n1, n2).\n",
        "    \"\"\"\n",
        "    x = np.asarray(x)\n",
        "\n",
        "    if x.ndim == 1:\n",
        "        # Caso 1D: calcular para un solo vector\n",
        "        d = len(x)\n",
        "        sum_term = np.sum(x**2) / 4000\n",
        "        product_term = np.prod(np.cos(x / np.sqrt(np.arange(1, d + 1))))\n",
        "        return 1 + sum_term - product_term\n",
        "\n",
        "    elif x.ndim == 3:\n",
        "        # Caso ND: calcular para una cuadrícula (vectorizado)\n",
        "        d = x.shape[0]\n",
        "        i_indices = np.arange(1, d + 1).reshape(-1, 1, 1)\n",
        "        sum_term = np.sum(x**2, axis=0) / 4000\n",
        "        product_term = np.prod(np.cos(x / np.sqrt(i_indices)), axis=0)\n",
        "        return 1 + sum_term - product_term\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"La entrada debe ser un array 1D o un array con forma (d, n1, n2).\")\n",
        "plot_function(griewank, x1_range=(-600, 600), x2_range=(-600, 600), title=\"Función Griewank\", x1_point=0, x2_point=0)"
      ],
      "id": "0d5b80b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elaboración propia.\n",
        "\n",
        "Segun @simonfraser_rosenbrock la función de Griewank tiene muchos mínimos locales generalizados, que se distribuyen de forma regular. Lo que hace compleja su optimización al minimo global. Normalmente se evalua en el hipercubo $x_i \\in [-600,600]$. Su minimo global está en $f(0,...,0)=0$\n",
        "\n",
        "## Función Goldstein-Price\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n",
        "         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n",
        "\\end{align} \\tag{6}\n",
        "$$\n",
        "\n",
        "**Figura 5.**\n",
        "\n",
        "*Representación gráfica de la función de Goldstein-Price.*\n"
      ],
      "id": "b182c352"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función Goldstein-Price\n",
        "def goldstein_price(x):\n",
        "    \"\"\"\n",
        "    Calcula el valor de la función Goldstein-Price.\n",
        "    x1, x2: coordenadas en 2D\n",
        "    \"\"\"\n",
        "    x1=x[0]\n",
        "    x2=x[1]\n",
        "    term1 = (1 + (x1 + x2 + 1)**2 * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2))\n",
        "    term2 = (30 + (2 * x1 - 3 * x2)**2 * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2))\n",
        "    return term1 * term2\n",
        "plot_function(goldstein_price, x1_range=(-2, 2), x2_range=(-2, 2), title=\"Función Goldstein price\", x1_point=0, x2_point=-1)"
      ],
      "id": "907aeec6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elaboración propia.\n",
        "\n",
        "La función Goldstein-Price es una función en 2 dimensiones y tiene varios mínimos locales. Segun @molga2005test, la función generalmente se evalúa en el cuadrado $x_1 \\in [-2, 2]$ y $x_1 \\in [-2, 2]$ . Su mínimo global es $f(0,-1) = 3$\n",
        "\n",
        "## Función de las seis jorobas de camello\n",
        "\n",
        "$$ \n",
        "f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n",
        "$$\n",
        "\n",
        "**Figura 6.**\n",
        "\n",
        "*Representación gráfica de la función de las seis jorobas del camello.*\n"
      ],
      "id": "f0bcb72d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Función de las seis jorobas de camello\n",
        "def camel_six_humps(x):\n",
        "    \"\"\"\n",
        "    Calcula el valor de la función de las seis jorobas de camello.\n",
        "    x1, x2: coordenadas en 2D\n",
        "    \"\"\"\n",
        "    x1 = x[0]\n",
        "    x2 = x[1]\n",
        "    term1 = (4 - 2.1 * x1**2 + x1**4 / 3) * x1**2\n",
        "    term2 = x1 * x2\n",
        "    term3 = (-4 + 4 * x2**2) * x2**2\n",
        "    return term1 + term2 + term3\n",
        "plot_function(camel_six_humps, x1_range=(-2, 2), x2_range=(-1, 1), title=\"Función 6 jorobas de camello\", x1_point=0.0898, x2_point=-0.7126, elev=30, azim=75 )"
      ],
      "id": "d8712129",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elaboración propia.\n",
        "\n",
        "La función de las seis jorobas de camello es una función en 2 dimensiones.Segun @molga2005test la función tiene seis mínimos locales, dos de los cuales son globales y recomienda evaluar la función en el rectángulo $x_1 \\in [-3, 3], x_2 \\in [-2, 2]$, donde los mínimos globales son $f(0.0898,-0.7126) = -1.0316$ y $f(-0.0898, 0.7126) = -1.0316$\n",
        ":::\n",
        "\n",
        "# Proceso de optimización\n",
        "\n",
        "## Optimización por descenso del gradiente\n",
        "\n",
        "El descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\n",
        "\n",
        "De acuerdo con @bishop2006pattern, para una función $f(x)$, el algoritmo actualiza iterativamente el punto $x$ usando la regla que se observa en la Ecuación 8.\n",
        "\n",
        "$$ \n",
        "x_{t+1} = x_t - \\eta \\nabla f(x_t) \\tag{8}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "-   $x_t$ es el punto actual\n",
        "\n",
        "-   $\\eta$ es la tasa de aprendizaje\n",
        "\n",
        "-   $\\nabla f(x_t)$ es el gradiente de la función en $x_t$\n",
        "\n",
        "El gradiente $\\nabla f$ es un vector que contiene las derivadas parciales respecto a cada variable, tal como se ilustra en la Ecuación 9:\n",
        "\n",
        "$$\n",
        "\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix} \\tag{9}\n",
        "$$\n",
        "\n",
        "El gradiente $\\nabla f$ se puede aproximar numéricamente usando diferencias finitas. @bishop2006pattern plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función $f(x_1, x_2)$, las derivadas parciales se calculan como se muestra en las Ecuaciones 10 y 11.\n",
        "\n",
        "$$ \n",
        "\\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\tag{10}\n",
        "$$\n",
        "\n",
        "$$ \n",
        "\\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\tag{11}\n",
        "$$\n",
        "\n",
        "donde $h$ es un pequeño incremento (típicamente $10^{-7}$ o $10^{-8}$).\n"
      ],
      "id": "77df5b4b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def partial_derivative(x0, func, i, h, *args):\n",
        "  e = np.zeros(len(x0))\n",
        "  e[i] = 1\n",
        "  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n",
        "\n",
        "def numerical_gradient(x0, func, h, *args):\n",
        "  gradient = np.zeros(len(x0))\n",
        "  for i in range(len(x0)):\n",
        "    gradient[i] = partial_derivative(x0, func, i, h, *args)\n",
        "  return gradient\n",
        "\n",
        "def gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n",
        "  \"\"\"\n",
        "  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n",
        "\n",
        "  Parameters:\n",
        "      x0 (array-like): Initial guess for the variables.\n",
        "      eta (float): Learning rate.\n",
        "      func (callable): Function to minimize.\n",
        "      h (float): Step size for numerical gradient calculation.\n",
        "      max_iter (int): Maximum number of iterations.\n",
        "      *args: Additional arguments for the function.\n",
        "\n",
        "  Returns:\n",
        "      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n",
        "                                containing the trajectory of points.\n",
        "  \"\"\"\n",
        "  x_old = np.array(x0)\n",
        "  x_hist = []  # List to store the history of x and f(x)\n",
        "\n",
        "  for i in range(max_iter):\n",
        "      # Calculate the gradient numerically\n",
        "      gradient = numerical_gradient(x_old, func, h, *args)\n",
        "\n",
        "      # Update x based on gradient descent rule\n",
        "      x_new = x_old - eta * gradient\n",
        "\n",
        "      # Append current x and function value to history\n",
        "      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n",
        "\n",
        "      # Update x_old\n",
        "      x_old = x_new\n",
        "\n",
        "  # Add the final position and function value\n",
        "  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n",
        "\n",
        "  # Convert history to a pandas DataFrame\n",
        "  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n",
        "\n",
        "  return result_df"
      ],
      "id": "3d2886b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n",
        "\n",
        "::: panel-tabset\n",
        "### Función de Rosenbrock\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n",
        "$$\n",
        "\n",
        "| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n",
        "|-----------|-----------|--------|-----|\n",
        "| -1.5      | -1.7      | 0.001  | 30  |\n",
        "\n",
        "**Figura 7.**\n",
        "\n",
        "*Aplicación del descenso del gradiente en la función de Rosenbrok.* ![Aplicación del descenso del gradiente en la función de Rosenbrok](images/rosenbrock.gif) Elaboración propia.\n",
        "\n",
        "### Función de Rastrigin\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n",
        "$$\n",
        "\n",
        "| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n",
        "|-----------|-----------|--------|-----|\n",
        "| -0.46     | 0.46      | 0.005  | 30  |\n",
        "\n",
        "**Figura 8.**\n",
        "\n",
        "*Aplicación del descenso del gradiente en la función de Rastrigin.* ![Aplicación del descenso del gradiente en la función de Rastrigin](images/rastrigin.gif) Elaboración propia.\n",
        "\n",
        "### Función de Schwefel\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n",
        "$$\n",
        "\n",
        "| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n",
        "|-----------|-----------|--------|-----|\n",
        "| 310       | 310       | 0.8    | 30  |\n",
        "\n",
        "**Figura 9.**\n",
        "\n",
        "*Aplicación del descenso del gradiente en la función de Schwefel.* ![Aplicación del descenso del gradiente en la función de Schwefel](images/schwefel.gif) Elaboración propia.\n",
        "\n",
        "### Función de Griewank\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n",
        "$$\n",
        "\n",
        "| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n",
        "|-----------|-----------|--------|-----|\n",
        "| -500      | 500       | 70     | 33  |\n",
        "\n",
        "**Figura 10.**\n",
        "\n",
        "*Aplicación del descenso del gradiente en la función de Griewank.* ![Aplicación del descenso del gradiente en la función de Griewank](images/griewank.gif) Elaboración propia.\n",
        "\n",
        "### Función Goldstein-Price\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n",
        "         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n",
        "\\end{align} \\tag{6}\n",
        "$$\n",
        "\n",
        "| $x_{1_0}$ | $x_{2_0}$ | $\\eta$  | $n$ |\n",
        "|-----------|-----------|---------|-----|\n",
        "| 0.5       | -1.5      | 0.00005 | 50  |\n",
        "\n",
        "**Figura 11.**\n",
        "\n",
        "*Aplicación del descenso del gradiente en la función de Goldstein-Price.* ![Aplicación del descenso del gradiente en la función de Goldstein-Price](images/goldstein_price.gif) Elaboración propia.\n",
        "\n",
        "### Función de las seis jorobas de camello\n",
        "\n",
        "$$ \n",
        "f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n",
        "$$\n",
        "\n",
        "| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n",
        "|-----------|-----------|--------|-----|\n",
        "| -1        | -1        | 0.015  | 33  |\n",
        "\n",
        "**Figura 12.**\n",
        "\n",
        "*Aplicación del descenso del gradiente en la función de las seis jorobas del camello.* ![Aplicación del descenso del gradiente en la función de las seis jorobas del camello](images/camel_six_humps.gif) Elaboración propia.\n",
        ":::\n",
        "\n",
        "El método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\n",
        "\n",
        "Para garantizar que este método sea eficiente, es importante considerar lo siguiente:\n",
        "\n",
        "-   **Tasa de aprendizaje**: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\n",
        "\n",
        "-   **Punto inicial**: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\n",
        "\n",
        "-   **Criterio de parada**: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia).\n",
        "\n",
        "## Agoritmo genético\n",
        "\n",
        "Un algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la **selección natural** y la **evolución biológica**, propuesto inicialmente por @holland1975adaptation. Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n",
        "\n",
        "### Concepto General\n",
        "\n",
        "El algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n",
        "\n",
        "-   **Selección**: Elegir individuos con mayor *fitness*.[^1]\n",
        "\n",
        "-   **Cruce**: Combinar soluciones para generar descendencia.\n",
        "\n",
        "-   **Mutación**: Introducir variación genética.\n",
        "\n",
        "[^1]: El *fitness* representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.\n",
        "\n",
        "Matemáticamente, en un problema de minimización, el objetivo es encontrar:\n",
        "\n",
        "$$ \n",
        "x^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) \\tag{12}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "-   $x$ representa un individuo en el espacio de búsqueda.\n",
        "-   $f(x)$ es la función objetivo que evalúa la calidad de $x$.\n",
        "\n",
        "Cada solución candidata se representa como un **individuo**, que puede ser un vector real o un cromosoma binario, tal como se ilustra en la Ecuación 13:\n",
        "\n",
        "$$\n",
        "x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n \\tag{13}\n",
        "$$\n",
        "\n",
        "La función objetivo, mostrada en la Ecuación 14, mide qué tan buena es una solución.\n",
        "\n",
        "$$\n",
        "\\text{Fitness}(x) = f(x) \\tag{14}\n",
        "$$\n",
        "\n",
        "Para problemas de **minimización**, menor $f(x)$ implica mejor fitness.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Etapas\n",
        "\n",
        "**Inicialización de la Población**\n",
        "\n",
        "Se genera una población inicial de $P$ individuos de forma aleatoria dentro de un intervalo $[a, b]$:\n",
        "\n",
        "$$\n",
        "x_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\} \\tag{15}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "-   $x_{ij}$ es la $j-ésima$ coordenada del $i-ésimo$ individuo.\n"
      ],
      "id": "d2842b71"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inicializar población\n",
        "def initialize_population(size, dim, bounds):\n",
        "    return np.random.uniform(bounds[0], bounds[1], (size, dim))"
      ],
      "id": "2545a87e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "**Evaluación del Fitness**\n",
        "\n",
        "Cada individuo de la población es evaluado usando la función objetivo mostrada a continuación, en la Ecuación 16.\n",
        "\n",
        "$$\n",
        "\\text{Fitness}_i = f(x_i) \\tag{16}\n",
        "$$\n"
      ],
      "id": "8ed31471"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluar fitness\n",
        "def evaluate_fitness(population,fitness_function):\n",
        "    return np.array([fitness_function(ind) for ind in population])"
      ],
      "id": "e9456060",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "**Selección**\n",
        "\n",
        "Se seleccionan individuos para reproducirse basándose en su fitness. Un métodos común es el método de torneo, observado en la Ecuación 17, donde primero se seleccionan $k$ individuos al azar y luego se elige al mejor de ellos (quien tenga el mejor fitness):\n",
        "\n",
        "$$\n",
        "\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k \\tag{17}\n",
        "$$\n"
      ],
      "id": "9fb8b20d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Selección por torneo\n",
        "def tournament_selection(population, fitness, k=3):\n",
        "    selected = []\n",
        "    for _ in range(len(population)):\n",
        "        candidates = np.random.choice(range(len(population)), k, replace=False)\n",
        "        winner = candidates[np.argmin(fitness[candidates])]\n",
        "        selected.append(population[winner])\n",
        "    return np.array(selected)"
      ],
      "id": "1781c41d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "**Cruce (Recombinación)**\n",
        "\n",
        "Dos individuos (padres) se combinan para generar descendencia. Un método común es **punto de corte único**, donde primero se elige un punto de cruce aleatorio $k$ y después se genera la descendencia mezclando las características de los padres, como se observa en las Ecuaciones 18 y 19.\n",
        "\n",
        "$$\n",
        "\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:]) \\tag{18}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:]) \\tag{19}\n",
        "$$\n",
        "\n",
        "La probabilidad de realizar un cruce está determinada por $p_c$ (tasa de cruce).\n"
      ],
      "id": "48144c63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cruce\n",
        "def crossover(parent1, parent2, crossover_rate):\n",
        "    if np.random.rand() < crossover_rate:\n",
        "        point = np.random.randint(1, len(parent1))\n",
        "        child = np.concatenate([parent1[:point], parent2[point:]])\n",
        "        return child\n",
        "    return parent1 if np.random.rand() < 0.5 else parent2"
      ],
      "id": "879b2492",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "**Mutación**\n",
        "\n",
        "Se introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad $p_m$:\n",
        "\n",
        "$$\n",
        "x_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta) \\tag{20}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "-   $\\Delta$ es una perturbación aleatoria.\n",
        "-   $x_{ij}$ se restringe a los límites del problema.\n"
      ],
      "id": "b2054e6d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Mutación\n",
        "def mutate(individual, bounds, mutation_rate, delta):\n",
        "    for i in range(len(individual)):\n",
        "        if np.random.rand() < mutation_rate:\n",
        "            individual[i] += np.random.uniform(-delta, delta)\n",
        "            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n",
        "    return individual"
      ],
      "id": "bb1cdf81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "**Evaluación y Sustitución**\n",
        "\n",
        "La nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n"
      ],
      "id": "4ba17847"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Algoritmo completo\n",
        "def genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n",
        "    population = initialize_population(population_size, dim, bounds)\n",
        "    best_individual = None\n",
        "    trajectory = []\n",
        "    populations = []\n",
        "\n",
        "    for generation in range(generations):\n",
        "        populations.append(population.copy())\n",
        "        fitness = evaluate_fitness(population, fitness_function)\n",
        "        \n",
        "        if best_individual is None or np.min(fitness) < fitness_function(best_individual):\n",
        "            best_individual = population[np.argmin(fitness)]\n",
        "        \n",
        "        # Guardar la mejor solución de esta generación\n",
        "        trajectory.append((*best_individual, fitness_function(best_individual)))\n",
        "        \n",
        "        # Selección\n",
        "        selected_population = tournament_selection(population, fitness)\n",
        "        \n",
        "        # Cruce y mutación\n",
        "        new_population = []\n",
        "        for i in range(0, len(selected_population), 2):\n",
        "            if i + 1 < len(selected_population):\n",
        "                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n",
        "                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n",
        "                new_population.extend([child1, child2])\n",
        "            else:\n",
        "                new_population.append(selected_population[i])\n",
        "        \n",
        "        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n",
        "    \n",
        "    # Convertir la trayectoria a DataFrame\n",
        "    \n",
        "    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n",
        "    df = pd.DataFrame(trajectory, columns=columns)\n",
        "    return best_individual, fitness_function(best_individual), df, populations"
      ],
      "id": "bd37d4e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "::: panel-tabset\n",
        "### Función de Rosenbrock\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n",
        "$$\n",
        "\n",
        "**Figura 13.**\n",
        "\n",
        "*Aplicación del algoritmo genético sobre la función de Rosenbrok.* ![Aplicación del algoritmo genético sobre la función de Rosenbrok](images/Rosenbrock_population_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Rastrigin\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n",
        "$$\n",
        "\n",
        "**Figura 14.**\n",
        "\n",
        "*Aplicación del algoritmo genético sobre la función de Rastrigin.* ![Aplicación del algoritmo genético sobre la función de Rastrigin](images/Rastrigin_population_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Schwefel\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n",
        "$$\n",
        "\n",
        "**Figura 15.**\n",
        "\n",
        "*Aplicación del algoritmo genético sobre la función de Schwefel.* ![Aplicación del algoritmo genético sobre la función de Schwefel](images/Schwefel_population_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Griewank\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n",
        "$$\n",
        "\n",
        "**Figura 16.**\n",
        "\n",
        "*Aplicación del algoritmo genético sobre la función de Griewank.* ![Aplicación del algoritmo genético sobre la función de Griewank](images/Griewank_population_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función Goldstein-Price\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n",
        "         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n",
        "\\end{align} \\tag{6}\n",
        "$$\n",
        "\n",
        "**Figura 17.**\n",
        "\n",
        "*Aplicación del algoritmo genético sobre la función de Goldstein-Price.* ![Aplicación del algoritmo genético sobre la función de Goldstein-Price](images/Goldstein_Price_population_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de las seis jorobas de camello\n",
        "\n",
        "$$ \n",
        "f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n",
        "$$\n",
        "\n",
        "**Figura 18.**\n",
        "\n",
        "*Aplicación del algoritmo genético sobre la función de las seis jorobas del camello.* ![Aplicación del algoritmo genético sobre la función de las seis jorobas del camello](images/Camel_Six_Humps_population_animation.gif) Elaboración propia.\n",
        ":::\n",
        "\n",
        "Los algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: **exploración**, que consiste en descubrir nuevas regiones del espacio de búsqueda, y **explotación**, enfocada en refinar y mejorar las soluciones existentes.\n",
        "\n",
        "Para las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación $\\delta$ se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n",
        "\n",
        "### Observaciones\n",
        "\n",
        "Ventajas:\n",
        "\n",
        "-   No requiere derivadas ni condiciones específicas en $f(x)$ .\n",
        "-   Es efectivo en espacios de búsqueda multimodales o no convexos.\n",
        "-   Adaptable a diversos problemas.\n",
        "\n",
        "Desventajas:\n",
        "\n",
        "-   Puede ser computacionalmente costoso.\n",
        "-   No garantiza convergencia al óptimo global.\n",
        "-   Requiere ajuste cuidadoso de parámetros.\n",
        "\n",
        "## Optimización de partículas\n",
        "\n",
        "### Concepto Básico y Analogía\n",
        "\n",
        "De acuerdo con @kennedy1995particle, puede decirse que la Optimización por Enjambre de Partículas (PSO) es una técnica metaheurística inspirada en el comportamiento social de los animales, como los pájaros o los peces. En PSO, cada solución potencial al problema se representa como una partícula que se mueve en un espacio de búsqueda multidimensional. Cada partícula ajusta su posición y velocidad en cada iteración, basándose en su propia mejor posición encontrada (pBest) y la mejor posición encontrada por todo el enjambre (gBest).\n",
        "\n",
        "Los métodos PSO se atribuyen originalmente a los investigadores @kennedy1997particle. En un principio fueron concebidos para elaborar modelos de conductas sociales,​como el movimiento descrito por los organismos vivos en una bandada de aves o un banco de peces. Posteriormente el algoritmo se simplificó y se comprobó que era adecuado para problemas de optimización.\n",
        "\n",
        "**Funcionamiento de PSOz**\n",
        "\n",
        "En el algoritmo PSO (Particle Swarm Optimization), cada partícula, que representa un individuo, posee una posición *p*⃗  ​ dentro del espacio de búsqueda y una velocidad *v*⃗ que determina su desplazamiento. Estas partículas, al igual que objetos en un entorno físico, cuentan con una inercia *w*, la cual conserva su movimiento en la dirección previamente seguida.\n"
      ],
      "id": "db373334"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "self.positions = np.random.uniform(\n",
        "    self.bounds[:, 0],\n",
        "    self.bounds[:, 1],\n",
        "    size=(n_particles, dimensions)\n",
        ")\n",
        "\n",
        "self.velocities = np.zeros((n_particles, dimensions))\n",
        "\n",
        "# Evaluar posiciones iniciales\n",
        "self.scores = np.array([self.objective_function(p) for p in self.positions])"
      ],
      "id": "58897c0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además, su aceleración, que representa un cambio en la velocidad, está influenciada por dos factores principales:\n",
        "\n",
        "-   Atracción hacia su mejor posición personal: Cada partícula tiende a moverse hacia la mejor ubicación que ha identificado en su trayectoria histórica (*pbest).*\n",
        "\n",
        "-   Atracción hacia la mejor posición global: Las partículas también se dirigen hacia la mejor ubicación encontrada por el grupo completo en el espacio de búsqueda (*pgbest*).\n",
        "\n",
        "*Ilustración del funcionamiento del algoritmo PSO.* ![Ilustración del funcionamiento del algoritmo PSO](images/paste-1.png)\n",
        "\n",
        "Adaptado de @sancho_pso_image\n"
      ],
      "id": "5db86300"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "for iteration in range(self.max_iter):\n",
        "    # Actualizar velocidades\n",
        "    r1, r2 = np.random.rand(2)\n",
        "    self.velocities = (self.w * self.velocities +\n",
        "                     self.c1 * r1 * (self.p_best - self.positions) +\n",
        "                     self.c2 * r2 * (self.g_best - self.positions))\n",
        "    \n",
        "    # Actualizar posiciones\n",
        "    self.positions += self.velocities\n",
        "    \n",
        "    # Mantener partículas dentro de los límites\n",
        "    self.positions = np.clip(\n",
        "        self.positions,\n",
        "        self.bounds[:, 0],\n",
        "        self.bounds[:, 1]\n",
        "    )\n",
        "    \n",
        "    # Evaluar nuevas posiciones\n",
        "    self.scores = np.array([self.objective_function(p) for p in self.positions])\n",
        "    \n",
        "    # Actualizar mejores posiciones personales\n",
        "    improved_mask = self.scores < self.p_best_scores\n",
        "    self.p_best[improved_mask] = self.positions[improved_mask]\n",
        "    self.p_best_scores[improved_mask] = self.scores[improved_mask]\n",
        "    \n",
        "    # Actualizar mejor posición global\n",
        "    min_score_idx = np.argmin(self.p_best_scores)\n",
        "    if self.p_best_scores[min_score_idx] < self.g_best_score:\n",
        "        self.g_best = self.p_best[min_score_idx].copy()\n",
        "        self.g_best_score = self.p_best_scores[min_score_idx]"
      ],
      "id": "7c8e6f1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El algoritmo se detiene cuando se alcanza un número máximo de iteraciones, o cuando la mejora en la función objetivo es menor a un umbral predefinido.\n",
        "\n",
        "Al implementar el algoritmo, se presentó un comportamiento oscilatorio donde las partículas convergían inicialmente pero luego se dispersaban de manera repentina. El análisis reveló cuatro posibles causas: velocidades excesivas de las partículas, coeficientes de aprendizaje mal ajustados, peso de inercia estático y ausencia de un mecanismo de estabilización.\n",
        "\n",
        "La solución implementada aborda estos problemas mediante cuatro modificaciones: Se  limitó la velocidad máxima al 10% del espacio de búsqueda para evitar saltos excesivos, se optimizaron los coeficientes cognitivo y social a un valor de 2.0 para balancear exploración y explotación, se implementó un peso de inercia dinámico que decrece linealmente de 0.9 a 0.4 durante la optimización y se añadió un factor de constricción calculado a partir de los coeficientes de aprendizaje para garantizar convergencia matemática.\n"
      ],
      "id": "d13cea52"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Control de Velocidad Máxima\n",
        "v_max = 0.1 * (bounds[:, 1] - bounds[:, 0])\n",
        "velocities = np.clip(velocities, -v_max, v_max)\n",
        "\n",
        "# Peso de Inercia Dinámico\n",
        "w = w_max - (w_max - w_min) * (iteracion / max_iter)\n",
        "\n",
        "# Factor de Constricción\n",
        "phi = c1 + c2\n",
        "chi = 2 / abs(2 - phi - np.sqrt(phi * phi - 4 * phi))\n",
        "\n",
        "# Parámetros Optimizados\n",
        "c1 = c2 = 2.0\n",
        "w_max = 0.9\n",
        "w_min = 0.4"
      ],
      "id": "6cbc8a21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estas modificaciones resultaron en una mejora significativa en la estabilidad del algoritmo, con una transición más suave entre las fases de exploración y explotación, y una convergencia más consistente hacia el óptimo global.\n",
        "\n",
        "::: panel-tabset\n",
        "### Función de Rosenbrock\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n",
        "$$\n",
        "\n",
        "**Figura 19.**\n",
        "\n",
        "*Aplicación de optimización de partículas sobre la función de Rosenbrock.* ![Aplicación de optimización de partículas sobre la función de Rosenbrock](images/Rosenbrock_particulas_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Rastrigin\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n",
        "$$\n",
        "\n",
        "**Figura 20.**\n",
        "\n",
        "*Aplicación de optimización de partículas sobre la función de Rastrigin.* ![Aplicación de optimización de partículas sobre la función de Rastrigin](images/Rastrigin_particulas_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Schwefel\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n",
        "$$\n",
        "\n",
        "**Figura 21.**\n",
        "\n",
        "*Aplicación de optimización de partículas sobre la función de Schwefel.* ![Aplicación de optimización de partículas sobre la función de Schwefel](images/Schwefel_particulas_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Griewank\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n",
        "$$\n",
        "\n",
        "**Figura 22.**\n",
        "\n",
        "*Aplicación de optimización de partículas sobre la función de Griewank.* ![Aplicación de optimización de partículas sobre la función de Griewank](images/Griewank_particulas_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función Goldstein-Price\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n",
        "         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n",
        "\\end{align} \\tag{6}\n",
        "$$\n",
        "\n",
        "**Figura 23.**\n",
        "\n",
        "*Aplicación de optimización de partículas sobre la función de Goldstein-Price.* ![Aplicación de optimización de partículas sobre la función de Goldstein-Price](images/Goldstein_Price_particulas_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de las seis jorobas de camello\n",
        "\n",
        "$$ \n",
        "f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n",
        "$$\n",
        "\n",
        "**Figura 24.**\n",
        "\n",
        "*Aplicación de optimización de partículas sobre la función de las seis jorobas del camello.* ![Aplicación de optimización de partículas sobre la función de las seis jorobas del camello](images/Camel_Six_Humps_particulas_animation.gif) Elaboración propia.\n",
        ":::\n",
        "\n",
        "## Optimización diferencial\n",
        "\n",
        "**Funcionamiento Básico**\n",
        "\n",
        "La Evolución Diferencial (ED) es un algoritmo de optimización poblacional inspirado en los procesos evolutivos naturales. Al igual que otros algoritmos de esta categoría, la ED mantiene una población de soluciones candidatas, las cuales se recombinan y mutan para producir nuevos individuos los cuales serán elegidos de acuerdo al valor de su función de desempeño. Lo que caracteriza a la ED es el uso de vectores de prueba, los cuales compiten con los individuos de la población actual a fin de sobrevivir. [@price1995differential]\n",
        "\n",
        "**Pasos clave:**\n",
        "\n",
        "-   **Inicialización de la población:**\n",
        "\n",
        "    -   Se genera aleatoriamente una población inicial de individuos (soluciones potenciales).\n",
        "\n",
        "    -   Cada individuo es un vector que representa un punto en el espacio de búsqueda.\n"
      ],
      "id": "677a3db7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def initialize_population(self):\n",
        "    \"\"\"\n",
        "    Inicializa la población de manera aleatoria dentro de los límites especificados\n",
        "\n",
        "    Returns:\n",
        "    - Matriz numpy con población inicial\n",
        "    \"\"\"\n",
        "    # Crea una matriz de ceros con el tamaño de la población\n",
        "    population = np.zeros((self.population_size, self.dimension))\n",
        "\n",
        "    # Genera valores aleatorios para cada dimensión\n",
        "    for i in range(self.dimension):\n",
        "        population[:, i] = np.random.uniform(\n",
        "            self.bounds[i][0],  # Límite inferior\n",
        "            self.bounds[i][1],  # Límite superior\n",
        "            size=self.population_size  # Número de individuos\n",
        "        )\n",
        "    return population"
      ],
      "id": "fd79d28d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Evaluación de la población:**\n",
        "\n",
        "    -   Se evalúa el valor de la función objetivo para cada individuo de la población\n",
        "\n",
        "-   **Generación de nuevos individuos:**\n",
        "\n",
        "    -   **Mutación:** Se crea un vector mutante sumando a un individuo objetivo una diferencia escalada entre otros dos individuos de la población.\n"
      ],
      "id": "40a6cd72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mutation(self, population):\n",
        "    \"\"\"\n",
        "    Aplica la estrategia de mutación DE/rand/1\n",
        "\n",
        "    Parameters:\n",
        "    - population: Población actual\n",
        "\n",
        "    Returns:\n",
        "    - Población mutada\n",
        "    \"\"\"\n",
        "    # Crea una matriz para almacenar la población mutada\n",
        "    mutation_pop = np.zeros_like(population)\n",
        "\n",
        "    for i in range(self.population_size):\n",
        "        # Selecciona tres individuos aleatorios diferentes\n",
        "        candidates = list(range(self.population_size))\n",
        "        candidates.remove(i)\n",
        "        r1, r2, r3 = np.random.choice(candidates, 3, replace=False)\n",
        "\n",
        "        # Genera un nuevo vector mediante mutación\n",
        "        mutation_pop[i] = population[r1] + self.F * (population[r2] - \n",
        "                                                               population[r3])\n",
        "\n",
        "        # Asegura que los valores estén dentro de los límites\n",
        "        for j in range(self.dimension):\n",
        "            mutation_pop[i, j] = np.clip(\n",
        "                mutation_pop[i, j],\n",
        "                self.bounds[j][0],\n",
        "                self.bounds[j][1]\n",
        "            )\n",
        "\n",
        "    return mutation_pop"
      ],
      "id": "8631ffb0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Cruce:** Se crea un vector de prueba combinando el vector mutante y el individuo objetivo mediante un operador de cruce.\n"
      ],
      "id": "c3b7e867"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def crossover(self, population, mutation_pop):\n",
        "    \"\"\"\n",
        "    Aplica el cruce binomial (crossover)\n",
        "\n",
        "    Parameters:\n",
        "    - population: Población actual\n",
        "    - mutation_pop: Población mutada\n",
        "\n",
        "    Returns:\n",
        "    - Población de prueba tras el cruce\n",
        "    \"\"\"\n",
        "    # Crea una matriz para almacenar la población de prueba\n",
        "    trial_pop = np.zeros_like(population)\n",
        "\n",
        "    for i in range(self.population_size):\n",
        "        # Genera puntos de cruce basados en CR\n",
        "        cross_points = np.random.rand(self.dimension) <= self.CR\n",
        "        # Asegura al menos un punto de cruce\n",
        "        cross_points[np.random.randint(0, self.dimension)] = True\n",
        "\n",
        "        # Genera vector de prueba\n",
        "        trial_pop[i] = np.where(cross_points, mutation_pop[i], population[i])\n",
        "\n",
        "    return trial_pop"
      ],
      "id": "3e899482",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Selección:** Se compara el valor de la función objetivo del vector de prueba con el del individuo objetivo. El mejor de los dos se selecciona para la siguiente generación.\n"
      ],
      "id": "38d0f6bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def selection(self, population, trial_pop):\n",
        "    \"\"\"\n",
        "    Selección de los mejores individuos\n",
        "\n",
        "    Parameters:\n",
        "    - population: Población actual\n",
        "    - trial_pop: Población de prueba\n",
        "\n",
        "    Returns:\n",
        "    - Nueva población y sus valores de aptitud\n",
        "    \"\"\"\n",
        "    # Calcula la aptitud de la población actual y de prueba\n",
        "    pop_fitness = np.array([self.func(ind) for ind in population])\n",
        "    trial_fitness = np.array([self.func(ind) for ind in trial_pop])\n",
        "\n",
        "    # Identifica qué individuos de prueba son mejores\n",
        "    better_indices = trial_fitness < pop_fitness\n",
        "    population[better_indices] = trial_pop[better_indices]\n",
        "\n",
        "    return population, np.minimum(pop_fitness, trial_fitness)"
      ],
      "id": "c13c5958",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Criterio de parada**:\n",
        "\n",
        "    -   Se repiten los pasos 3 y 4 hasta que se cumpla un criterio de parada (número máximo de generaciones, mejora mínima en la función objetivo, etc.), de acuerdo con @martinez2019evolucion.\n",
        "\n",
        "::: panel-tabset\n",
        "### Función de Rosenbrock\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n",
        "$$\n",
        "\n",
        "**Figura 25.**\n",
        "\n",
        "*Aplicación de optimización diferencial sobre la función de Rosenbrock.* ![Aplicación de optimización diferencial sobre la función de Rosenbrock](images/Rosenbrock_diferential_evolution_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Rastrigin\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n",
        "$$\n",
        "\n",
        "**Figura 26.**\n",
        "\n",
        "*Aplicación de optimización diferencial sobre la función de Rastrigin.* ![Aplicación de optimización diferencial sobre la función de Rastrigin](images/Rastrigin_diferential_evolution_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Schwefel\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n",
        "$$\n",
        "\n",
        "**Figura 27.**\n",
        "\n",
        "*Aplicación de optimización diferencial sobre la función de Schwefel.* ![Aplicación de optimización diferencial sobre la función de Schwefel](images/Schwefel_diferential_evolution_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de Griewank\n",
        "\n",
        "$$ \n",
        "f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n",
        "$$\n",
        "\n",
        "**Figura 28.**\n",
        "\n",
        "*Aplicación de optimización diferencial sobre la función de Griewank.* ![Aplicación de optimización diferencial sobre la función de Griewank](images/Griewank_diferential_evolution_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función Goldstein-Price\n",
        "\n",
        "$$ \n",
        "\\begin{align} f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\          & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right] \\end{align} \\tag{6}\n",
        "$$\n",
        "\n",
        "**Figura 29.**\n",
        "\n",
        "*Aplicación de optimización diferencial sobre la función de Goldstein-Price.* ![Aplicación de optimización diferencial sobre la función de Goldstein-Price](images/Goldstein_Price_diferential_evolution_animation.gif) Elaboración propia.\n",
        "\n",
        "### Función de las seis jorobas de camello\n",
        "\n",
        "$$ \n",
        "f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n",
        "$$\n",
        "\n",
        "**Figura 30.**\n",
        "\n",
        "*Aplicación de optimización diferencial sobre la función de las seis jorobas del camello.* ![Aplicación de optimización diferencial sobre la función de las seis jorobas del camello](images/Camel_Six_Humps_diferential_evolution_animation.gif) Elaboración propia.\n",
        ":::\n",
        "\n",
        "# Resultados\n",
        "\n",
        "Como se puede observar, en la mayoría de los casos de optimización para una única corrida los puntos óptimos conergen a mínimos locales, lo que indica que los resultados óptimos pueden estar fuertemente influenciados por los valores iniciales de $x$ o las condiciones de inicio de los algoritmos. Por esta razón, para evaluar el rendimiento y el comportamiento de los algoritmos en un entorno más general, se realizarán múltiples ejecuciones.\n",
        "\n",
        "En cada corrida, los algoritmos partirán de valores iniciales distintos generados aleatoriamente. Para evaluar el rendimiento de los métodos de optimización desarrollados, se harán 20 corridas para cada funció y se tomará para cada uno el tiempo de ejecución y el mejor fitness encontrado hasta el momento.\n",
        "\n",
        "## Análisis de mejor fitness para los diferentes métodos\n",
        "\n",
        "Para cada función se realizó un gráfico de comparación de mejor fitness para cada corrida en cada uno de los métodos utilizados, originando el conjunto de resultados que se pueden observar en la Figura 31, como se muestra a continuación.\n",
        "\n",
        "**Figura 31.**\n",
        "\n",
        "*Rendimiento de las funciones, en función de las corridas y los métodos de optimización.* ![Rendimiento de las funciones, en función de las corridas y los métodos de optimización](images/rendimiento_funciones.png){fig-align=\"center\"} *Nota.* Es posible hacer una comparación tanto a nivel de corridas como al respecto de los métodos empleados anteriormente, con lo cual se llega a las conclusiones enunciadas más adelante. Elaboración propia.\n",
        "\n",
        "Finalmente, en la Figura 32 se pueden observar los resultados generales obtenidos en cuanto a los tiempos de ejecución de cada uno de los algoritmos utilizados.\n",
        "\n",
        "**Figura 32.**\n",
        "\n",
        "*Tiempo promedio de ejecución de cada método de optimización ejecutado.* ![Tiempo promedio de ejecución de cada método de optimización ejecutado](images/paste-2.png) Elaboración propia.\n",
        "\n",
        "# Conclusiones y comentarios\n",
        "\n",
        "## Eficiencia computacional (tiempo de ejecución)\n",
        "\n",
        "-   **Gradiente Descendente**: Es consistentemente el método más rápido, pues obtuvo tiempos de ejecución de entre 0.003 a 0.008 segundos, siendo extremadamente rápido en comparación con los demás pero potencialmente menos preciso.\n",
        "\n",
        "-   **Enjambre de Partículas**: Tiene tiempos de ejecución moderados, de 0.07 a 0.27 segundos, con una sobrecarga computacional ligeramente mayor que Gradiente Descendente y presenta buen equilibrio entre velocidad y exploración.\n",
        "\n",
        "-   **Evolución Diferencial**: Tiene un rendimiento más lento con tiempos de ejecución de entre 0.8 y 1.9 segundos y consume significativamente más tiempo, lo que sugiere la utilización de operaciones de mutación y cruce más complejas.\n",
        "\n",
        "-   **Algoritmo Genético**: Posee un rendimiento similar a Enjambre de Partículas con tiempos de ejecución de entre 0.07 y 0.14 segundos, es más eficiente que Evolución Diferencial, lo que sugiere la necesidad de requisitos computacionales moderados.\n",
        "\n",
        "## Rendimiento de Optimización\n",
        "\n",
        "En el análisis del rendimiento de optimización, se observaron variaciones significativas entre los diferentes algoritmos según la función de prueba. En funciones como Rosenbrock y Rastrigin, el Enjambre de Partículas y la Evolución Diferencial mostraron un rendimiento superior, logrando valores de error casi cero, mientras que el Algoritmo Genético tuvo resultados moderados y el Gradiente Descendente mostró mayor dificultad. En contraste, para funciones como Goldstein-Price y Camellos de Seis Jorobas, casi todos los métodos convergieron de manera similar cerca del óptimo conocido, sugiriendo que la efectividad de cada algoritmo depende crucialmente de la estructura y complejidad de la función objetivo.\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "El rendimiento de los algoritmos de optimización es altamente dependiente del contexto. Mientras que Enjambre de Partículas y Evolución Diferencial mostraron un rendimiento robusto en la mayoría de las funciones, la mejor elección depende de los desafíos específicos de optimización.\n",
        "\n",
        "# Discusión\n",
        "\n",
        "-   Los algoritmos de optimización presentan rendimientos distintos según la complejidad de las funciones, con métodos estocásticos como Enjambre de Partículas y Evolución Diferencial mostrando mayor capacidad de exploración y adaptabilidad en espacios de búsqueda complejos.\n",
        "\n",
        "-   Los métodos heurísticos (Enjambre de Partículas, Evolución Diferencial y Algoritmo Genético) demostraron una superior capacidad para explorar y optimizar funciones complejas, logrando errores casi cero en algunas funciones, mientras que el Descenso por Gradiente, aunque extremadamente rápido, mostró limitaciones significativas en funciones no convexas aunque resultados cercanos a los otros métodos en funciones mas simples, revelando que no existe un algoritmo universalmente óptimo y que la elección del método depende críticamente de las características específicas del problema de optimización.\n",
        "\n",
        "-   Se observa también, de acuerdo con lo mostrado en la Figura 31, que entre más corridas se hagan, los métodos heurísticos de optimización podrían ir consiguiendo mejores resultados, considerando el factor aleatorio presente en cada uno de ellos."
      ],
      "id": "d14ac77a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\asus\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}