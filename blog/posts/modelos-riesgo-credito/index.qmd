---
title: "Modelos de riesgo de crédito con Redes Neuronales Artificiales"
format: 
  html:
    toc: true
    toc-width: 250px   # Ajusta el ancho de la ToC
    main-container-width: 90%  # Incrementa el ancho del contenido principal
    fig-width: 8
    fig-height: 6
    number-sections: true
    math: 
      method: mathjax
      options:
        TeX:
          equationNumbers: { autoNumber: "AMS" }
  
author:
  - name: "Tomás Rodríguez Taborda"
  - name: "Julián Castaño Pineda"
  - name: "Luis Andrés Altamar Romero"
  - name: "Catalina Restrepo Salgado"
date: "2025-01-23"
categories: [redes neuronales artificiales, desarrollo web, python]
image: "image.jpg"
bibliography: ref.bib
execute:
  cache: true
---

# Introducción a la evaluación y gestión del riesgo de crédito

El riesgo de crédito, de acuerdo con información encontrada en el sitio web @financionario2025 y, en concordancia con lo dicho por @financestrategists2023, se define como una medida empleada para dimensionar el riesgo (en términos de probabilidad) de que un prestatario incumpla con el pago de una obligación financiera o el reembolso del dinero correspondiente a un préstamo.

En este sentido, es posible notar que una correcta evaluación y gestión del riesgo de crédito es de vital importancia en las actividades relacionadas con el préstamo y la inversión, pues ayudan a que las entidades financieras puedan mantener su estabilidad, a la misma vez que se proyectan como instituciones de confianza ante las entidades estatales, sus socios y clientes. Adicionalmente, el riesgo de crédito suele tenerse en cuenta como un criterio a la hora de aprobar o definir las condiciones de un préstamo, solicitando garantías de respaldo al prestatario o ajustando la tasa de interés de acuerdo con estos resultados; la Figura 1 puede considerarse una imagen ilustrativa de las condiciones óptimas de crédito asignadas a un prestatario de acuerdo con su evaluación positiva del riesgo de crédito.

**Figura 1.**

*Crédito y ahorro.* ![Crédito y ahorro](imagen_credito.jpg) Adaptado de Ilustración del plan de ahorro de los empleados dibujada a mano \[Ilustración\], por Freepik, 2024 (https://www.freepik.es/vector-gratis/ilustracion-plan-ahorro-empleados-dibujada-mano_87161866.htm#fromView=search&page=1&position=11&uuid=e54defbf-b176-455c-82c3-276ae1b3c634&new_detail=true). Licencia gratuita.

Sabiendo lo anterior, puede decirse que, tanto para las instituciones financieras como para quienes solicitan estos servicios, el riesgo de crédito es un factor de incertidumbre que influye en la toma de decisiones relacionada con la admisión de préstamos y otros productos financieros, entendiendo incertidumbre como "la falta de (...) certeza o de un conocimiento seguro respecto de una determinada situación", según @significadode2023.

## Delimitaciones del problema y metodología

Considerando entonces la importancia del estudio del riesgo de crédito y sus implicaciones en las decisiones que toman las instituciones financieran que invierten y otorgan préstamos, así como las consecuencias que estas decisiones acarrean sobre las personas que los solicitas, se decide abordar esta cuestión a partir desde el punto de vista de los conocimientos adquiridos en el curso. Esto, pues la evaluación del riesgo de crédito involucra tareas como las que se enuncian a continuación:

-   **Manejo de grandes volúmenes de datos:** las entidades financieras o estatales poseen un amplio registro de información sobre los clientes que acceden a estos servicios, tales como sus comportamientos de pago y datos demográficos.

-   **Identificación de patrones no evidentes:** la probabilidad de incumplimiento de un cliente con sus pagos no siempre tendrá una relación lineal con las características que se conocen acerca de su persona, por lo que pueden necesitarse técnicas de mayor complejidad para descubrir los patrones o relaciones que lo explican.

-   **Toma de decisiones basadas en riesgo**: correspondiente al objetivo final de la presente actividad, se es importante realizar una clasificación de los clientes según su nivel de riesgo de crédito, asignando un puntaje que permita evaluar cualitativa y cuantitativamente las solicitudes de préstamo.

Dicho esto, puede verse que la elaboración de una herramienta que permita una evaluación adecuada del riesgo de crédito sería altamente beneficiosa no solo para las entidades financieras, que contarían con un medio de conocer mejor a sus posibles clientes, sino también para estos últimos, pues tendrían la oportunidad de conocer con antelación las posibilidades de que su crédito sea aprobado así como las variables que influirían en esa decisión.

Para tal fin se desarrollará una aplicación web que permitirá responder a la pregunta: *¿cuál es el puntaje de riesgo de crédito de un posible prestatario?* a través de la utilización de un modelo de redes neuronales artificiales entrenado sobre un amplio conjunto de datos en este contexto. El dataset a emplear, titulado **Credit Risk Analysis** y proporcionado por @r_g__2021 será tratado con la siguiente metodología y posteriormente evaluado, como podrá verse más adelante.

**Metodología**

1.  Análisis descriptivo e hipótesis del conjunto de datos.
2.  Planteamiento y evaluación de modelos.
3.  Conclusiones y aprendizajes a partir del modelo.
4.  Planteamiento de un caso de uso.

A continuación se da inicio al desarrollo de la actividad, la cual será complementada con todos los recursos empleados y productos resultantes de dicho ejercicio.

## Análisis descriptivo e hipótesis del conjunto de datos

El análisis exploratorio de datos es una fase crítica para comprender la estructura, la calidad y la naturaleza de los datos, estableciendo las bases para el análisis posterior. Este proceso lo divideremos en varias etapas, comenzaremos con una exploración inicial de los datos, seguida de su manipulación y limpieza, y culminando con el análisis visual y la selección de características.

### Entendiendo los datos

El primer paso del análisis exploratorio será entender los datos en términos generales. Para ello: leeiemos la base datos e identificmos sus dimensiones que corresponden con 887379 filas y 74 columnas o variables.

En la Tabla 1 que se muestra a continuación puede verse la estructura de las variables del conjunto de datos así como del porcentaje del valores nulos *NA* presentes en cada variable.

**Tabla 1.**

*Primer análisis exploratorio del conjunto de datos.*

```{python}

import pandas as pd
from IPython.display import display, HTML

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
def show_dataframe(df):
    display(HTML(f"""
    <div style="height: 300px; overflow: auto; margin-bottom: 16px;">
        {df.to_html()}
    </div>
    """))


# Leer el archivo Excel
df = pd.read_excel("info_data.xlsx")

show_dataframe(df)
```

Elaboración propia.

Una vez entendida la estructura y consistencia de los datos, se procede con una fase de análisis para su preparación y limpieza. Usando diccionarios de variables para interpretar el significado y contexto de cada una de las variables, se ha decidido eliminar las siguientes, considerando que no aportan relevancia práctica o lógica al modelo. Estas variables son:

-   **id**: es un identificador único del crédito, por lo que no proporciona información adicional útil para el modelo.

-   **member_id**: al ser un identificador único del prestatario, tampoco añade valor informativo al análisis.

-   **url**: es un enlace único que no aporta información relevante para el modelo.

-   **desc**: es una descripción de las razones para solicitar el préstamo. Aunque podría contener información útil, su análisis requeriría técnicas de procesamiento de texto, lo cual está fuera del alcance inmediato.

-   **title**: representa el título del préstamo proporcionado por el prestatario. Debido a su alta diversidad y el gran número de categorías, no se considera relevante para este análisis.

-   **recoveries**: indica la cantidad de dinero recuperado en caso de incumplimiento (default). Al estar relacionada con eventos posteriores al interés del modelo, no puede ser una covariable válida y además proporcionaría información determinística, lo que no es deseable.

-   **collection_recovery_fee**, **out_prncp** y **out_prncp_inv** al igual que la variable anterior, no se incluye por estar causada por eventos posteriores al interés del modelo.

-   Las variables **next_pymnt_d**, **last_pymnt_d**, **earliest_cr_line**, **issue_d** y **last_credit_pull_d** corresponden a fechas registradas durante el proceso del préstamo. Dado que estas variables representan información recolectada después de la aprobación del préstamo, no se consideran relevantes para el análisis y pueden ser descartadas.

-   Debido a la relación directa entre **grade** y **subgrade**, se opta por descartar **grade** y conservar **subgrade**, ya que esta última proporciona un nivel de detalle mayor y, por lo tanto, más información relevante para el análisis.

-   **Depuración de variables**: Adicionalmente, debido a la gran cantidad de variables con valores faltantes, se decidió eliminar aquellas que presentan más del 75% de datos faltantes. Con un porcentaje tan elevado, no es óptimo realizar imputaciones u otros procedimientos de recuperación de datos.

### Análisis Visual y Tratamiento de NAs

En esta fase se van a explorar las distribuciones y relaciones de los datos para detectar posibles problemas de los datos y necesidades de transformación, como podrá observarse a continuación en la Figura 2:

-   Se analizará la distribución de las variables, evaluando si requieren transformaciones, como normalización o estandarización.
-   Se tratarán los valores faltantes restantes mediante técnicas de imputación que se ajusten al contexto de las variables.

**Figura 2.**

*Análisis completo del conjunto de datos.*

```{python}
from IPython.core.display import HTML

# Cargar el archivo HTML
with open("sweetviz_report.html", "r", encoding="utf-8") as file:
    html_content = file.read()

# Mostrar el HTML en el notebook

display(HTML(f"""
<div style="
    height: 500px;
    overflow: auto;
    margin: 0 auto; /* Centrar horizontalmente si es más estrecho */
    margin-bottom: 16px;
">
    {html_content}
</div>
"""))
```

Elaboración propia.

Dicho análisis proporciona información adicional sobre el comportamiento de las variables por una parte se obreva que hay ciertas variables que se pueden omitir.

-   **policy_code:** Esta variable tiene un valor constante, lo que significa que no contribuye con variabilidad ni información al modelo.
-   **pyment_plan:** Esta variable solo tiene 2 niveles y uno de ellos tiene muy pocas observaciones, por lo que esta variable no daría mucha información al modelo.
-   **emp_title:** Esta variable puede ser descartada debido a la alta cantidad de categorías que presenta, lo que dificulta su utilidad y análisis en el modelo.
-   **zip_code:** Se descarta por la gran cantidad de niveles

En general, las variables obtenidas presentan un balance adecuado. Sin embargo, es necesario imputar los valores faltantes de las siguientes variables: **emp_length, mths_since_last_delinq, revol_util, collections_12_mths_ex_med, tot_coll_amt, tot_cur_bal** y **total_rev_hi_lim**.

Una vez completada la imputación, en las etapas siguientes se realizará una transformación de las variables numéricas para corregir el sesgo observado, mejorando así su distribución. Posteriormente, se aplicará un escalamiento a las variables numéricas y una codificación a las variables categóricas, preparando los datos para el modelado.

### Modelo de Redes Neuronales Artificiales

Las redes neuronales artificiales son modelos computacionales agrupados dentro del *machine learning*, con los cuales se busca simular el comportamiento del cerebro humano, de acuerdo con @unirrna2021 y @ibmrna2025. Su funcionamiento imita el procedimiento con el que trabajan en conjunto las neuronas biológicas para aprender de la información que reciben desde el exterior o por parte de otras neuronas.

Gracias a su comportamiento, basado en la utilización de datos de entrenamiento para mejorar paulatinamente la precisión de sus resultados, las redes neuronales permiten la realización de tareas que no se podían automatizar en otro tipo de modelos, lo que ha llevado al desarrollo de avances significativos en el área de la inteligencia artificial e impactando de forma directa a las personas e industrias.

Considerando lo dicho anteriormente, es posible ver que las redes neuronales artificiales son una gran alternativa a la hora de enfrentar tareas relacionadas con el aprendizaje a partir de un conjunto de datos, encontrando patrones que puedan explicar el comportamiento de estos últimos respecto de alguna variable objetivo, con la finalidad de tomar una decisión después del entendimiento de dicho fenómeno. En este sentido, será utilizada una red neuronal para mejorar el resultado obtenido con el modelo de baja complejidad en el presente ejercicio.

#### Teorema de Aproximación Universal

Este teorema establece que:

"Cualquier función continua definida en un conjunto compacto puede ser aproximada arbitrariamente bien por una red neuronal feedforward con una sola capa oculta y un número suficiente de neuronas, utilizando funciones de activación no lineales"

Lo anterior significa que las funciones de activación no lineales son esenciales para que las redes neuronales puedan aproximar funciones complejas, como se puede observar en la Figura 3. Si bien el teorema garantiza que una sola capa oculta con suficientes neuronas puede aproximar cualquier función continua en un conjunto compacto, en la práctica, aumentar el número de capas suele ser más eficiente para modelar problemas complejos.

**Figura 3.**

*Comparación entre resultados obtenidos mediante funciones lineales y no lineales.* ![Funciones lineales vs funciones no lineales](no_linealidad.png) *Nota.* La gráfica muestra un comparativo entre los resultados obtenidos al aproximar una función a través de una función lineal y de una serie de funciones no lineales, observando que estas últimas permiten una aproximación mucho mejor en comparación con su contraparte lineal.

#### Arquitectura de una red neuronal artificial

Las redes neuronales están compuestas por un conjunto de nodos, que vendrían siendo las neuronas artificiales, repartidos en capas que pertenecen a alguna de las siguientes tres categorías, con información obtenida de @cloudflare y @paroledevs:

-   **Capa de entrada:** esta capa tiene conexión con el "mundo exterior" a la red neuronal artificial, recibiendo los datos iniciales que serán procesados por ella.

-   **Capa de salida:** esta capa proporciona el resultado del procesamiento realizado por la red neuronal, comúnmente como una predicción o una clasificación (lo cual se ve internamente en términos de probabilidad).

-   **Capas ocultas:** una o más capas que se encuentran entre las dos mencionadas anteriormente, realizando el procesamiento y extracción de características de los datos. Este análisis se realiza de menor a mayor profundidad, pues cada capa extrae los patrones más significativos de los datos que recibió como entrada y los envía a una capa superior para que sean vistos con más detalle.

Ahora bien, es conveniente conocer los elementos que componen a cada uno de los nodos que interactúan en las capas anteriormente mencionadas, pues de esta manera será posible comprender la importancia del correcto diseño de la arquitectura de una red neuronal artificial. De acuerdo con @franciscopalaciorna, estos elementos son:

**Entrada:** los datos que recibe la neurona artificial del exterior o de otras neuronas, se representa como un vector $x = (x_1, x_2, ..., x_n)$.

**Pesos sinápticos:** representan los factores de importancia $w_{ij}$ que se le asignan a las entradas que cada neurona recibió de su anterior compañera. Son valores numéricos que se modifican durante el entrenamiento del modelo y poseen una vital importancia en el desempeño de este mismo frente al conjunto de datos del que está aprendiendo.

**Regla de propagación:** una operación que se aplica de forma primordial a los datos de entrada y los pesos para calcular el posible valor de la salida de la neurona artificial; generalmente es una suma ponderada pero también pueden ser otras clases de operaciones.

**Función de activación capa de entrada:** el valor obtenido con la regla de propagación se procesa con a través de esta función, a fin de obtener el verdadero resultado de salida de la neurona. Existe una gran variedad de funciones que se eligen de acuerdo con el objetivo de entrenamiento de la red neuronal artificial, entre las cuales se encuentran las siguientes:

-   **Identidad:** la función identidad es una función lineal que devuelve el mismo valor de entrada como salida, como se observa en la Ecuación (1):

$$
 f(x) = x \tag{1} 
$$

-   **Escalón:** la función escalón devuelve un valor binario dependiendo de si la entrada supera un umbral $\theta$, según lo visto en la Ecuación (2):

$$ 
f(x) = 
\begin{cases} 
1 & \text{si } x \geq \theta \\ 
0 & \text{si } x < \theta 
\end{cases} \tag{2}
$$

-   **Lineal a tramos:** la función lineal a tramos aplica una transformación lineal dentro de un rango específico, de acuerdo con la Ecuación (3):

$$ f(x) = 
\begin{cases} 
0 & \text{si } x \leq 0 \\ 
x & \text{si } 0 < x \leq 1 \\ 
1 & \text{si } x > 1 
\end{cases} \tag{3}
$$

-   **Sigmoide:** la función sigmoide suaviza la salida en un rango entre 0 y 1, aplicando la expresión definida en la Ecuación (4):

$$ 
f(x) = \frac{1}{1 + e^{-x}} \tag{4}
$$

-   **Gaussiana** la función gaussiana calcula una salida basada en la forma de una campana, con media $\mu$ y desviación estándar $\sigma$, como se puede ver en la Ecuación (5):

$$ 
f(x) = e^{-\frac{(x - \mu)^2}{2\sigma^2}} \tag{5}
$$

-   **Sinusoidal:** la función sinusoidal genera una salida oscilatoria basada en una onda sinusoidal, es decir, la expresión dada en la Ecuación (6):

$$ 
f(x) = \sin(x) \tag{6}
$$

**Salida:** resultado $y_i$ del procedimiento aplicado sobre los datos de entrada.

**Función de activación capa de salida:**

-   **Softmax:** permite convertir un conjunto de valores en probabilidades que suman 1. Se encuentra definida en la Ecuación (6) y su principal uso se encuentra en problemas de clasificación multiclase.

$$
\text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}} \tag{6}
$$

-   **Cross-entropy:** mide la diferencia entre las predicciones $\hat{y_i}$ y la real $y$, para el caso de clasificación lo hace de la manera en que está definido en la Ecuación (7).

$$
\text{Cross-Entropy Loss} = - \sum_{i=1}^{n} y_i \log(\hat{y}_i) \tag{7}
$$

-   **Sparse Cross-Entropy Loss** es una variante de *Cross-Entropy* que no requiere codificación *one-hot*, sino que trabaja directamente con índices de las clases verdaderas, como se observa en la Ecuación (8).

$$
\text{Sparse Cross-Entropy Loss} = - \log(\hat{y}_{c}) \tag{8}
$$

-   **Focal loss:** es una extensión de *Cross-Entropy* que aplica un factor de penalización para enfocarse más en ejemplos mal clasificados, de acuerdo con la Ecuación (9). Es especialmente útil para casos de datasets desbalanceados.

$$
\text{Focal Loss} = - \alpha_t (1 - p_t)^\gamma \log(p_t) \tag{9}
$$

donde \$ p_t = \hat{y}\_c \$

#### Tipos de redes neuronales artificiales

Teniendo en cuenta las particularidades de la arquitectura de las redes neuronales artificiales, a continuación se detallan algunos tipos diferentes de modelos, clasificados según su diseño, así como sus correspondientes aplicaciones en diferentes campos de la academia y la industria.

-   **Redes neuronales artificiales perceptrón:** tienen la arquitectura más sencilla, compuesta por nodos con una única función de activación, suelen utilizarse para tareas de clasificación binaria.

-   **Redes neuronales artificiales multicapa:** su arquitectura está conformada por capas de neuronas artificiales interconectadas y son utilizadas para tareas más complejas como toma de decisiones y clasificación multiclase.

-   **Redes neuronales artificiales convolucionales:** estas redes están especialmente diseñadas para realizar tareas relacionadas con el reconocimiento de imágenes, pues utilizan filtros convolucionales para identificar patrones y características especiales en cada pixel.

-   **Redes neuronales artificiales recurrentes:** suelen ser empleadas para tareas como reconocimiento de voz, traducción automática y generación de texto por su capacidad para procesar datos secuenciales, donde toda la información está relacionada entre sí y posee un contexto común para explicarse.

#### Aplicaciones de las redes neuronales artificiales

Algunas de las aplicaciones de las redes neuronales en la actualidad incluyen las siguientes:

-   **Reconocimiento de imágenes:** las redes neuronales pueden ser utilizadas para identificar personas y objetos en imágenes y videos.
-   **Procesamiento del lenguaje natural:** las redes neuronales pueden utilizarse en tareas de comprensión del lenguaje como la traducción automática, la generación de texto y el reconocimiento de voz.
-   **Toma de decisiones:** las redes neuronales pueden ser herramientas de ayuda para la toma de decisiones en situaciones complejas tales como el análisis financiero, que es el caso del presente ejercicio y el diagnóstico médico, entre otras.
-   **Sistemas de recomendación:** las redes neuronales pueden ser empleadas para generar recomendaciones personalizadas con base en las preferencias del usuario en diferentes plataformas de streaming, comercio electrónico y redes sociales. @profedigital

## Construcción del Modelo de Aprendizaje Automático

Como podrá observarse detalladamente más adelante, la conexión entre las diferentes neuronas artificiales permite el aprendizaje de patrones complejos. El video presentado en la Figura 4 es una representación artística de este planteamiento.

**Figura 4.**

*Conexión entre las neuronas del modelo.* {{< video video.mp4 >}} Tomado de Sora OpenAI.

### Preprocesamiento

Después de haber jugado con el dataset en la sección anterior para los análisis descriptivos y exploratorios, se continúa con la realización del preprocesamiento de los datos, necesario para que la arquitectura de la red neuronal sea capaz de recibirlos y además ayudar a mejorar su rendimiento. Como primer paso, se dividió el conjunto de datos en entrenamiento, validación y prueba para evitar cualquier tipo de *data leakage* durante el preprocesamiento.

#### Codificación de variables categóricas

En total se emplearán tres estrategias para la clasificación de las variables categóricas según su naturaleza.

1.  Ordinal Encoder: esta técnica se aplicó cuando las variables categóricas presentaban un orden natural. La codificación numérica asignada reflejaba este orden, asegurando que los valores fueran representativos de su jerarquía inherente.

2.  Label Encoder: se empleó en variables categóricas binarias. Este enfoque evitó imponer un orden ficticio entre los valores, lo que podría generar sesgos al interpretar una relación inexistente entre las categorías.

3.  One Hot Encoding: Diseñada para variables categóricas sin un orden natural y con más de dos niveles. Cada categoría fue representada mediante un vector binario, donde un valor de 1 indica pertenencia a una categoría específica y e asigna 0 a las demás. Se prestó especial atención al número de niveles en cada variable. En casos con muchas categorías, esta técnica podría haber generado una matriz de alta dimensionalidad, aumentando los requerimientos computacionales y complicando el entrenamiento de la red neuronal. Para evitar estos problemas, se evaluó cuidadosamente la viabilidad de aplicar este método en cada caso.

#### Selección de características

La técnica de imputación de datos faltantes elegidas fue **Iterative Imputer** para las variables numéricas, debido a que muestra mejores capacidades en manejar relaciones complejas que otros métodos de imputación como lo son la media o similares, gracias a que considera todo el dataset de manera conjunta en lugar de una sola columna. Para el caso de las variables catgóricas, se utilizó la imputación mediante mediana.

#### Estandarización

Fue utilizado el método **StandardScaler**, considerando que normaliza las características al cnetrar su media en 0 y escalando según la desviación estándar, lo cual es crucial en redes neuronales para garantizar estabilidad numérica y mejorar la eficiencia del entrenamiento.

Esto previene problemas como:

-   **Gradiente explosivo**: valores extremos en las entradas producen gradientes excesivamente grandes, causando desbordamientos numéricos y actualizaciones erráticas de pesos.
-   **Gradiente desvaneciente**: gradientes extremadamente pequeños ralentizan la convergencia, dificultando el aprendizaje efectivo.

La fórmula utilizada por este método de escalamiento puede observarse en la Ecuación (10):

$$
X' = \frac{X - \mu}{\sigma} \tag{10}
$$

donde

-   $X$: Valor original.
-   $u$: Media de los datos.
-   $sigma$: Desviación estándar de los datos.

Este método asegura que las características tengan una varianza de 1 y estén centradas en 0, permitiendo que funciones de activación como **sigmoid** y **tanh** operen eficientemente.

#### Balanceo de clases

El análisis descriptivo mostró que la variable respuesta del dataset está altamente desbalanceada, lo cual representa un reto significativo al crear el modelo. Un modelo entrenado en estas condiciones puede tender a predecir únicamente la clase mayoritaria, generando métricas como el *accuracy* con valores engañosamente altos, pero sin reflejar una verdadera capacidad predictiva. Para abordar este problema, se emplearán las siguientes técnicas:

-   **Sobremuestreo y Submuestreo**: esta estrategia, ilustrada en la Figura 5, combina el aumento de las clases minoritarias mediante sobremuestreo con la estrategia SMOTE (generando muestras ficticias a partir de la información proporcionada) y la reducción de las clases mayoritarias mediante submuestreo. El objetivo es equilibrar la cantidad de datos entre las clases, incentivando al modelo a aprender las características de todas las clases y mejorando sus métricas al minimizar la función de pérdida. Como se mencionará más adelante, emplear un balance perfecto entre todas las clases no representó una ventaja en términos del desempeño del modelo (dada la naturaleza del conjunto de datos analizado), por lo tanto se optó por la escogencia de clases con pesos que representaran correctamente su importancia en el proceso de entrenamiento del modelo de redes neuronales artificiales. 

**Figura 5.**

*Ilustración del funcionamiento de las técnicas de sobremuestreo y submuestreo.* ![Ilustración del funcionamiento de las técnicas de sobremuestreo y submuestreo](muestreo.png)

Tomado de *Handling imbalanced dataset in supervised learning using family of SMOTE algorithm*, por RohitWalimbe, 2017 (https://www.datasciencecentral.com/handling-imbalanced-data-sets-in-supervised-learning-using-family)

-   **Agrupamiento de las clases**: en esta estrategia se agruparon algunas de las clases con una menor cantidad de datos, teniendo en cuenta que, como se verá más adelante, son clases que tienen tan pocos datos que predecirlas es altamente complejo; esto pone en evidencia las limitaciones de las técnicas de sobremuestreo y submuestreo en la presencia de clases altamente desbalanceadas.

### Diseño y Arquitectura

Todo lo descrito a continuación fue implementado mediante Tensorflow.

#### Modelo simple

Este es el modelo que utilzaremos como referencia, este reflejará los resultados que se obtienen, no solo al utilizar una arquitectura bastante sencilla del modelo, sino además no realizar un proceso de ingeniería de características, es entonces esperado un mal rendimiento en este modelo al tener malas prácticas dentro del mismo.

##### Evaluación del modelo

Utilizaremos la métrica más simple posible, que es la que toma Tensorflow por defecto, el accuracy.

**Función de pérdida**

La función de pérdida a elegir, es sparse categorical cross entropy, la cual esta pensada para problemas de clasificación multiclase donde la variable esta codificada mediante Ordinal o Label Encoder, no mediante One Hot Encoding (para este caso usar sparse cross entropy).

##### Capas

1.  **Capa de entrada.**

    La capa de entrada está definida para recibir un número de características igual a la dimensión de los datos en el conjunto balanceado.

2.  **Primera Capa Oculta.**

    Contiene 32 neuronas con activación ReLU, lo que permite que el modelo aprenda patrones no lineales en los datos. Además se agrego regularización $L_2$ para evitar el sobreajuste, y un dropout del 20% para reducir la posibilidad de sobreajuste.

3.  **Capa de Salida.**

    La capa de salida contiene tantas neuronas como clases en el problema, se utiliza la función de activación softmax para convertir las salidas en probabilidades.

##### Resultados del modelo de baja complejidad

**Evolución de las métricas**

Es posible notar en la Figura 6 que, durante el entrenamiento, el modelo tiene una función de pérdida muy alta y una precisión que, en vez de incrementar, va disminuyendo en los datos de validación a pesar de que empieza en un valor muy alto. Los motivos por los cuales sucede esto serán abordados más adelante de una manera específica.

**Figura 6.**

*Evolución de las métricas del modelo a través de las épocas durante el proceso de entrenamiento.* ![Evolución de las métricas del modelo a través de las épocas durante el proceso de entrenamiento.](metricas_baja.png) Elaboración propia.

**Reporte de clasificación**

**Matriz de confusión**

De acuerdo con la matriz de confusión observada en la Figura 7, se pueden notar ciertas dificultades para predecir clases como *Fully Paid*. Sin embargo, el modelo predice bien clases como *Charged Off* y *Current*.

**Figura 7.**

*Matriz de confusión del modelo de baja complejidad.* ![Matriz de confusón del modelo de baja complejidad.](matriz_de_confusion_baja.png) Elaboración propia.

#### Modelo con mayor complejidad

##### Ingeniería de características

Durante la fase de diseño del modelo de mayor complejidad, se consideró conveniente emplear una estrategia de ingeniería de características enfocada en los siguientes aspectos, con el objetivo de mejorar los resultados obtenidos en el modelo anterior:

-   En primer lugar, se procuró utilizar variables cuya consecución o interpretación no esté sujeta a eventos posteriores a la aprobación del crédito. Sin embargo, esto puede hacer que el modelo pierda capacidad para identificar las características relevantes de cada una de las clases, pues algunos de los aspectos más importantes del comportamiento de pago de los prestarios solo podrán saberse después de que se se haya iniciado el proceso de aprobación de los productos financieros solicitados.

-   Por otra parte, se empleó un **árbol de decisión** para seleccionar las características que tuvieran un impacto más significativo en los resultados proporcionados por el modelo, mejorando el proceso de escogencia de variables adecuadas para este caso.

##### Evaluación del modelo

Con el fin de evaluar los resultados del modelo de una forma más equitativa, se seleccionaron las siguientes métricas como marco de referencia para la evaluación del comportamiento del modelo de redes neuronales artificiales, asegurándose de no favorecer especialmente a la clase mayoritaria en comparación con las demás:

-   **F1-Score Macro**: a diferencia de métricas como el **accuracy**, que tienden a favorecer la clase mayoritaria en datasets desbalanceados, el **F1-Score Macro** asigna igual importancia a todas las clases, independientemente del número de muestras. Esto brinda una evaluación más realista del desempeño del modelo.

##### Función de pérdida

Para abordar el desbalance de clases durante el entrenamiento, utilizaremos técnicas como:

-   **Focal Loss:** esta función de pérdida está diseñada específicamente para problemas de clasificación desbalanceados. Su objetivo es priorizar las clases minoritarias al reducir la importancia de las predicciones correctamente clasificadas para las clases mayoritarias. Esto ayuda al modelo a concentrarse más en aprender las características de las clases menos representadas.

##### Callbacks

-   **Reduce Learning Rate on Plateu:** ayuda a mantener la capacidad de mejora durante el entrenamiento, los cálculos del gradiente, que dependen de la tasa de aprendizaje pueden no ser capaces de llegar al mínimo de la función de pérdida, por lo que este callback reduce la tasa de entrenamiento si para una cantidad de Epochs dada, no ha habida una mejoría en los resultados, esto permite tener un aprendizaje con capacidad de mejoría a través de las Epochs.

##### Capas

Las capas definidas en el modelo fueron las siguiente:

1.  **Capa de Entrada**

    Define el tamaño de entrada, el cual corresponde al número de características del dataset ya balanceado. Esta capa recibe los datos y los prepara para su procesamiento en las siguientes capas.

2.  **Primera Capa Oculta**

    Contiene **256 neuronas** con activación **ReLU**, lo que permite capturar relaciones no lineales en los datos.\
    Se aplica **Batch Normalization** para estabilizar el entrenamiento y acelerar la convergencia.\
    Se incorpora un **Dropout del 30%** para reducir el sobreajuste regularizando la activación de las neuronas.

3.  **Segunda Capa Oculta**

    La cantidad de neuronas se reduce a **128**, lo que permite refinar la representación aprendida por la red. Por otra parte, se mantiene la activación **ReLU** y se aplica un **Batch Normalization** y **Dropout del 20%** para evitar el sobreajuste.

4.  **Tercera Capa Oculta**

    Finalmente, se reduce la dimensionalidad a un total de **64  neuronas** para extraer patrones más específicos.\
    Se mantiene la combinación de anterior de funciones de activación, **Batch Normalization** y **Dropout** para asegurar un entrenamiento estable.

5.  **Capa de Salida**

    Contiene **una neurona por cada clase del problema de clasificación multiclase**.\
    Utiliza **Softmax** como función de activación, lo que convierte las salidas en probabilidades normalizadas, asegurando que la suma de las probabilidades sea igual a 1.

##### Resultados del modelo

**Evolución de las métricas**

En la Figura 8 se puede evidenciar cómo la función de pérdida va disminuyendo a lo largo de las épocas, con lo cual se va obteniendo un *accuracy* mucho más alto.

**Figura 8.**

*Evolución de las métricas obtenidas por el modelo a través de las épocas.* 

![Evolución de las métricas obtenidas por el modelo a través de las épocas](metricas_final.png)Elaboración propia.

En este sentido, se ha de observar que los resultados en el entrenamiento son muy estables mostrando una convergencia, además de que las fluctuaciones observadas en los datos de validación son mucho menores que los obtenidos anteriormente, siendo esta una mejora frente a los últimos resultados que fueron evaluados.

#### **Resultados de clasificación**

**F1-score macro:** 0.64

**Recall macro:** 0.74

**Matriz de confusión**

En adición a las métricas obtenidas para el modelo de redes neuronales artificiales, en la Figura 9 se observan cuántos datos de cada clase fueron clasificados correctamente en la diagonal principal de la matriz de confusión.

**Figura 9.**

*Matriz de confusión obtenida al evaluar el conjunto de prueba en el modelo.* 

![Matriz de confusión obtenida al evaluar el conjunto de prueba en el modelo.](matriz_de_confusion.png)Elaboración propia.

En consideración con los resultados mostrados anteriormente, se pudo reducir visiblemente la confusión entre las clases **Late** y **Current**, sin embargo, las predicciones erróneas en este caso pueden ser explicadas a la luz de la no consideración de variables prospectivas en la arquitectura del modelo, las cuales permitirían diferenciar ambas categorías de una mejor forma.

## Conclusiones y aprendizajes a partir de los modelos

En este punto, se pone en evidencia la dificultad de considerar este problema sin variables prospectivas que puedan brindar información acerca de los eventos futuros relacionados al comportamiento de pago por parte de los prestatarios hacia la entidad financiera. Sin embargo, se considera que los resultados obtenidos son satisfactorios es términos de las limitaciones presentadas y sus implicaciones en el desarrollo de un modelo de redes neuronales artificiales. Por lo tanto, se plantea como una posible mejora hacia el futuro la utilización de un conjunto de datos distinto, que contenga otro tipo de variables explicativas de cada clase (o una definición de clases que pueda ser obtenida a partir de un conjunto de variables no prospectivas).

## Puesta en producción del modelo

Debido a la naturaleza del proyecto, tareas como lo son la monitoría del modelo se dejan como futuras mejorías, nos centraremos específicamente en dos.

### Creación de la API

Se utilizó el framework de Python llamado FastAPI @fastapi para convertir el modelo en una API que pudiera realizar predicciones de acuerdo con la información de cada usuario. En el repositorio de GitHub se encuentra el archivo con el código necesario para lograr este resultado.

### Despliegue del modelo

Adicionalmente, se empleó Render como servicio de computación en la nube para desplegar el modelo. Esta plataforma fue elegida por su simplicidad para realizar la tarea además de la posibilidad que brinda de utilizar recursos gratuitos.

Para observar el resultado se pueden consultar los siguientes archivos, necesarios para el despliegue en el repositorio desde donde se realizó dicha actividad: <ins>[Repositorio despliegue del modelo](https://github.com/RNA-y-Algo-Bioinsp-2024-02/model_credit_risk)</ins>.

-   **Dockerfile:** describe como construir la imagen de tal manera que contenga todas las dependencias necesarias define el puerto de ejecución de la API.

-   **requirements.txt:** contiene los nombres y las versiones de todos los paquetes necesarios para ejecutar la API.

-   **app.py:** archivo con la API creada utilizando FastAPI que define los parámetros necesarios para llamar la API y obtener predicciones con el modelo entrenado.

Además se agregó un workflow con GitHub Actions para automatizar el despliegue del modelo a la última versión en Render, lo cual es el inicio del monitoreo necesario para el modelo como un agregado que se puede profundizar más en el futuro.

## Caso de uso

A continuación se desarrollará un caso de uso que ejemplifica cómo el uso del modelo desplegado anteriormente a través de una aplicación web puede traer beneficios a las entidades bancarias en los procesos de toma de decisiones, así como darle una mayor claridad a los usuarios de estos servicios, en términos de cononocer los motivos por los cuales se toman ciertas decisiones respecto a sus préstamos o productos bancarios (como puede ser la venta de cartera o similares).

De acuerdo con el @cooperativasdefinicion, en Colombia se encuentran reglamentadas el conjunto de "empresas asociativas sin ánimo de lucro en las cuales los trabajadores o los usuarios, según el caso, son simultáneamente los aportantes y los gestores de la Empresa", bajo el nombre de cooperativas. Estas entidades son reguladas por la Superintendencia de la Economía Solidaria **Supersolidaria** o por la Superintendencia Financiera de Colombia **Superfinanciera** y tienen como objetivo la distribución o producción de bienes o servicios que satisfagan las necesidades de sus asociados, de manera colaborativa y eficiente. De la misma manera, las cooperativas tienen facultades legales para asociarse entre sí en miras al cumplimiento de sus propósitos económicos y sociales de una mejor manera.

Ahora bien, la ley colombiana regula las actividades financieras de las cooperativas de la siguiente manera, según @supersolidaria:

-   Las **cooperativas financieras** como organismos cooperativos que tienen como función principal la realización de actividades financieras, se consideran establecimientos de crédito y pueden solicitar autorización de la Superfinanciera para ofrecer sus servicios a terceros no asociados a la cooperativa.

-   Las **cooperativas de ahorro y crédito** como organismos cooperativos que tienen la función principal de adelantar actividades financieras con sus asociados de forma única. A su vez, deben solicitar autorización de la Supersolidaria para la prestación de sus servicios.

Teniendo en cuenta lo anterior, al hacer énfasis en la actividad ejercida por las cooperativas financieras, es posible observar que dichas entidades deben tener una especial importancia en la correcta gestión del riesgo de crédito, pues de esto depende en gran medida su capacidad para continuar prestando sus servicios a sus asociados o terceros que así lo necesiten. Por lo tanto, este caso de uso obedece a la situación en que una cooperativa financiera necesite evaluar cuál sería la decisión adecuada con respecto al crédito solicitado por un tercero no asociado, considerando las variables que interactúan en el problema y se muestran en la Tabla 2.

**Tabla 2.**

*Información del perfil de crédito a analizar en el caso de estudio.*

| **Variable**                                | **Valor**          | **Descripción**                                                                                   |
|---------------------------------------------|--------------------|---------------------------------------------------------------------------------------------------|
| **Pago Mensual propusto**                            | $4500           | Es el máximo pago mensual que estaría dispuesto a pagar el prestatario si se aprueba el préstamo solicitado.                     |
| **Pago Mensual**         | $200        | Es el monto estimado del pago mensual que debe hacer el prestatario si se aprueba el préstamo solicitado.                                   |
| **Monto Financiado por Inversionistas**| $4500         | Cantidad total del préstamo que será financiada específicamente por inversionistas en el momento de otorgarse el préstamo.                    |
| **Monto Total Financiado**                      | $5000         | Monto total que podría ser comprometido al momento de aprobar el crédito, el cual puede coincidir o ser inferior al monto solicitado.                                                  |
| **Tasa de Interés**                    | 9.5%           | Tasa de interés del Banco de la República en el momento de la solicitud.                                                   |
| **Monto Original del Préstamo**                    | $5000          | Monto original solicitado por el prestatario para el préstamo; si la entidad crediticia lo ajusta a la baja, esto se refleja aquí.                                                  |
| **Monto Histórico de Cobro**                    | $1000          | Suma total histórica de montos que alguna vez estuvieron en estado de cobranza por incumplimiento del prestatario.                                                |
| **Saldo Total Actual**                    | $15000          | Saldo actual combinado de todas las cuentas activas del prestatario (incluye tanto crédito rotativo como crédito en cuotas).                                               |
| **Límite Total de Crédito Rotativo**                    | $20000          | El límite máximo combinado otorgado al prestatario para todas sus líneas de crédito rotativo.                                         |
| **Relación Deuda-Ingresos**                    | 35.2%           | Relación entre los pagos mensuales totales de deuda del prestatario (excluyendo hipotecas y el préstamo actual solicitado) dividido por su ingreso mensual autodeclarado.                                               |
| **Saldo Total de Crédito Rotativo**                    | $5000           | Monto total actual que el prestatario tiene como saldo pendiente en créditos rotativos (como tarjetas de crédito).solicitud.                                                   |
| **Línea de Crédito Rotativo**                    | 75%           | Porcentaje del crédito rotativo disponible que está actualmente en uso por parte del prestatario.                                                |
| **Calificación de Préstamo**                    | B3           | Subcalificación asignada por la entidad crediticia al último préstamo solicitado por el prestatario que fue aprobado.                                               |

Dados estos datos, es posible observar que la respuesta por parte del modelo desplegado será que el prestatario muestra un **riesgo crediticio bajo**, por lo cual es considerado un buen candidato para la aprobación de futuros préstamos, pues ha presentado un comportamiento de pago adecuado a nivel histórico y su capacidad de pago está demostrada al momento de realizar la solicitud que está siendo evaluada actualmente.

# Aplicación web

Como se mencionó anteriormente, el modelo de redes neuronales artificiales fue desplegado en una aplicación web titulada *CrediMetric* que podrá ser accedida en el siguiente enlace: <ins>[CrediMetric](https://front-credit-risk.onrender.com/)</ins>.

Esta aplicación web cuenta con una funcionalidad que permitirá a las entidades financieras evaluar los perfiles de crédito de los casos en los que necesitan evaluar una decisión especial, además de permitir que los prestatarios también puedan conocer su perfil de riesgo de crédito de una manera más completa y descriptiva.

# Video publicitario

De manera adicional a los resultados anteriormente obtenidos, se presentan los siguientes recursos audiovisuales como material complementario al desarrollo del presente ejercicio mostrando la forma en que la herramienta web puede ser utilizada y los diferentes contextos en los que su uso puede resultar beneficioso para las entidades financieras y las personas naturales:

- Lista de reproducción de los contenidos complementarios: <ins>[Redes Neuronales y Algoritmos Bioinspirados \| CrediMetric](https://www.youtube.com/playlist?list=PL6M0kvPyv0EbZ4FTTQHGzsTv5Yri6RmOQ)</ins>

## Contribuciones individuales

Las contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo de los ejercicios correspondientes a **Modelos de riesgo de crédito con Redes Neuronales Artificiales** se muestran en el siguiente video.

{{< video https://youtu.be/3H1xWTNLn0g >}}

# Correcciones implementadas sobre la primera versión del informe

A partir de esta sección, el presente informe presenta un desarrollo actualizado basado en una serie de mejoras y ajustes implementados tras una evaluación detallada del trabajo realizado. A continuación, se ofrece una visión general de los cambios incorporados, permitiendo apreciar de manera clara la mejora alcanzada en cada caso.

## Modelado y evaluación de desempeño

Con el objetivo de abordar las correcciones identificadas en relación con el desempeño del modelo de redes neuronales artificiales en la clasificación de las categorías del riesgo de crédito, especialmente la confusión entre las clases **Late** y **Current**, así como la baja representación de **In Progress**, se implementaron las siguientes mejoras en el procesamiento de datos, el balanceo de clases y la calibración del modelo:

### Balanceo de clases: 

Considerando el desbalance de los datos y la predominancia de las clases **Current** Y **Fully paid**, se implementó una estrategia combinada de submuestreo y sobremuestreo para balancear la cantidad de muestras en el conjunto de datos de entrenamiento (como se especificará más adelante). Por medio de esta estrategia, se logró que el modelo distinguiera mejor los casos de **Late**, aunque la mejora en ¨*recall* y *f1-score* para esta categoría fue limitada debido a la naturaleza de las variables disponibles.

### Uso exclusivo de variables no prospectivas

Respondiendo a la corrección realizada en este sentido, el modelo de redes neuronales entrenado solamente contó con variables *no prospectivas*, es decir, aquellas que están disponibles antes de la aprobación del crédito y que no dependen del comportamiento posterior del cliente o de las condiciones finalmente definidas por la entidad financiera. Debido a esto, se presentaron ciertas limitaciones en la capacidad del modelo para identificar correctamente clases como **Late** e **In Progress**, puesto que la mayor cantidad de información relacionada con el retraso en los pagos o el desarrollo de un crédito en progreso solamente se puede encontrar en variables que tendrán sentido una vez se aprueba el crédito. 

Adicionalmente, es necesario considerar que un mismo crédito puede estar en diferentes clases (como por ejemplo **Late**, **Current** e **In progress**) en diferentes momentos del tiempo y esto no puede detectarse sino con la utilziación de variables prospectivas, por lo que conseguir una mejor predicción para estas clases sigue siendo un reto que debe ser abordado con estrategias diferentes a las planteadas en el presente ejercicio.

### Evalución y otros ajustes

En concordancia con las estrategias mencionadas anteriormente, también se hizo un proceso más exhaustivo de ingeniería de características, seleccionando por medio de un **árbol de decisión** aquellas variables no prospectivas que representaban una mayor importancia en el proceso de entrenamiento del modelo. Asimismo, se probaron varias configuraciones de pesos para las categorías analizadas en el problema de clasificación, esperando obtener la mejor representación posible de las clases minoritarias; de esta manera se redujo parcialmente la confusión entre **Late** y **Current** dentro de las limitaciones ocasionadas por las variables no prospectivas.

## Balanceo de clases en el entrenamiento

Teniendo en cuenta lo dicho anteriormente, se realizó una nueva estrategia de balanceo de clases en el entrenamiento del modelo de redes neuronales, considerando que en el conjunto de datos original, las clases **Current** y **Fully paid** tenían un número de registros considerablemente mayor en comparación con las clases **Charged off**, **Late** e **In progress**. En este sentido, es importante mencionar que la estrategia de balanceo utilizada implementó una combinación de submuestreo aleatorio *RandomUnderSampler* y sobremuestreo con *SMOTE*. A continuación se describe con mayor detalle el enfoque de balanceo utilizado:

1.  **Submuestreo aleatorio:** Esta estrategia ayuda a reducir la cantidad de muestras de las clases mayoritarias para evitar que dominen el entrenamiento del modelo, ayudando a prevenir el sesgo del modelo hacia las clases **Current** y **Fully paid**. Sin embargo, se procuró no eliminar una cantidad sustancial de datos, pues podría ocasionar el efecto contrario y perder información importante para la predicción de dichas categorías.

2.  **Sobremuestreo con SMOTE:** Por medio de este proceso se generaron nuevas muestras sintéticas para las clases minoritarias, en vez de duplicar registros existentes en el conjunto de datos original. Gracias a esto, el modelo pudo aprender patrones más diversos en las clases **Charged off**, **Late** e **In progress**, ayudando a reducir el riesgo de sobreajuste en el modelo.

Sin embargo, es posible notar que no se buscó utilizar un enfoque que balanceara perfectamente el conjunto de datos, haciendo que todas las clases tuviesen el mismo número de muestras en el entrenamiento del modelo de redes neuronales. Esto sucedió debido a que se identificaron varias dificultades a la hora de entrenar un modelo que cumpliera con dicha característica, entre las cuales se encuentran las siguientes:

-   El submuestreo llegó a eliminar una gran cantidad de información de las clases mayoritarias, de manera que el modelo - posiblemente - perdió información importante para realizar predicciones correctas en estas clases y no mejoró en su desempeño global, que era lo que se esperaba.

-   Cuando se siguió una estrategia de sobremuestreo para equiparar la cantidad de registros en las clases minoritarias con las mayoritarias, posiblemente los datos (artificiales o duplicados) que se generaron no representaron de manera realisra la distribución real de estas clases, generando un sobreajuste en el modelo e impidiendo una correcta generalización en los datos de validación y prueba.

Finalmente, se llegó a la conclusión de que el enfoque de balanceo de clases utilizado fue el más conveniente de acuerdo con la naturaleza del conjunto de datos analizado, mejorando los resultados que se habían obtenido con anterioridad y utilizando solamente las variables **no prospectivas**, según se mencionó en el ítem anterior.

## Aplicación web

De acuerdo con las correcciones sugeridas, se verificó que la herramienta web <ins>[CrediMetric](https://front-credit-risk.onrender.com/)</ins> implementara correctamente el modelo de redes neuronales desarrollado y corregido en el presente ejercicio, brindando predicciones de acuerdo a la información proporcionada y manejando adecuadamente los errores que pudieran encontrarse en el flujo de ejecución de la herramienta. 

## Presentación y material complementario

Para finalizar, se realizó un énfasis especial en la generación de material complementario que fuera pertinente para comprender de una mejor manera la utilización de los productos obtenidos durante la realización del presente trabajo (es decir, el modelo de redes neuronales artificiales y el sitio web). Por lo tanto, en concordancia con la sugerencia presentada, se grabó y publicó un video tutorial de la aplicación web *CrediMetric* el cual puede encontrarse en la lista de reproducción mencionada en una sección anterior de este reporte, con el objetivo de brindar un mayor entendimiento con respecto a la utilización de dicha herramienta y los posibles casos de uso en que puede ser aplicada. 
