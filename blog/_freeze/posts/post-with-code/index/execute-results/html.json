{
  "hash": "40b4772fb2a9f73a166f951bc864849f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Métodos de optimización heurística\"\nformat: \n  html:\n    fig-width: 8      # Ancho de las figuras en pulgadas para HTML\n    fig-height: 6     # Alto de las figuras en pulgadas para HTML\n    number-sections: true\nauthor:\n  - name: \"Julián Castaño Pineda\"\n  - name: \"Luis Andrés Altamar Romero\"\n  - name: \"Catalina Restrepo Salgado\"\n  - name: \"Tomás Rodríguez Taborda\"\ndate: \"2024-11-15\"\ncategories: [optimización, métodos heurísticos, python]\nimage: \"image.jpg\"\nbibliography: ref.bib\n---\n\n::: {#5e0e8fb9 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport io\nfrom PIL import Image\n```\n:::\n\n\nEl objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.\n\nAl final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas.\n\n# Funciones a optimizar\n\nSe seleccionaron seis funciones comúnmente empleadas para evaluar métodos de optimización, debido a sus características particulares. Estas funciones presentan desafíos como la existencia de un mínimo global acompañado de múltiples mínimos locales, así como valles que pueden dificultar la convergencia de los algoritmos. A continuación, se describen dichas funciones, incluyendo su forma funcional generalizada para $d$ dimensiones, su representación gráfica en 2 dimensiones, el valor del mínimo global, una breve descripción de cada función y el rango de evaluación sugerido por diversos autores. Las gráficas fueron generadas a partir de la funcion `plot_function()` que se muestra en la pestaña de `Code` sugerida.\n\n::: {#a5e40ee0 .cell execution_count=2}\n``` {.python .cell-code}\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None, elev=30, azim=45 ):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(np.array([X1,X2]))\n\n    fig = plt.figure(figsize=(8, 4))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    ax1.view_init(elev=elev, azim=azim)\n\n    if x1_point is not None and x2_point is not None:\n        z_point = f(np.array([x1_point, x2_point])[:, None, None])[0, 0]\n\n        ax1.plot([x1_point], [x2_point], [z_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n        ax1.legend()\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, levels = 10)\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.plot([x1_point], [x2_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n        ax2.legend()\n\n    plt.show()\n```\n:::\n\n\n::: panel-tabset\n## Función de Rosenbrock\n\n$$f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]$$\n\n::: {#1195acf7 .cell height='auto' width='100%' execution_count=3}\n``` {.python .cell-code}\n# Función de Rosenbrock\ndef rosenbrock(x, a=1, b=100):\n    \"\"\"\n    Calcula el valor de la función de Rosenbrock.\n    x: vector de entrada (numpy array)\n    a, b: parámetros de la función\n    \"\"\"\n    return (sum(b * (x[1:] - x[:-1]**2)**2 + (x[:-1] - a)**2))\n\nplot_function(rosenbrock, x1_range=(-2.048, 2.048), x2_range=(-2.048, 2.048), title=\"Función Rosenbrock\", x1_point=1, x2_point=1)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=661 height=376}\n:::\n:::\n\n\nEn 2 dimensiones se puede definir como $$ f(x_1, x_2) = (a - x_1)^2 + b(x_2 - x_1^2)^2 $$\n\nLa Función de Rosenbrock, también conocida como función del valle o del plátano, es ampliamente utilizada para evaluar algoritmos de optimización basados en gradientes. Esta función es unimodal y presenta su mínimo global en un valle parabólico estrecho, lo que facilita su localización. Sin embargo, segun @simonfraser_rosenbrock citando a @picheny2012benchmark convergencia hacia este mínimo puede ser desafiante debido a la naturaleza del valle.\n\nLa función se evalúa generalmente en el hipercubo $x_i \\in [-5, 10]$ y tiene un mínimo global en $f(1,...,1) = 0$\n\n## Función de Rastrigin\n\n$$f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]$$\n\n::: {#35990e86 .cell execution_count=4}\n``` {.python .cell-code}\n# Función de Rastrigin\ndef rastrigin(x):\n    \"\"\"\n    Calcula el valor de la función de Rastrigin.\n    x: vector de entrada (numpy array)\n    \"\"\"\n    d = len(x)\n    return 10 * d + sum(x**2 - 10 * np.cos(2 * np.pi * x))\nplot_function(rastrigin, x1_range=(-5.12, 5.12), x2_range=(-5.12, 5.12), title=\"Función Rastrigin\", x1_point=0, x2_point=0)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=638 height=377}\n:::\n:::\n\n\nSegun @simonfraser_rosenbrock, la función de Rastrigin tiene varios mínimos locales. Es altamente multimodal, pero las ubicaciones de los mínimos se distribuyen regularmente. La función generalmente se evalúa en el hipercubo $x_i \\in [-5.12, 5.12]$ y su mínimo local se encuentra en $f(0,...,0)=0$.\n\n## Función de Schwefel\n\n$$ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) $$\n\n::: {#5f7b82d5 .cell execution_count=5}\n``` {.python .cell-code}\n# Función de Schwefel\ndef schwefel(x):\n    \"\"\"\n    Calcula el valor de la función de Schwefel.\n    x: vector de entrada (numpy array)\n    \"\"\"\n    d = len(x)\n    return 418.9829 * d - sum(x * np.sin(np.sqrt(np.abs(x))))\nplot_function(schwefel, x1_range=(-500, 500), x2_range=(-500, 500), title=\"Función Schwefel\", x1_point=420.9687, x2_point=420.9687)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=662 height=376}\n:::\n:::\n\n\nSegun @simonfraser_rosenbrock La función de Schwefel es compleja, con muchos mínimos locales. Normalmente se evalua en el hipercubo $x_i \\in [-500,500]$. Su minimo global está en $f(420.9687,...,420.9687)=0$\n\n## Función de Griewank\n\n$$ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) $$\n\n::: {#6f26bbdd .cell execution_count=6}\n``` {.python .cell-code}\n# Función de Griewank\ndef griewank(x):\n    \"\"\"\n    Calcula el valor de la función Griewank.\n    x: numpy array unidimensional (1D) o un array con forma (d, n1, n2) para evaluaciones vectorizadas.\n    \n    Retorna:\n    - Un valor escalar si `x` es 1D.\n    - Una matriz (n1, n2) si `x` tiene forma (d, n1, n2).\n    \"\"\"\n    x = np.asarray(x)\n\n    if x.ndim == 1:\n        # Caso 1D: calcular para un solo vector\n        d = len(x)\n        sum_term = np.sum(x**2) / 4000\n        product_term = np.prod(np.cos(x / np.sqrt(np.arange(1, d + 1))))\n        return 1 + sum_term - product_term\n\n    elif x.ndim == 3:\n        # Caso ND: calcular para una cuadrícula (vectorizado)\n        d = x.shape[0]\n        i_indices = np.arange(1, d + 1).reshape(-1, 1, 1)\n        sum_term = np.sum(x**2, axis=0) / 4000\n        product_term = np.prod(np.cos(x / np.sqrt(i_indices)), axis=0)\n        return 1 + sum_term - product_term\n\n    else:\n        raise ValueError(\"La entrada debe ser un array 1D o un array con forma (d, n1, n2).\")\nplot_function(griewank, x1_range=(-600, 600), x2_range=(-600, 600), title=\"Función Griewank\", x1_point=0, x2_point=0)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=649 height=376}\n:::\n:::\n\n\nSegun @simonfraser_rosenbrock la función de Griewank tiene muchos mínimos locales generalizados, que se distribuyen de forma regular. Lo que hace compleja su optimización al minimo global. Normalmente se evalua en el hipercubo $x_i \\in [-600,600]$. Su minimo global está en $f(0,...,0)=0$\n\n## Función Goldstein-Price\n\n$$\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n$$\n\n::: {#d928d9d4 .cell execution_count=7}\n``` {.python .cell-code}\n# Función Goldstein-Price\ndef goldstein_price(x):\n    \"\"\"\n    Calcula el valor de la función Goldstein-Price.\n    x1, x2: coordenadas en 2D\n    \"\"\"\n    x1=x[0]\n    x2=x[1]\n    term1 = (1 + (x1 + x2 + 1)**2 * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2))\n    term2 = (30 + (2 * x1 - 3 * x2)**2 * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2))\n    return term1 * term2\nplot_function(goldstein_price, x1_range=(-2, 2), x2_range=(-2, 2), title=\"Función Goldstein price\", x1_point=0, x2_point=-1)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=644 height=377}\n:::\n:::\n\n\nLa función Goldstein-Price es una función en 2 dimensiones y tiene varios mínimos locales. Segun @molga2005test, la función generalmente se evalúa en el cuadrado $x_1 \\in [-2, 2]$ y $x_1 \\in [-2, 2]$ . Su mínimo global es $f(0,-1) = 3$\n\n## Función de las seis jorobas de camello\n\n$$ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 $$\n\n::: {#b943f135 .cell execution_count=8}\n``` {.python .cell-code}\n# Función de las seis jorobas de camello\ndef camel_six_humps(x):\n    \"\"\"\n    Calcula el valor de la función de las seis jorobas de camello.\n    x1, x2: coordenadas en 2D\n    \"\"\"\n    x1 = x[0]\n    x2 = x[1]\n    term1 = (4 - 2.1 * x1**2 + x1**4 / 3) * x1**2\n    term2 = x1 * x2\n    term3 = (-4 + 4 * x2**2) * x2**2\n    return term1 + term2 + term3\nplot_function(camel_six_humps, x1_range=(-2, 2), x2_range=(-1, 1), title=\"Función 6 jorobas de camello\", x1_point=0.0898, x2_point=-0.7126, elev=30, azim=75 )\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=654 height=377}\n:::\n:::\n\n\nLa función de las seis jorobas de camello es una función en 2 dimensiones.Segun @molga2005test la función tiene seis mínimos locales, dos de los cuales son globales y recomienda evaluar la función en el rectángulo $x_1 \\in [-3, 3], x_2 \\in [-2, 2]$, donde los mínimos globales son $f(0.0898,-0.7126) = -1.0316$ y $f(-0.0898, 0.7126) = -1.0316$\n:::\n\n# Proceso de optimización\n\n## Optimización por descenso del gradiente\n\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\n\nSegun [@bishop2006pattern], para una función $f(x)$, el algoritmo actualiza iterativamente el punto $x$ usando la regla:\n\n$$ x_{t+1} = x_t - \\eta \\nabla f(x_t) $$\n\ndonde:\n\n-   $x_t$ es el punto actual\n\n-   $\\eta$ es la tasa de aprendizaje\n\n-   $\\nabla f(x_t)$ es el gradiente de la función en $x_t$\n\nEl gradiente $\\nabla f$ es un vector que contiene las derivadas parciales respecto a cada variable: $$\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}$$\n\nEl gradiente $\\nabla f$ se puede aproximar numéricamente usando diferencias finitas. [@bishop2006pattern] plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función $f(x_1, x_2)$, las derivadas parciales se calculan como:\n\n$$ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} $$\n\n$$ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} $$\n\ndonde $h$ es un pequeño incremento (típicamente $10^{-7}$ o $10^{-8}$).\n\n::: {#3dfb56a3 .cell execution_count=9}\n``` {.python .cell-code}\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n```\n:::\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\n::: panel-tabset\n### Función de Rosenbrock\n\n$$f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]$$\n\n| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n|-----------|-----------|--------|-----|\n| -1.5      | -1.7      | 0.001  | 30  |\n\n![](rosenbrock.gif)\n\n### Función de Rastrigin\n\n$$f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]$$\n\n| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n|-----------|-----------|--------|-----|\n| -0.46     | 0.46      | 0.005  | 30  |\n\n![](rastrigin.gif)\n\n### Función de Schwefel\n\n$$ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) $$\n\n| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n|-----------|-----------|--------|-----|\n| 310       | 310       | 0.8    | 30  |\n\n![](schwefel.gif)\n\n### Función de Griewank\n\n$$ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) $$\n\n| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n|-----------|-----------|--------|-----|\n| -500      | 500       | 70     | 33  |\n\n![](griewank.gif)\n\n### Función Goldstein-Price\n\n$$\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n$$\n\n| $x_{1_0}$ | $x_{2_0}$ | $\\eta$  | $n$ |\n|-----------|-----------|---------|-----|\n| 0.5       | -1.5      | 0.00005 | 50  |\n\n![](goldstein_price.gif)\n\n### Función de las seis jorobas de camello\n\n$$ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 $$\n\n| $x_{1_0}$ | $x_{2_0}$ | $\\eta$ | $n$ |\n|-----------|-----------|--------|-----|\n| -1        | -1        | 0.015  | 33  |\n\n![](camel_six_humps.gif)\n:::\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\n\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\n-   **Tasa de aprendizaje**: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\n\n-   **Punto inicial**: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\n\n-   **Criterio de parada**: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia).\n\n## Agoritmo genético\n\nUn algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la **selección natural** y la **evolución biológica**, propuesto inicialmente por [@holland1975adaptation]. Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n\n### Concepto General\n\nEl algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n\n-   **Selección**: Elegir individuos con mayor *fitness*.[^1]\n\n-   **Cruce**: Combinar soluciones para generar descendencia.\n\n-   **Mutación**: Introducir variación genética.\n\n[^1]: El *fitness* representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.\n\nMatemáticamente, en un problema de minimización, el objetivo es encontrar:\n\n$$ x^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) $$\n\ndonde:\n\n-   $x$ representa un individuo en el espacio de búsqueda.\n-   $f(x)$ es la función objetivo que evalúa la calidad de $x$.\n\nCada solución candidata se representa como un **individuo**, que puede ser un vector real o un cromosoma binario:\n\n$$x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n$$\n\nLa función objetivo mide qué tan buena es una solución:\n\n$$\\text{Fitness}(x) = f(x)$$\n\nPara problemas de **minimización**, menor $f(x)$ implica mejor fitness.\n\n------------------------------------------------------------------------\n\n### Etapas\n\n**Inicialización de la Población**\n\nSe genera una población inicial de $P$ individuos de forma aleatoria dentro de un intervalo $[a, b]$ :\n\n$$x_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\}$$ donde:\n\n-   $x_{ij}$ es la $j-ésima$ coordenada del $i-ésimo$ individuo.\n\n::: {#9b61bf85 .cell execution_count=10}\n``` {.python .cell-code}\n# Inicializar población\ndef initialize_population(size, dim, bounds):\n    return np.random.uniform(bounds[0], bounds[1], (size, dim))\n```\n:::\n\n\n------------------------------------------------------------------------\n\n**Evaluación del Fitness**\n\nCada individuo de la población es evaluado usando la función objetivo:\n\n$\\text{Fitness}_i = f(x_i)$\n\n::: {#7ff8fb0c .cell execution_count=11}\n``` {.python .cell-code}\n# Evaluar fitness\ndef evaluate_fitness(population,fitness_function):\n    return np.array([fitness_function(ind) for ind in population])\n```\n:::\n\n\n------------------------------------------------------------------------\n\n**Selección**\n\nSe seleccionan individuos para reproducirse basándose en su fitness. Un métodos comune es el método de torneo, donde primero se seleccionan $k$ individuos al azar y luego se elige al mejor de ellos(mejor fitness):\n\n$$\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k$$\n\n::: {#e05c6e88 .cell execution_count=12}\n``` {.python .cell-code}\n# Selección por torneo\ndef tournament_selection(population, fitness, k=3):\n    selected = []\n    for _ in range(len(population)):\n        candidates = np.random.choice(range(len(population)), k, replace=False)\n        winner = candidates[np.argmin(fitness[candidates])]\n        selected.append(population[winner])\n    return np.array(selected)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n**Cruce (Recombinación)**\n\nDos individuos (padres) se combinan para generar descendencia. Un método común es **punto de corte único**, donde: 1. Se Elegie un punto de cruce aleatorio $k$. 2. Se genera la descendencia mezclando las características de los padres.\n\n$$\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:])$$\n\n$$\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:])$$\n\nLa probabilidad de realizar un cruce está determinada por $p_c$ (tasa de cruce).\n\n::: {#56ef7cbd .cell execution_count=13}\n``` {.python .cell-code}\n# Cruce\ndef crossover(parent1, parent2, crossover_rate):\n    if np.random.rand() < crossover_rate:\n        point = np.random.randint(1, len(parent1))\n        child = np.concatenate([parent1[:point], parent2[point:]])\n        return child\n    return parent1 if np.random.rand() < 0.5 else parent2\n```\n:::\n\n\n------------------------------------------------------------------------\n\n**Mutación**\n\nSe introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad $p_m$:\n\n$$x_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta)$$\n\ndonde:\n\n-   $\\Delta$ es una perturbación aleatoria.\n-   $x_{ij}$ se restringe a los límites del problema.\n\n::: {#455b7103 .cell execution_count=14}\n``` {.python .cell-code}\n# Mutación\ndef mutate(individual, bounds, mutation_rate, delta):\n    for i in range(len(individual)):\n        if np.random.rand() < mutation_rate:\n            individual[i] += np.random.uniform(-delta, delta)\n            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n    return individual\n```\n:::\n\n\n------------------------------------------------------------------------\n\n**Evaluación y Sustitución**\n\nLa nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n\n::: {#025c14e3 .cell execution_count=15}\n``` {.python .cell-code}\n# Algoritmo completo\ndef genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n    population = initialize_population(population_size, dim, bounds)\n    best_individual = None\n    trajectory = []\n    populations = []\n\n    for generation in range(generations):\n        populations.append(population.copy())\n        fitness = evaluate_fitness(population, fitness_function)\n        \n        if best_individual is None or np.min(fitness) < fitness_function(best_individual):\n            best_individual = population[np.argmin(fitness)]\n        \n        # Guardar la mejor solución de esta generación\n        trajectory.append((*best_individual, fitness_function(best_individual)))\n        \n        # Selección\n        selected_population = tournament_selection(population, fitness)\n        \n        # Cruce y mutación\n        new_population = []\n        for i in range(0, len(selected_population), 2):\n            if i + 1 < len(selected_population):\n                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n                new_population.extend([child1, child2])\n            else:\n                new_population.append(selected_population[i])\n        \n        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n    \n    # Convertir la trayectoria a DataFrame\n    \n    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n    df = pd.DataFrame(trajectory, columns=columns)\n    return best_individual, fitness_function(best_individual), df, populations\n```\n:::\n\n\n------------------------------------------------------------------------\n\n::: panel-tabset\n### Función de Rosenbrock\n\n$$f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]$$\n\n![](Rosenbrock_population_animation.gif)\n\n### Función de Rastrigin\n\n$$f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]$$\n\n![](Rastrigin_population_animation.gif)\n\n### Función de Schwefel\n\n$$ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) $$\n\n![](Schwefel_population_animation.gif)\n\n### Función de Griewank\n\n$$ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) $$\n\n![](Griewank_population_animation.gif)\n\n### Función Goldstein-Price\n\n$$\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n$$\n\n![](Goldstein_Price_population_animation.gif)\n\n### Función de las seis jorobas de camello\n\n$$ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 $$\n\n![](Camel_Six_Humps_population_animation.gif)\n:::\n\nLos algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: **Exploración**, que consiste en descubrir nuevas regiones del espacio de búsqueda, y **Explotación**, enfocada en refinar y mejorar las soluciones existentes.\n\nPara las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación $\\delta$ se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n\n### Observaciones\n\nVentajas:\n\n-   No requiere derivadas ni condiciones específicas en \\$\\$\\$f(x)\\$ .\n-   Es efectivo en espacios de búsqueda multimodales o no convexos.\n-   Adaptable a diversos problemas.\n\nDesventajas:\n\n-   Puede ser computacionalmente costoso.\n-   No garantiza convergencia al óptimo global.\n-   Requiere ajuste cuidadoso de parámetros.\n\n## Optimización de partículas\n\n::: panel-tabset\n### Función de Rosenbrock\n\n$$f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]$$\n\n![](Rosenbrock_particulas_animation.gif)\n\n### Función de Rastrigin\n\n$$f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]$$\n\n![](Rastrigin_particulas_animation.gif)\n\n### Función de Schwefel\n\n$$ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) $$\n\n![](Schwefel_particulas_animation.gif)\n\n### Función de Griewank\n\n$$ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) $$\n\n![](Griewank_particulas_animation.gif)\n\n### Función Goldstein-Price\n\n$$\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n$$\n\n![](Goldstein_Price_particulas_animation.gif)\n\n### Función de las seis jorobas de camello\n\n$$ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 $$\n\n![](Camel_Six_Humps_particulas_animation.gif)\n:::\n\n## Optimización diferencial\n\n# Resultados\n\nComo se puede observar, en la mayoría de los casos de optimización para una unica corrida los puntos óptimos conergen a mínimos locales, lo que indica que los resultados óptimos pueden estar fuertemente influenciado por los valores iniciales de $x$ o las condiciones de inicio de los algoritmos. Por esta razón, para evaluar el rendimiento y el comportamiento de los algoritmos en un entorno más general, se realizarán múltiples ejecuciones. En cada corrida, los algoritmos partirán de valores iniciales distintos generados aleatoriamente. Con esto se verá cuanto tardan los algoritmos en mejorar la evaluación de la función objetivo y cuales pueden ser algunos comentarios particulares a realizar. Los resultados se presentaran para los casos de 2 y 3 dimensiones de las funciones.\n\n(Tabla o gráfica de resutlados)\n\n# Conclusiones y comentarios\n\n### Tareas:\n\n1.  **Escoja dos funciones de prueba.**\n2.  **Optimización con método de descenso por gradiente:**\n    -   Optimice las funciones seleccionadas en **dos y tres dimensiones** usando un **método de descenso por gradiente** con condición inicial aleatoria.\n3.  **Optimización con métodos heurísticos:**\n    -   Optimice las funciones seleccionadas en **dos y tres dimensiones** usando:\n        -   Algoritmos evolutivos.\n        -   Optimización de partículas.\n        -   Evolución diferencial.\n4.  **Representación visual:**\n    -   Cree un **GIF animado** o un **video** que muestre el proceso de optimización usando:\n        -   **Descenso por gradiente**.\n        -   **Métodos heurísticos**.\n\n### Discusión:\n\nReflexione sobre los siguientes puntos: - ¿Qué aportaron los métodos de **descenso por gradiente** y qué aportaron los **métodos heurísticos**? - Para responder a esta pregunta, considere: - El **valor final** de la función objetivo. - El **número de evaluaciones** de la función objetivo. - Es posible que se requiera realizar **varias corridas** de los algoritmos para obtener conclusiones significativas.\n\n# Parte 2: Optimización Combinatoria\n\n## Problema del Viajero:\n\nUn vendedor debe realizar un recorrido por **todas las capitales** de los **32 estados** de los **Estados Unidos Mexicanos**.\n\n### Tareas:\n\n1.  **Optimización con métodos metaheurísticos:**\n    -   Utilice **colonias de hormigas** para encontrar el orden óptimo del recorrido.\n    -   Utilice **algoritmos genéticos** para encontrar el orden óptimo del recorrido.\n2.  **Costo del recorrido:**\n    -   El costo de desplazamiento entre ciudades se calcula como la suma de:\n        -   El valor de la **hora del vendedor** (este es un parámetro que debe estudiarse).\n        -   El **costo de los peajes**.\n        -   El **costo del combustible**.\n    -   Cada equipo debe definir el **vehículo** que utilizará el vendedor para realizar el recorrido y, con base en esta elección, **calcular el costo del combustible**.\n\n### Representación Visual:\n\n-   Cree un **GIF animado** o un **video** que muestre cómo se comporta la **mejor solución** encontrada, usando un **gráfico del recorrido** en el mapa de México.\n\n------------------------------------------------------------------------\n\n### Discusión:\n\nReflexione sobre: - Los resultados obtenidos con las **colonias de hormigas** y los **algoritmos genéticos**. - Comparación de costos y tiempo de ejecución.\n\n## Solución de las tareas propuestas\n\n### Extracción de datos\n\nPara empezar a solucionar el problema, es necesario obtener información acerca del valor del salario del vendedor, el costo de los peajes y el cálculo correspondiente al costo total destinado a combustible; definiendo entonces el modelo de automóvil a considerar en el ejercicio, junto con su respectivo costo de gasolina. Durante el desarrollo de este proceso de extracción de información se tomaron como referencia las ciudades capitales de cada uno de los estados mexicanos y se observó el mapa de la división política de México en sus 32 estados, a fin de tener un mejor entendimiento de la región.\n\n**Figura 1.**\n\n*Mapa de México.* ![Mapa de México](images/mapa_mexico.jpg) *Nota.* El mapa representa cada una de las ciudades capitales del país. Adaptado de *Fondo plano de mapa de méxico* \\[Ilustración\\], por Freepik, 2024, Freepik (<https://www.freepik.es/vector-gratis/mapa-mexico).> Licencia gratuita.\n\n#### Distancias y tiempo de conducción\n\nLa tabla de distancias y tiempo de conducción entre las ciudades fue obtenida a través del sitio web @mejoresrutas2024, diseñado especialmente para el cálculo y planeación de viajes a lo largo de todo el país. Dicho recurso online permite obtener información como distancias, tiempo de conducción y otros valores asociados entre dos ciudades ingresando el nombre de cada una de ellas.\n\n#### Peajes\n\nPara obtener la información de los peajes, fue utilizado el mismo sitio web @mejoresrutas2024, el cual también contiene datos relacionados con el costo actual de los peajes que se encuentran entre las ciudades donde se realiza la consulta.\n\nDebido al gran número de combinaciones posibles, se programó un bot en Python empleando la librería *Beautiful Soup*, lo que permitió automatizar la extracción de la información anteriormente mencionada. En el repositorio en GitHub es posible encontrar el archivo con el código para llevar a cabo esta tarea.\n\n### Definición de gastos\n\nEn la siguiente sección se definen los gastos que deben ser consultados, entre los cuales se encuentran el salario del vendedor, el modelo de automóvil a utilizar y su correspondiente gasto de combustible.\n\n#### Salario del vendedor\n\nPara definir el salario del vendedor, se toma como referencia el salario minimo en México, que actualmente se encuentra en 248,93 pesos diarios según la @conasami2024; por lo tanto, para una jornada de 8 horas, el salario mínimo por hora es de 31,12 aproximadamente. Dicho esto, se decide establecer un salario de 35 pesos mexicanos por hora para el vendedor del presente ejercicio.\n\n#### Modelo del carro y gasto en gasolina\n\nDe acuerdo con @elpais2024, el modelo de automóvil más vendido actualmente en México es el Nissan Versa, por lo que se ha considerado conveniente seleccionarlo como medio de transporte a utilizar por parte del vendedor. Esto permitirá hacer una estimación más justa del costo total de realizar la ruta por los 32 estados mexicanos en el contexto de dicho país.\n\nAdicionalmente, es importante considerar que el rendimiento promedio de este modelo en carreteras es de 25 kilómetros por litro de acuerdo con información proporcionada por @nissanversarendimiento2023 y que el tipo de gasolina que utiliza es la comúnmente denominada como \"Gasolina Magna\" en México la cual, al día 14 de noviembre, tiene un precio promedio de 23.96 pesos mexicanos por litro según @gasolinamx2024.\n\n#### Transformaciones\n\nSe ha obtenido la información anterior con el objetivo de calcular el costo total de desplazamiento entre las ciudades capitales de México, sin embargo, se observa que no todos los datos se encuentran en las unidades requeridas (MXN): hay magnitudes en litros, horas, kilómetros, etc. Por lo tanto, se realizarán las siguientes transformaciones en todas las unidades para poder sumar dichos gastos en pesos mexicanos, a diferencia del caso de los peajes, pues estos ya se encuentran en la unidad monetaria deseada.\n\n##### Tiempo de viaje\n\nEl costo por el salario del vendedor es calculado la forma que se muestra en la Ecuación (1):\n\n$$ \n\\text{Costo\\_vendedor} = \\text{tiempo} \\times \\text{salario\\_del\\_vendedor} \\tag{1}\n$$\n\n#### Gasolina para el viaje\n\nEl gasto total en gasolina se obtiene con la fórmula mostrada en la Ecuación (2):\n\n$$ \n\\text{Costo\\_gasolina} = \\left( \\frac{\\text{Distancia}}{\\text{Rendimiento (km/litro)}} \\right) \\times \\text{Precio\\_por\\_litro} \\tag{2}\n$$\n\n##### Gasto total\n\nDespués de realizar las operaciones mostradas anteriormente, se tiene como resultado toda la información necesaria en las unidades requeridas para obtener un valor correspondiente al gasto total del viaje en pesos mexicanos, de acuerdo con lo definido en la Ecuación (3).\n\n$$\n\\text{Gasto\\_recorrido} = \\text{Costo\\_gasolina} + \\text{Costo\\_vendedor} + \\text{Costo\\_Peajes} \\tag{3}\n$$\n\n### Ruta óptima\n\nA continuación, se procede con la utilización de los algoritmos propuestos para este caso: Colonia de Hormigas y Algoritmos Genéticos, con el fin de responder a la actividad planteada al principio del presente ejercicio, esto es, hallar la ruta óptima para el recorrido del vendedor a través de los 32 estados de México.\n\n#### Colonia de Hormigas\n\nConsiderando la información recolectada en @acowikipedia2024 y @acobook2018 y lo presentado en la primera sección del trabajo, puede decirse que los **algoritmos de colonia de hormigas (Ant Colony Optimization, ACO)** son una técnica de optimización basada en la inteligencia colectiva observada en las colonias de hormigas naturales. Fueron inspirados en el comportamiento de las hormigas en la naturaleza para resolver problemas complejos de optimización combinatoria, en esta segunda parte del trabajo profundizaremos más en sus hiperparámetros claves los cuales son:\n\n-   **Cantidad de hormigas:** Cantidad de hormigas que participarán en cada iteración de la búsqueda de soluciones. Influye en la capacidad del algoritmo de explorar diferentes soluciones de manera simultánea. En este caso se utilizarán 32 hormigas, es decir, igual al número de estados en México.\n\n-   **Alpha**: Controla la influencia de la feromona en la probabilidad de que una hormiga elija ese camino. A medida que el valor aumenta, las hormigas son más propensas a seguir caminos con más feromona. Aquí se utilizará un valor de 1 para otorgar una influencia moderada de las feromonas depositadas.\n\n-   **Beta**: Controla la preferencia de las hormigas por caminos más \"baratos\" o prometedores, lo cual ayuda aumentar la exploración. Se va a considerar un valor de 2, puesto que se busca minimizar el costo del viaje\n\n-   **\\\\(\\\\rho\\\\)**: Indica la tasa de evaporación de la feromona, lo cual evita que las soluciones previas influencien las iteraciones futuras. Se seleccionó una tasa de evaporación del 0.5, es decir, el 50% de las feromonas se evaporan en cada iteración.\n\n-   **\\\\(Q\\\\)**: Cantidad de feromona depositada por una hormiga en su recorrido tras encontrar una solución. Se utilizará un valor de 100 para indicar la cantidad de feromonas en el camino.\n\nUna vez definidos los hiperparámetros, se puede continuar con la ejecución del algoritmo de colonia de hormigas, cuyo detalle se puede observar más a profundidad en el repositorio de GitHub. En la Figura 2 se puede observar cómo va variando el costo de realizar el viaje en cada una de las iteraciones que realizó dicho algoritmo.\n\n**Figura 2.**\n\n*Función costo del algoritmo Colonia de Hormigas.* ![Función costo del algoritmo Colonia de Hormigas](images/costo-aco-primera.png) *Nota.* La gráfica muestra la evolución del costo total del viaje a medida que se ejecutan las diferentes iteraciones del algoritmo, que para este caso fueron 500. Elaboración propia.\n\nDe acuerdo con la imagen anterior, es posible observar que el costo mínimo se alcanza relativamente rápido, antes de las 100 iteraciones. En este sentido, también es interesante notar que el cálculo de esta función de costo varía al considerar diferentes variaciones que puedan realizarse sobre el planteamiento inicial del problema, comportamiento que se verá más adelante.\n\nPosteriormente, en la Figura 3 puede verse la ruta óptima encontrada por el algoritmo de colonia de hormigas para que el vendedor pueda recorrer los 32 estados mexicanos.\n\n**Figura 3.**\n\n*Ruta óptima encontrada mediante el algoritmo de Colonia de Hormigas.* ![Ruta óptima encontrada mediante el algoritmo de Colonia de Hormigas](images/imagen1.png) *Nota.* Puede observarse que esta visualización gráfica está dada por líneas rectas entre cada una de las ciudades y no muestra con fidelidad la forma en que se haría el recrorrido. Elaboración propia.\n\nCon el fin de que el camino óptimo pueda reflejar la realidad del viaje, en la Figura 4 se ilustra la utilización de la API gratuita *Open Route Service* para graficar el recorrido propuesto a lo largo de las carreteras en el mapa de México. La API key para acceder a este servicio es la siguiente:\n\n::: {#9e2181e5 .cell execution_count=16}\n``` {.python .cell-code}\napi_key = \"5b3ce3597851110001cf6248c140bc578aac4c2d95295dc798e53a22\"\n```\n:::\n\n\n**Figura 4.**\n\n*Forma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas.* ![Forma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas](images/imagen2.png) *Nota.* El gráfico muestra las carreteras que deberían seguirse para completar el recorrido propuesto, sin embargo, algunos aspectos siguen siendo siendo interesantes. Elaboración propia.\n\nComo se mencionó anteriormente, de esta forma se obtiene una ruta óptima más realista. No obstante, llama la atención que, en ciertas secciones, la ruta implica cruzar cuerpos de agua. Al investigar las razones de este comportamiento, se descubrió que para conectar algunos estados del país como Baja California Sur y Sinaloa, la opción de tomar un ferri es considerada la más conveniente según servicios de planificación de trayectos como @mejoresrutasferri2024 y @bajaferries2024.\n\nDado que la matriz de costos actual no considera el valor asociado al uso del ferri ni los gastos asociados al transporte del vehículo para continuar posteriormente el recorrido, se propone un análisis de los siguientes escenarios:\n\n1.  Incluir el costo del ferri en la matriz de costos y evaluar la ruta resultante.\n\n2.  Realizar el viaje completamente por tierra, excluyendo los estados que se alcanzan únicamente utilizando el ferri.\n\n**Primer escenario**\n\nSe consultó el valor del tiquete de ferri para una persona adulta y el costo del transporte de un automóvil, encontrando que el más económico para un adulto es de **1,460 pesos mexicanos**, mientras que el transporte del automóvil tiene un valor de **5,480 pesos mexicanos** según @debate2023.\n\nEstos costos fueron utilizados como parámetros para el algoritmo de colonia de hormigas, llegando a que, como se observa en la Figura 5, el algoritmo sigue alcanzando un mínimo de manera relativamente rápida.\n\n**Figura 5.**\n\n*Evolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri.* ![Evolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri](images/costos-aco-segunda.png) *Nota.* Es interesante notar que, a pesar del incremento en el costo de moverse entre dos estados (debido al ferri), el algoritmo logró encontrar una ruta más barata que la hallada originalmente. Esto sugiere que en la primera solución encontrada el algoritmo podría haberse quedado atascado en un mínimo local debido a la falta de iteraciones. Elaboración propia.\n\nAdemás, también es posible observar que el tiempo y la distancia se redujeron en esta nueva solución, lo cual permite pensar que esta ruta no solo es más económica, sino también más eficiente, a pesar de que está considerando el costo adicional del ferri y el transporte del vehículo.\n\nLos resultados correspondientes a la visualización gráfica del camino óptimo encontrado para el vendedor en este escenario pueden observarse a continuación, en las Figuras 6 y 7.\n\n**Figura 6.**\n\n*Ruta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri.* ![Ruta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri](images/imagen3.png). *Nota.* Las observaciones respecto a la forma en que se conectan los distintos puntos del recorrido permanecen iguales que en el caso considerado originalmente. Elaboración propia.\n\n**Figura 7.**\n\n*Carreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas.* ![Carreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas](images/imagen4.png) *Nota.* Esta imagen también fue generada por medio del uso de la API gratuita, así que sus resultados son reproducibles. Elaboración propia.\n\n**Segundo escenario**\n\nEn este segundo escenario, la ciudad de **La Paz** fue eliminada del recorrido, por lo que el viaje ahora solo incluye los **31 estados restantes**. En consecuencia, también se redujo la cantidad de hormigas utilizadas en el algoritmo a un valor de **31**, asignando una hormiga por estado para realizar la búsqueda.\n\nComo era de esperarse, el precio del recorrido se redujo en este caso. Sin embargo, al algoritmo le tomó muchas más iteraciones encontrar el costo mínimo, como se observa en la Figura 8.\n\n**Figura 8.**\n\n*Evolución de la función costo para los 31 estados de México.* ![Evolución de la función costo para los 31 estados de México](images/costo-aco-tercera.png) *Nota.* El hecho de que el planteamiento inicial de ciudades y estados a recorrer cambiara al no tener en cuenta el estado que solamente puede ser conectado vía marítima fue un factor determinante en la ejecución del algoritmo de hormigas, siendo mucho menos rápido que en el primer escenario (incluso que en el escenario original). Elaboración propia.\n\nA diferencia del caso anterior, la Figura 8 también muestra que la **distancia** y el **tiempo** aumentaron. Esto se debe a que, al no utilizar el ferri, el automóvil tuvo que realizar un recorrido más largo en ciertas partes para completar su ruta. Por lo tanto, aunque esta solución es más eficiente en términos de costo, no lo es en términos de tiempo y distancia recorrida.\n\nLa visualización gráfica de los resultados obtenidos para este caso pueden observarse en las Figuras 9 y 10, teniendo en cuenta las mismas consideraciones anteriormente mencionadas.\n\n**Figura 9.**\n\n*Ruta óptima encontrada mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.* ![Ruta encontradas mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México](images/imagen5.png) Elaboración propia.\n\n**Figura 10.**\n\n*Orden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.* ![Orden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México](images/imagen6.png) *Nota.* Sumado a los inconvenientes observados en este escenario, al desconectar uno de los estados de México, puede observarse que una gran región del país queda excluida del recorrido del vendedor, lo que puede implicar significativas pérdidas económicas y oportunidades de establecer nuevos negocios.\n\n#### Algoritmo genético\n\nDe acuerdo con información proporcionada por @tesisga2009 y encontrada en @gawikipedia2024, y como se explico en la primera sección del trabajo, puede decirse que los **algoritmos genéticos (Genetic Algorithms, GA)** son una técnica de optimización inspirada en los principios de la selección natural y la evolución biológica. Los GA buscan soluciones óptimas mediante la creación, evaluación y modificación de una población de individuos, representando posibles soluciones a un problema dado. La evolución de la población se realiza mediante operadores genéticos como la mutación y en esta sección profundizaremos más en sus hiperparámetros clave, los cuales son:\n\n-   **Tamaño de la población**: Define el número de individuos en cada generación. Un tamaño de población más grande permite una mejor exploración del espacio de soluciones, pero también aumenta el tiempo de cómputo. En este caso, se utilizará una población de 100 individuos, lo que proporciona un equilibrio adecuado entre diversidad y eficiencia computacional.\n\n-   **Número de generaciones**: Especifica cuántas veces se evolucionará la población mediante el proceso de selección, cruce y mutación; se consideran adecuadas un total de 200 generaciones para permitir al algoritmo explorar el espacio de búsqueda y converger hacia una solución óptima o cercana al óptimo.\n\n-   **Tasa de mutación**: Representa la probabilidad de que un gen sea modificado aleatoriamente en un individuo. La mutación introduce variación genética, lo que ayuda a explorar nuevas áreas del espacio de búsqueda y a evitar estancamientos en óptimos locales. Se empleará una tasa de mutación de 0.1 (10%), lo que mantiene una buena cantidad de diversidad sin perturbar excesivamente a la población.\n\nDe la misma manera en que se realizó en la sección anterior, la presentación de resultados comienza con una obtención de resultados iniciales considerando los 32 estados de México y sin tener en cuenta el costo del ferri.\n\nComo se observa en la Figura 11, alcanzar el mínimo toma casi 175 generaciones, lo que indica que este algoritmo se demora más en llegar a un valor mínimo en comparación con el algoritmo de colonia de hormigas. Además, la solución que encuentra tiene un costo mayor y toma más tiempo y una mayor distancia completarla.\n\n**Figura 11.**\n\n*Evolución de la función costo del algoritmo genético.* ![Evolución de la función costo del algoritmo genético](images/costo-genetico-primera.png) *Nota.* En la ejecución de este algoritmo, la solución óptima se encontró en una iteración muy cercana al límite máximo establecido, a diferencia del algoritmo de colonia de hormigas, que lo realizó muy rápidamente. Elaboración propia.\n\nAhora bien, en las Figuras 12 y 13 se tiene la visualización gráfica del recorrido propuesto por este algoritmo, siguiendo los mismos procedimientos de utilización de la API que se mencionaron de manera previa.\n\n**Figura 12.**\n\n*Ruta óptima encontrada mediante algoritmo genético.* ![Ruta óptima encontrada mediante algoritmo genético](images/imagen1_ga.png) Elaboración propia.\n\n**Figura 13.**\n\n*Ruta óptima con las carreteras encontrada mediante algoritmo genético.* ![Ruta óptima con las carreteras encontrada mediante algoritmo genético](images/imagen2_ga.png) Elaboración propia.\n\nNuevamente, se considera pertinente considerar los dos escenarios adicionales de análisis: un nuevo cálculo de costos teniendo en cuenta el tiquete de ferri y el transporte adicional para el automóvil y la exclusión La Paz, como territorio que solo puede conectarse a través de cuerpos de agua.\n\n**Primer escenario**\n\nEs posible observar que al tomar en cuenta el costo del ferri, en este caso sí se aumenta el costo del camino óptimo y el número de iteraciones se reduce un poco, como puede verse en la Figura 14. Sin embargo, el tiempo que toma completar esta ruta es mucho más alto que en el caso anterior, lo que podría indicar que esta solución se quedó atrapada en un mínimo local.\n\n**Figura 14.**\n\n*Evolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri.* ![Evolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri](images/costo-genetico-segunda.png) Elaboración propia.\n\nPor otra parte, en las Figuras 15 y 16 se puede observar el recorrido propuesto por esta solución del algoritmo para que el vendedor se desplace por todo el país, viendo que los puntos de inicio y finalización son diferentes a los que había arrojado como resultado el algoritmo de colonia de hormigas.\n\n**Figura 15.**\n\n*Ruta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri.* ![Ruta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri](images/imagen3_ga.png) *Nota.* Sabiendo que la ruta marítima que seleccionaron ambos algoritmos es la misma, puede decirse que las diferencias entre sus resultados radican en otros aspectos inherentes a su propia definición, como pueden serlo los hiperparámetros y la forma en que realizan una búsqueda de la solución óptima. Elaboración propia.\n\n**Figura 16.**\n\n*Ruta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri.* ![Ruta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri](images/imagen4_ga.png) *Nota.* La utilización de la API se dio exactamente igual que en los escenarios anteriores, de manera que estos resultados también son reproducibles.\n\n**Segundo escenario**\n\nEn este último escenario, el cual solamente considera 31 de los estados de México, es posible notar que el costo óptimo nuevamente bajó y, a diferencia del algoritmo de colonia de hormigas, el algoritmo genético sí encuentra una forma de reducir el tiempo y la distancia del recorrido, mostrando una mejoría en ese aspecto.\n\nDe acuerdo con la Figura 17, en este escenario el algoritmo genético necesitó más iteraciones para encontrar un mínimo, lo cual se ve compensado por el hecho de que mejoró el desempeño del algoritmo de colonia de hormigas en términos de las variables anteriormente mencionadas.\n\n**Figura 17.**\n\n*Evolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México.* ![Evolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México](images/costo-genetico-tercera.png) Elaboración propia.\n\nFinalmente, las Figuras 18 y 19 permiten observar el recorrido que debería realizar el vendedor de acuerdo con este escenario propuesto, en el que también queda aislada una amplia región del país debido a la decisión de no considerar recorridos que no fueran terrestres.\n\n**Figura 18.**\n\n*Ruta óptima encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México.* ![Ruta encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México](images/imagen5_ga.png) Elaboración propia.\n\n**Figura 19.**\n\n*Ruta óptima de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México.* ![Ruta de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México](images/imagen6_ga.png) *Nota.* Al observar las carreteras que debería recorrer esta solución, puede observarse que el vendedor terminaría pasando por los mismos caminos varias veces, ya que deben darse varios recorridos de manera repetida por la necesidad de conectar algunos territorios de los 31 estados sin contemplar la opción del viaje en ferri. Elaboración propia.\n\n### Verificación de la calidad de la solución\n\nEs importante evaluar qué tan buena es la solución alcanzada. Métodos exhaustivos como la fuerza bruta, que permiten comprobar cuál es la mejor solución entre todas las posibles, resultan computacionalmente inviables en este caso. Aprovechando que disponemos de un gran número de iteraciones y tres diferentes escenarios que nos permiten variar las condiciones del problema, podemos concluir que la solución obtenida es, al menos, razonablemente buena.\n\nAdemás, es relevante analizar el comportamiento de las funciones de costo. En todos los escenarios se observa que el costo se reduce significativamente al principio y luego comienza a fluctuar alrededor de una media estable. Esto indica que el algoritmo está convergiendo hacia esos valores. A partir de este comportamiento, seleccionamos la solución con el menor costo como la mejor alternativa.\n\nEn general, las funciones de costo tienden a estabilizarse dentro de un rango limitado de valores. Este patrón nos permite confiar en que las soluciones obtenidas se encuentran entre las mejores posibles, considerando las limitaciones inherentes a los métodos no determinísticos.\n\n### Discusión de los resultados\n\nLos resultados obtenidos al aplicar el Algoritmo de Colonia de Hormigas y el Algoritmo Genético en tres situaciones diferentes permiten destacar las fortalezas y diferencias de cada uno. Por un lado, el Algoritmo de Colonia de Hormigas logra encontrar una solución más económica y en un menor número de iteraciones en comparación con el Algoritmo Genético. Por lo tanto, en esta evaluación específica, dicho algoritmo puede considerarse más eficiente para resolver el problema en esta situación particular.\n\nNo obstante, es importante señalar que la elección del algoritmo adecuado depende en gran medida de la naturaleza del problema. Incluso para un mismo problema, diferentes enfoques pueden llevar a variaciones significativas en los resultados, como se observó en este análisis. Aunque en este caso el Algoritmo de Colonia de Hormigas demostró ser más eficiente que el Algoritmo Genético, esta ventaja es altamente circunstancial y no necesariamente aplicable a todos los contextos. Esto refuerza la importancia de adaptar la metodología a las características específicas del problema a resolver.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}