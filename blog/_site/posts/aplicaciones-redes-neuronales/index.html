<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Julián Castaño Pineda">
<meta name="author" content="Luis Andrés Altamar Romero">
<meta name="author" content="Catalina Restrepo Salgado">
<meta name="author" content="Tomás Rodríguez Taborda">
<meta name="dcterms.date" content="2025-02-18">

<title>Aplicaciones de Redes Neuronales – Redes Neuronales Artificiales y Algoritmos Bioinspirados</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ea72dc5fed832574809a9c94082fbbb.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-f3c2ea88cadbcfb37ba28ffa2c97cfc1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-ae2d0dcda2edce4ab590422bb373b64f.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Redes Neuronales Artificiales y Algoritmos Bioinspirados</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/RNA-y-Algo-Bioinsp-2024-02/blog"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Aplicaciones de Redes Neuronales</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">redes neuronales artificiales</div>
                <div class="quarto-category">desarrollo web</div>
                <div class="quarto-category">python</div>
                <div class="quarto-category">series de tiempo</div>
                <div class="quarto-category">clasificación</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Julián Castaño Pineda </p>
               <p>Luis Andrés Altamar Romero </p>
               <p>Catalina Restrepo Salgado </p>
               <p>Tomás Rodríguez Taborda </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 18, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#resumen-ejecutivo" id="toc-resumen-ejecutivo" class="nav-link active" data-scroll-target="#resumen-ejecutivo"><span class="header-section-number">1</span> Resumen ejecutivo</a></li>
  <li><a href="#introducción" id="toc-introducción" class="nav-link" data-scroll-target="#introducción"><span class="header-section-number">2</span> Introducción</a></li>
  <li><a href="#metodología" id="toc-metodología" class="nav-link" data-scroll-target="#metodología"><span class="header-section-number">3</span> Metodología</a>
  <ul class="collapse">
  <li><a href="#módulos" id="toc-módulos" class="nav-link" data-scroll-target="#módulos"><span class="header-section-number">3.1</span> Módulos</a></li>
  </ul></li>
  <li><a href="#desarrollo-técnico-por-módulo" id="toc-desarrollo-técnico-por-módulo" class="nav-link" data-scroll-target="#desarrollo-técnico-por-módulo"><span class="header-section-number">4</span> Desarrollo técnico por módulo</a>
  <ul class="collapse">
  <li><a href="#módulo-de-predicción-de-la-demanda" id="toc-módulo-de-predicción-de-la-demanda" class="nav-link" data-scroll-target="#módulo-de-predicción-de-la-demanda"><span class="header-section-number">4.1</span> Módulo de predicción de la demanda</a>
  <ul class="collapse">
  <li><a href="#comprensión-del-negocio" id="toc-comprensión-del-negocio" class="nav-link" data-scroll-target="#comprensión-del-negocio"><span class="header-section-number">4.1.1</span> <strong>1. Comprensión del Negocio</strong></a></li>
  <li><a href="#comprensión-de-los-datos" id="toc-comprensión-de-los-datos" class="nav-link" data-scroll-target="#comprensión-de-los-datos"><span class="header-section-number">4.1.2</span> <strong>2. Comprensión de los Datos</strong></a></li>
  <li><a href="#preparación-de-los-datos" id="toc-preparación-de-los-datos" class="nav-link" data-scroll-target="#preparación-de-los-datos"><span class="header-section-number">4.1.3</span> <strong>3. Preparación de los Datos</strong></a></li>
  <li><a href="#modelado" id="toc-modelado" class="nav-link" data-scroll-target="#modelado"><span class="header-section-number">4.1.4</span> <strong>4. Modelado</strong></a></li>
  <li><a href="#evaluación" id="toc-evaluación" class="nav-link" data-scroll-target="#evaluación"><span class="header-section-number">4.1.5</span> <strong>5. Evaluación</strong></a></li>
  <li><a href="#despliegue" id="toc-despliegue" class="nav-link" data-scroll-target="#despliegue"><span class="header-section-number">4.1.6</span> <strong>6. Despliegue</strong></a></li>
  </ul></li>
  <li><a href="#módulo-de-clasificación-de-productos" id="toc-módulo-de-clasificación-de-productos" class="nav-link" data-scroll-target="#módulo-de-clasificación-de-productos"><span class="header-section-number">4.2</span> Módulo de clasificación de productos</a>
  <ul class="collapse">
  <li><a href="#limpieza-del-dataset" id="toc-limpieza-del-dataset" class="nav-link" data-scroll-target="#limpieza-del-dataset"><span class="header-section-number">4.2.1</span> Limpieza del dataset</a></li>
  <li><a href="#preprocesamiento-de-las-imágenes" id="toc-preprocesamiento-de-las-imágenes" class="nav-link" data-scroll-target="#preprocesamiento-de-las-imágenes"><span class="header-section-number">4.2.2</span> Preprocesamiento de las imágenes</a></li>
  <li><a href="#data-augmentation" id="toc-data-augmentation" class="nav-link" data-scroll-target="#data-augmentation"><span class="header-section-number">4.2.3</span> Data Augmentation</a></li>
  <li><a href="#arquitectura-de-una-red-neuronal-convolucional" id="toc-arquitectura-de-una-red-neuronal-convolucional" class="nav-link" data-scroll-target="#arquitectura-de-una-red-neuronal-convolucional"><span class="header-section-number">4.2.4</span> Arquitectura de una red neuronal convolucional</a></li>
  <li><a href="#aplicación-en-el-dataset" id="toc-aplicación-en-el-dataset" class="nav-link" data-scroll-target="#aplicación-en-el-dataset"><span class="header-section-number">4.2.5</span> Aplicación en el dataset</a></li>
  </ul></li>
  <li><a href="#módulo-de-recomendaciones-personalizadas" id="toc-módulo-de-recomendaciones-personalizadas" class="nav-link" data-scroll-target="#módulo-de-recomendaciones-personalizadas"><span class="header-section-number">4.3</span> Módulo de recomendaciones personalizadas</a>
  <ul class="collapse">
  <li><a href="#limpieza-de-los-datos" id="toc-limpieza-de-los-datos" class="nav-link" data-scroll-target="#limpieza-de-los-datos"><span class="header-section-number">4.3.1</span> Limpieza de los datos</a></li>
  <li><a href="#arquitectura-del-modelo" id="toc-arquitectura-del-modelo" class="nav-link" data-scroll-target="#arquitectura-del-modelo"><span class="header-section-number">4.3.2</span> Arquitectura del modelo</a></li>
  <li><a href="#métricas-obtenidas-por-el-modelo" id="toc-métricas-obtenidas-por-el-modelo" class="nav-link" data-scroll-target="#métricas-obtenidas-por-el-modelo"><span class="header-section-number">4.3.3</span> Métricas obtenidas por el modelo</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#herramienta-web" id="toc-herramienta-web" class="nav-link" data-scroll-target="#herramienta-web"><span class="header-section-number">5</span> Herramienta web</a>
  <ul class="collapse">
  <li><a href="#despliegue-de-los-modelos" id="toc-despliegue-de-los-modelos" class="nav-link" data-scroll-target="#despliegue-de-los-modelos"><span class="header-section-number">5.1</span> Despliegue de los modelos</a></li>
  </ul></li>
  <li><a href="#resultados-generales-y-discusión" id="toc-resultados-generales-y-discusión" class="nav-link" data-scroll-target="#resultados-generales-y-discusión"><span class="header-section-number">6</span> Resultados generales y discusión</a></li>
  <li><a href="#conclusiones-y-recomendaciones" id="toc-conclusiones-y-recomendaciones" class="nav-link" data-scroll-target="#conclusiones-y-recomendaciones"><span class="header-section-number">7</span> Conclusiones y recomendaciones</a></li>
  <li><a href="#anexos" id="toc-anexos" class="nav-link" data-scroll-target="#anexos"><span class="header-section-number">8</span> Anexos</a>
  <ul class="collapse">
  <li><a href="#videos-explicativos" id="toc-videos-explicativos" class="nav-link" data-scroll-target="#videos-explicativos"><span class="header-section-number">8.1</span> Videos explicativos</a></li>
  <li><a href="#aspectos-éticos-de-los-modelos" id="toc-aspectos-éticos-de-los-modelos" class="nav-link" data-scroll-target="#aspectos-éticos-de-los-modelos"><span class="header-section-number">8.2</span> Aspectos éticos de los modelos</a>
  <ul class="collapse">
  <li><a href="#presentación-del-modelo" id="toc-presentación-del-modelo" class="nav-link" data-scroll-target="#presentación-del-modelo"><span class="header-section-number">8.2.1</span> Presentación del modelo</a></li>
  <li><a href="#uso-de-los-modelos" id="toc-uso-de-los-modelos" class="nav-link" data-scroll-target="#uso-de-los-modelos"><span class="header-section-number">8.2.2</span> Uso de los modelos</a></li>
  </ul></li>
  <li><a href="#contribuciones-individuales" id="toc-contribuciones-individuales" class="nav-link" data-scroll-target="#contribuciones-individuales"><span class="header-section-number">8.3</span> Contribuciones individuales</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p><strong>Aplicaciones de Redes Neuronales en el desarrollo de un Sistema Inteligente Integrado para Predicción, Clasificación y Recomendación en Comercio Electrónico</strong></p>
<section id="resumen-ejecutivo" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Resumen ejecutivo</h1>
</section>
<section id="introducción" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Introducción</h1>
<p>El comercio electrónico, que puede definirse según <span class="citation" data-cites="ibm2024">Hayes and Downie (<a href="#ref-ibm2024" role="doc-biblioref">2024</a>)</span> como el “proceso de compraventa de bienes y servicios a través de internet”, se facilitan a través de diferentes plataformas en línea como lo son principalmente las aplicaciones móviles y sitios web. En sus primeros años se definió como un proceso simple que incluía transacciones de compra entre vendedores y sus clientes por medio de sitios web, no obstante, a medida que se han desarrollado tecnologías más complejas y se han ampliado las dinámicas comerciales entre personas y empresas, el comercio electrónico ha comenzado a abarcar otras aplicaciones como:</p>
<ul>
<li>Sitios web de comercios minoristas que también tienen tiendas físicas.</li>
<li>Plataformas de economía colaborativa que facilitan la adquisición de servicios.</li>
<li>Sitios de redes sociales, por ejemplo, Facebook Marketplace, donde los usuarios pueden ofrecer y vender bienes y servicios.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="walmart.jpg" class="img-fluid figure-img"></p>
<figcaption>El comercio masivo presenta nuevos desafíos que con la llegada de la inteligencia artifical aparecen soluciones a la medida de sus problemas. Tomado de <a href="https://www.youtube.com/watch?v=XRRu9cea1sg" class="uri">https://www.youtube.com/watch?v=XRRu9cea1sg</a></figcaption>
</figure>
</div>
<p>Considerando lo anterior, y si se tiene un enfoque especial en la dinámica de comercio electrónico generado por las compañías que ofrecen bienes a través de un sitio web, abarcando grandes multitudes de clientes (y posibles clientes), es posible observar que se presentan una serie de retos a la hora de desarrollar estrategias de marketing adecuadas y que aporten valor al negocio. Algunos de estos retos, definidos después de contrastar con lo dicho por <span class="citation" data-cites="danielb2023">Bengochea (<a href="#ref-danielb2023" role="doc-biblioref">2023</a>)</span> son:</p>
<ol type="1">
<li><p>¿Cómo mejorar las actividades logísticas y de gestión del inventario, que pueden verse afectadas a causa de una mala (o nula) estimación de la demanda futura o una clasificación incorrecta de los productos que se ofrecen a los clientes?</p></li>
<li><p>¿De qué manera mejorar la retención de clientes y brindar una experiencia personalizada a cada comprador, disminuyendo así la pérdida de ventas potenciales y mejorando la reputación en el mercado?</p></li>
</ol>
<p>Estos retos pueden ser abordados desde diferentes perspectivas. sin embargo, el presente trabajo pretende plantear soluciones desde las temáticas vistas en el curso de Redes Neuronales y Algoritmos Bioinspirados, desarrollando herramientas que puedan servir de ayuda a la hora de tomar decisiones por parte del equipo de mercadeo en la sección dedicada al comercio electrónico de una compañía. Para esto, se plantearán los siguientes objetivos que esperan ser alcanzados a lo largo del trabajo aquí desarrollado.</p>
<p><strong>Objetivo general</strong></p>
<p>Desarrollar un sistema basado en aprendizaje profundo que integre predicción de demanda, clasificación de productos y recomendaciones personalizadas en la dinámica de negocio de una empresa de comercio electrónico.</p>
<p><strong>Objetivos específicos</strong></p>
<ul>
<li><p>Desarrollar un modelo de redes neuronales que pueda estimar la demanda durante los próximos 30 días de acuerdo con información histórica proporcionada por la tienda de comercio electrónico.</p></li>
<li><p>Desarrollar un modelo de redes neuronales que pueda clasificar automáticamente un producto de acuerdo con categorías previamente establecidas, a fin de facilitar la gesión de inventarios.</p></li>
<li><p>Diseñar un sistema de recomendaciones de productos de acuerdo con el comportamiento presentado por un usuario de la tienda a la hora de navegar a través del sitio web de comercio electrónico.</p></li>
</ul>
</section>
<section id="metodología" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Metodología</h1>
<p>Para el desarrollo del presente trabajo se planteó una metodología basada en <strong>Design Thinking</strong>, pues garantiza un enfoque centrado en el usuario (que para este caso, será la tienda de comercio electrónico que requiere una mejora en sus estrategias de marketing para abordar los retos anteriormente mencionados), el cual permitirá comprender sus necesidades y diseñar una solución innovadora. Dicha metodología será desarrollada en las cinco fases que se describena a continuación:</p>
<ol type="1">
<li><strong>Empatizar:</strong></li>
</ol>
<ul>
<li>Análisis del comportamiento de clientes y tendencias de compra en comercio electrónico.</li>
<li>Identificación de problemas clave mediante análisis de datos históricos.</li>
</ul>
<ol start="2" type="1">
<li><strong>Definir:</strong></li>
</ol>
<ul>
<li>Formulación de los problemas a resolver con base en la información obtenida en la fase de empatización.</li>
<li>Identificación de métricas clave para evaluar el desempeño de los modelos de redes neuronales artificiales.</li>
</ul>
<ol start="3" type="1">
<li><strong>Idear:</strong></li>
</ol>
<ul>
<li>Propuestas de soluciones utilizando aprendizaje profundo para cada módulo del sistema.</li>
<li>Comparación de enfoques para determinar el más adecuado según los recursos disponibles.</li>
</ul>
<ol start="4" type="1">
<li><strong>Prototipar:</strong></li>
</ol>
<ul>
<li>Desarrollo inicial de modelos de predicción de demanda, clasificación de productos y recomendación personalizada.</li>
<li>Construcción de una interfaz web interactiva para visualizar los resultados.</li>
</ul>
<ol start="5" type="1">
<li><strong>Testear:</strong></li>
</ol>
<ul>
<li>Evaluación de los modelos con métricas como RMSE, MAE, precisión y F1-score.</li>
<li>Pruebas con usuarios para validar la funcionalidad y usabilidad de la herramienta web.</li>
</ul>
<p>Por medio de este enfoque se espera asegurar que las soluciones implementadas sean funcionales, escalables y alineadas con las necesidades reales de la empresa de comercio electrónico.</p>
<section id="módulos" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="módulos"><span class="header-section-number">3.1</span> Módulos</h2>
<p>Como se mencionó anteriormente, el trabajo será dividido en los siguientes módulos, con el fin de separar adecuadamente las actividades de diseño y desarrollo relacionadas con cada uno de los objetivos; posteriormente los resultados obtenidos en cada módulo serán unificados para el proceso de análisis de resultados y despliegue de la herramienta web que integrará todo el sistema de soluciones establecido.</p>
<ul>
<li>Módulo de <strong>predicción de la demanda</strong>.</li>
<li>Módulo de <strong>clasificación de productos</strong>.</li>
<li>Módulo de <strong>recomendaciones personalizadas</strong>.</li>
</ul>
</section>
</section>
<section id="desarrollo-técnico-por-módulo" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Desarrollo técnico por módulo</h1>
<section id="módulo-de-predicción-de-la-demanda" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="módulo-de-predicción-de-la-demanda"><span class="header-section-number">4.1</span> Módulo de predicción de la demanda</h2>
<p>El problema de predicción de inventario es un desafío recurrente en la industria del comercio electrónico. Modelos de negocio como el <em>dropshipping</em> dependen fundamentalmente de una gestión eficiente de inventarios para garantizar entregas rápidas y minimizar costos operativos. Por ello, el análisis de esta problemática se vuelve esencial para la optimización de la cadena de suministro y la mejora en la toma de decisiones estratégicas.</p>
<p>En esta sección, nos enfocamos en entrenar y desarrollar un producto de inteligencia artificial basado en redes neuronales recurrentes con múltiples salidas, orientado al pronóstico de ventas en almacenes de cadena, específicamente para Walmart. Este problema fue tomado de <a href="https://www.kaggle.com/datasets/aslanahmedov/walmart-sales-forecast/data?authuser=1">Kaggle</a>, en la que sugiere seguir una metodología basada en el <strong>Cross-Industry Standard Process for Data Mining (CRISP-DM)</strong>, un marco ampliamente utilizado en proyectos de minería de datos e inteligencia artificial.</p>
<p>Dicha metodología se estructura en las siguientes etapas:</p>
<section id="comprensión-del-negocio" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="comprensión-del-negocio"><span class="header-section-number">4.1.1</span> <strong>1. Comprensión del Negocio</strong></h3>
<p>Todo producto tecnológico que aspire a ofrecer una solución rentable debe centrarse en el entendimiento del negocio. En el caso del pronóstico de ventas para Walmart, la precisión en la predicción del inventario impacta directamente la rentabilidad y eficiencia operativa. Sin embargo, más allá de este caso específico, es crucial evaluar el impacto de una solución similar en otros modelos de negocio, como pequeñas y medianas empresas o plataformas de comercio electrónico.</p>
</section>
<section id="comprensión-de-los-datos" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="comprensión-de-los-datos"><span class="header-section-number">4.1.2</span> <strong>2. Comprensión de los Datos</strong></h3>
<p>El insumo inicial de todo modelo de aprendizaje automático (ML) o inteligencia artificial (IA) son los datos. En este caso, más que simplemente utilizarlos como materia prima, buscamos comprenderla y mostrar cuál debería ser la información mínima necesaria para un negocio que aspire a desarrollar un modelo de pronóstico de ventas efectivo, capaz de apoyar la planificación de inventario.</p>
<section id="análisis-descriptivo" class="level4" data-number="4.1.2.1">
<h4 data-number="4.1.2.1" class="anchored" data-anchor-id="análisis-descriptivo"><span class="header-section-number">4.1.2.1</span> Análisis Descriptivo</h4>
</section>
</section>
<section id="preparación-de-los-datos" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="preparación-de-los-datos"><span class="header-section-number">4.1.3</span> <strong>3. Preparación de los Datos</strong></h3>
<p>En esta etapa, realizamos la limpieza, transformación y estructuración de los datos para su uso en el modelo. Algunas de las tareas clave incluyen:<br>
- Manejo de valores faltantes y datos atípicos.<br>
- Generación de características (<em>feature engineering</em>), como tendencias de ventas, estacionalidad y efectos de días festivos.<br>
- Normalización y escalado de variables.<br>
- División del conjunto de datos en entrenamiento, validación y prueba.</p>
</section>
<section id="modelado" class="level3" data-number="4.1.4">
<h3 data-number="4.1.4" class="anchored" data-anchor-id="modelado"><span class="header-section-number">4.1.4</span> <strong>4. Modelado</strong></h3>
<p>Aquí implementamos una red neuronal recurrente (<em>Recurrent Neural Network</em>, RNN) con múltiples salidas, aprovechando su capacidad para capturar patrones temporales en series de tiempo. Se explorarán variantes como <em>Long Short-Term Memory</em> (LSTM) y <em>Gated Recurrent Units</em> (GRU) para mejorar el rendimiento del modelo. Además, se comparará el desempeño de estos modelos con enfoques más tradicionales, como ARIMA, para evaluar su eficacia.</p>
</section>
<section id="evaluación" class="level3" data-number="4.1.5">
<h3 data-number="4.1.5" class="anchored" data-anchor-id="evaluación"><span class="header-section-number">4.1.5</span> <strong>5. Evaluación</strong></h3>
<p>La validación del modelo se realizará utilizando métricas clave para problemas de series de tiempo, tales como:<br>
- <strong>Error Absoluto Medio (MAE)</strong><br>
- <strong>Error Porcentual Absoluto Medio (MAPE)</strong></p>
<p>Se evaluará la capacidad del modelo para capturar tendencias de ventas y su estabilidad en distintos escenarios, incluyendo cambios en la demanda y eventos atípicos.</p>
</section>
<section id="despliegue" class="level3" data-number="4.1.6">
<h3 data-number="4.1.6" class="anchored" data-anchor-id="despliegue"><span class="header-section-number">4.1.6</span> <strong>6. Despliegue</strong></h3>
<p>Finalmente, el modelo se integrará en un sistema de producción que permita generar pronósticos segun los inputs suminisrados. Para ello, se desarrolló:<br>
1. <strong>API en FastAPI</strong> para servir las predicciones.</p>
<ol start="2" type="1">
<li><strong>Dashboards interactivos</strong> una herramienta web que permitirá visualizar pronósticos y tomar decisiones estratégicas en la gestión de inventario para este ejemplo particular.</li>
</ol>
</section>
</section>
<section id="módulo-de-clasificación-de-productos" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="módulo-de-clasificación-de-productos"><span class="header-section-number">4.2</span> Módulo de clasificación de productos</h2>
<p>Frente a los avances en la calidad de las imágenes digitales, junto con la facilidad de acceso a GPUs, clasificar de maner automática productos es una opción muy atractiva para la mayoría de empresas. Una tarea que anteriormente debía ser manual, hoy en día es automática y cada vez más fácil de desarrollar, lo que se permite disminuir la cantidad de errores que tengan un impacto económico en el negocio.</p>
<p>Para afrontar este problema se desarrollo un modelo de visión artificial utilizando el dataset propuesto, conformado por imágenes etiquetadas en camisetas, jeans, sofas y televisiones. Inicialmente se puede observar como el dataset es bastante pequeno, lo que puede dificultar tener un modelo que pueda generalizarse hacia nuevas imágenes. Se propone un modelo basado en redes neuronales convolucionales debido a sus altas capacidades para clasificar correctamente datos del tipo de imágenes.</p>
<p>Para afrontar este problema, y el desarrollo general del modelo se hizo lo siguiente:</p>
<section id="limpieza-del-dataset" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="limpieza-del-dataset"><span class="header-section-number">4.2.1</span> Limpieza del dataset</h3>
<p>Si observamos algunos grupos, especialmente el de televisiones, tienen imágenes que no estan relacionadas con la temática, por lo que las eliminamos para no crear sesgos durante el entrenamiento.</p>
</section>
<section id="preprocesamiento-de-las-imágenes" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="preprocesamiento-de-las-imágenes"><span class="header-section-number">4.2.2</span> Preprocesamiento de las imágenes</h3>
<section id="normalización-de-las-imágenes" class="level4" data-number="4.2.2.1">
<h4 data-number="4.2.2.1" class="anchored" data-anchor-id="normalización-de-las-imágenes"><span class="header-section-number">4.2.2.1</span> Normalización de las imágenes</h4>
<p>Se recorren las carpetas de diferentes categorías de productos para cargar las imágenes disponibles. Para garantizar una uniformidad en los datos, cada imagen se convierte al formato <strong>RGB</strong> (tres canales de color) y se redimensiona a un tamaño estándar de <strong>224x224 píxeles</strong>. Posteriormente, se normalizan los valores de los píxeles dividiéndolos entre 255, lo que los escala a un rango entre <strong>0 y 1</strong>, mejorando la estabilidad del entrenamiento de la red neuronal.</p>
</section>
<section id="conversión-a-arrays-numéricos" class="level4" data-number="4.2.2.2">
<h4 data-number="4.2.2.2" class="anchored" data-anchor-id="conversión-a-arrays-numéricos"><span class="header-section-number">4.2.2.2</span> Conversión a arrays numéricos</h4>
<p>Una vez procesadas, las imágenes se almacenan en un arreglo de NumPy para facilitar su manipulación y procesamiento. De manera similar, las etiquetas correspondientes a cada imagen se almacenan en otro arreglo.</p>
</section>
</section>
<section id="data-augmentation" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="data-augmentation"><span class="header-section-number">4.2.3</span> Data Augmentation</h3>
<p>Para mejorar la generalización del modelo y reducir el sobreajuste, se aplica <strong>data augmentation</strong> en las imágenes de entrenamiento. Se utilizan técnicas como:</p>
<ul>
<li><p>Rotaciones de hasta 30 grados.</p></li>
<li><p>Desplazamientos horizontales y verticales (20% del tamaño de la imagen).</p></li>
<li><p>Transformaciones de corte y zoom.</p></li>
<li><p>Reflejo de las imágenes</p></li>
</ul>
<p>Estas modificaciones permiten simular nuevas imágenes a partir del conjunto de entrenamiento existente, ayudando al modelo a aprender características más robustas, lo cual es especialmente útil para el algoritmo del descenso del gradiente estocástico ya que al procesarse en batches permite distorsionar las imágenes en el bache que se esta procesando y no es necesario almacenar las nuevas imágenes.</p>
<p>Con esta técnica las 636 imágenes que había para cada batch se vuelven 20352, lo que permite obtener mayor información durante el entrenamiento.</p>
</section>
<section id="arquitectura-de-una-red-neuronal-convolucional" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="arquitectura-de-una-red-neuronal-convolucional"><span class="header-section-number">4.2.4</span> Arquitectura de una red neuronal convolucional</h3>
<p>Las redes neuronales convolucionales surgieron debido a la aparición de bases de datos masivas clasificadas en una gran variedad de posibilidades, y se mostraron como una alternativa muy poderosa para este tipo de problemas.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="funcionamiento_cnn.png" class="img-fluid figure-img"></p>
<figcaption>Ilustración acerca del funcionamiento de una red neuronal convolucional. Tomado de An Introduction to Statistical Learning.</figcaption>
</figure>
</div>
<p>Como se puede ver en la ilustración, estas redes imitan hasta cierto punto el comportamiento para reconocer patrones basado en características específicas, parten desde características diminutas como los bordes, el color y similares, y empiezan a evolucionar a características más notables como las orejas, los ojos y similares.</p>
<section id="capas-convolucionales" class="level4" data-number="4.2.4.1">
<h4 data-number="4.2.4.1" class="anchored" data-anchor-id="capas-convolucionales"><span class="header-section-number">4.2.4.1</span> Capas convolucionales</h4>
<p>Se basan en filtros convolucionales los cuales consisten en plantillas que determinan la presencia de alguna característica particular en la imagen. Para lograr lo anterior se basan en la operación llamada convolución, donde ilustramos su funcionamiento de la siguiente manera:</p>
<p>[</p>
<span class="math display">\[\begin{bmatrix}
a &amp; b &amp; c \\
d &amp; e &amp; f \\
g &amp; h &amp; i \\
j &amp; k &amp; l
\end{bmatrix}\]</span>
<p>]</p>
<p>[</p>
<span class="math display">\[\begin{bmatrix}
\alpha &amp; \beta \\
\gamma &amp; \delta
\end{bmatrix}\]</span>
<p>]</p>
<p>[</p>
<span class="math display">\[\begin{bmatrix}
a\alpha + b\beta + d\gamma + e\delta &amp; b\alpha + c\beta + e\gamma + f\delta \\
d\alpha + e\beta + g\gamma + h\delta &amp; e\alpha + f\beta + h\gamma + i\delta \\
g\alpha + h\beta + j\gamma + k\delta &amp; h\alpha + i\beta + k\gamma + l\delta
\end{bmatrix}\]</span>
<p>]</p>
<p>La convolución en imágenes consiste en aplicar un filtro pequeño sobre submatrices de la imagen original, multiplicando cada elemento correspondiente y sumando los resultados. Si una región de la imagen se parece al filtro, el valor resultante será alto, resaltando esa zona. Si no se parece, el valor será bajo. Este proceso permite detectar patrones y se usa en redes neuronales convolucionales (CNNs) para reconocimiento de imágenes.</p>
</section>
<section id="capas-de-pooling" class="level4" data-number="4.2.4.2">
<h4 data-number="4.2.4.2" class="anchored" data-anchor-id="capas-de-pooling"><span class="header-section-number">4.2.4.2</span> Capas de pooling</h4>
<p>Para condensar imágenes en un resumen más pequeño utilizando técnicas como <strong>max pooling</strong> y <strong>average pooling</strong>.</p>
<ul>
<li><p><strong>Max pooling</strong> selecciona el valor <strong>máximo</strong> dentro de cada bloque de la imagen (por ejemplo, de 2 ), lo que ayuda a resaltar las características más importantes.</p></li>
<li><p><strong>Average pooling</strong> en cambio, calcula el <strong>promedio</strong> de los valores en cada bloque, produciendo una versión más suavizada de la imagen.</p></li>
</ul>
</section>
<section id="capa-de-activación-relu" class="level4" data-number="4.2.4.3">
<h4 data-number="4.2.4.3" class="anchored" data-anchor-id="capa-de-activación-relu"><span class="header-section-number">4.2.4.3</span> <strong>Capa de Activación (ReLU)</strong></h4>
<p>Se utiliza la función ReLU (Rectified Linear Unit) para introducir no linealidad y mejorar la capacidad de aprendizaje de la red.&nbsp;Convierte valores negativos en cero, manteniendo los positivos sin cambios.</p>
</section>
<section id="capas-de-flattening" class="level4" data-number="4.2.4.4">
<h4 data-number="4.2.4.4" class="anchored" data-anchor-id="capas-de-flattening"><span class="header-section-number">4.2.4.4</span> Capas de Flattening</h4>
<p>Permite transformar las matrices de características que se forman al procesar las imágenes en vectores que pueden ser procesadas por capas completamente conectadas</p>
</section>
<section id="capas-completamente-conectadas" class="level4" data-number="4.2.4.5">
<h4 data-number="4.2.4.5" class="anchored" data-anchor-id="capas-completamente-conectadas"><span class="header-section-number">4.2.4.5</span> <strong>Capas completamente conectadas</strong></h4>
<p>Estas capas actúan como un <strong>clasificador</strong>, combinando la información extraída en las capas previas para hacer predicciones. Suele utilizarse la función softmax para clasificación múltiple y la función sigmoide para clasificación binaria.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cnn_arquitectura.webp" class="img-fluid figure-img"></p>
<figcaption>Arquitectura de una red neuronal convolucional. Tomado de https://developersbreach.com/convolution-neural-network-deep-learning/</figcaption>
</figure>
</div>
</section>
</section>
<section id="aplicación-en-el-dataset" class="level3" data-number="4.2.5">
<h3 data-number="4.2.5" class="anchored" data-anchor-id="aplicación-en-el-dataset"><span class="header-section-number">4.2.5</span> Aplicación en el dataset</h3>
<section id="arquitectura-propia" class="level4" data-number="4.2.5.1">
<h4 data-number="4.2.5.1" class="anchored" data-anchor-id="arquitectura-propia"><span class="header-section-number">4.2.5.1</span> Arquitectura propia</h4>
<p>Desarrollamos la siguiente arquitectura propia:</p>
<ul>
<li><p><strong>Capas Convolucionales y de Normalización</strong></p>
<ul>
<li><p>Se aplican <strong>convoluciones</strong> con filtros de 3×33 ×3 para detectar patrones en la imagen.</p></li>
<li><p>Se usa <strong>Batch Normalization</strong> después de cada convolución para estabilizar el aprendizaje y mejorar la convergencia.</p></li>
<li><p>Se emplea <strong>Max Pooling</strong> (2×22 ×2) después de cada bloque convolucional para reducir la dimensionalidad.</p></li>
</ul></li>
<li><p><strong>Bloques Convolucionales</strong></p>
<ul>
<li><p><strong>Bloque 1:</strong> 32 filtros, seguido de normalización y max pooling.</p></li>
<li><p><strong>Bloque 2:</strong> 64 filtros, normalización y max pooling.</p></li>
<li><p><strong>Bloque 3:</strong> 128 filtros, normalización y max pooling.</p></li>
<li><p><strong>Bloque 4 :</strong> 256 filtros, normalización y max pooling.</p></li>
</ul></li>
<li><p><strong>Aplanamiento y Capas Densas</strong></p>
<ul>
<li><p>Se aplanan las características extraídas en un vector de entrada para la parte densa.</p></li>
<li><p>Se añade una <strong>capa densa</strong> de 128 neuronas con <strong>ReLU</strong>.</p></li>
<li><p>Se incorpora <strong>Dropout (50%)</strong> para reducir el overfitting.</p></li>
</ul></li>
<li><p><strong>Capa de Salida</strong></p>
<ul>
<li><p>La última capa tiene tantas neuronas como clases en la clasificación.</p></li>
<li><p>Se usa la activación <strong>Softmax</strong> para generar probabilidades sobre cada categoría.</p></li>
</ul></li>
<li><p><strong>Compilación del Modelo</strong></p>
<ul>
<li><p>Se emplea el optimizador <strong>Adam</strong> para el entrenamiento.</p></li>
<li><p>La función de pérdida es <strong>categorical crossentropy</strong> (o <strong>sparse categorical crossentropy</strong> si las etiquetas no están en formato one-hot).</p></li>
<li><p>Se mide la precisión (<strong>accuracy</strong>) como métrica principal.</p></li>
</ul></li>
</ul>
<section id="matriz-de-confusión" class="level5" data-number="4.2.5.1.1">
<h5 data-number="4.2.5.1.1" class="anchored" data-anchor-id="matriz-de-confusión"><span class="header-section-number">4.2.5.1.1</span> Matriz de confusión</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="confusion1.png" class="img-fluid figure-img"></p>
<figcaption>Matriz de confusión para la red neuronal convolucional. Elaboración propia.</figcaption>
</figure>
</div>
<p>Podemos ver como para la clase 1, el modelo no es capaz de reconocerla bien, como se observa en el reporte de clasificación, esta corresponde a los sofas, con lo cual el modelo presenta una gran cantidad de errores para ese tipo de imágenes.</p>
</section>
<section id="métricas-obtenidas" class="level5" data-number="4.2.5.1.2">
<h5 data-number="4.2.5.1.2" class="anchored" data-anchor-id="métricas-obtenidas"><span class="header-section-number">4.2.5.1.2</span> Métricas obtenidas</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rendimiento.png" class="img-fluid figure-img"></p>
<figcaption>Evolución de la precisión y la función de pérdida en el entrenamiento y la validación. Elaboración propia.</figcaption>
</figure>
</div>
</section>
<section id="reporte-de-clasificación" class="level5" data-number="4.2.5.1.3">
<h5 data-number="4.2.5.1.3" class="anchored" data-anchor-id="reporte-de-clasificación"><span class="header-section-number">4.2.5.1.3</span> Reporte de clasificación</h5>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Clase</th>
<th>Precisión</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Soporte</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jeans</td>
<td>0.95</td>
<td>0.97</td>
<td>0.96</td>
<td>40</td>
</tr>
<tr class="even">
<td>Sofa</td>
<td>1.00</td>
<td>0.07</td>
<td>0.14</td>
<td>40</td>
</tr>
<tr class="odd">
<td>T-Shirt</td>
<td>1.00</td>
<td>0.95</td>
<td>0.97</td>
<td>40</td>
</tr>
<tr class="even">
<td>TV</td>
<td>0.49</td>
<td>0.95</td>
<td>0.64</td>
<td>40</td>
</tr>
<tr class="odd">
<td><strong>Accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.74</strong></td>
<td><strong>160</strong></td>
</tr>
<tr class="even">
<td><strong>Macro Avg</strong></td>
<td>0.86</td>
<td>0.74</td>
<td>0.68</td>
<td>160</td>
</tr>
<tr class="odd">
<td><strong>Weighted Avg</strong></td>
<td>0.86</td>
<td>0.74</td>
<td>0.68</td>
<td>160</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="modelo-preentrenado" class="level4" data-number="4.2.5.2">
<h4 data-number="4.2.5.2" class="anchored" data-anchor-id="modelo-preentrenado"><span class="header-section-number">4.2.5.2</span> Modelo preentrenado</h4>
<p>Debido a los problemas presentados con el problema propio, desarrollamos también un modelo preentrenado en Imagenet, lo cual es una alternativa muy atractiva al ser un conjunto de datos pequeno, por lo que esto puede ayudar a mejorar el rendimiento del modelo.</p>
<section id="arquitectura-agregada-al-modelo-preentrenado" class="level5" data-number="4.2.5.2.1">
<h5 data-number="4.2.5.2.1" class="anchored" data-anchor-id="arquitectura-agregada-al-modelo-preentrenado"><span class="header-section-number">4.2.5.2.1</span> Arquitectura agregada al modelo preentrenado</h5>
<ul>
<li><p><strong>GlobalAveragePooling2D</strong></p>
<ul>
<li><p>Reduce la dimensionalidad de los mapas de características mediante el cálculo del promedio de cada filtro convolucional.</p></li>
<li><p>Ayuda a disminuir el número de parámetros y mejora la eficiencia del modelo.</p></li>
</ul></li>
<li><p><strong>Capa Densa (128 neuronas, ReLU)</strong></p>
<ul>
<li><p>Introduce una capa completamente conectada para aprender combinaciones avanzadas de características.</p></li>
<li><p>La activación <strong>ReLU</strong> mejora la capacidad de aprendizaje al introducir no linealidad.</p></li>
</ul></li>
<li><p><strong>Dropout (50%)</strong></p>
<ul>
<li><p>Apaga aleatoriamente el 50% de las neuronas en cada iteración durante el entrenamiento.</p></li>
<li><p>Reduce el riesgo de sobreajuste, haciendo que la red sea más robusta y generalizable.</p></li>
</ul></li>
<li><p><strong>Capa de Salida (Softmax)</strong></p>
<ul>
<li><p>Tiene tantas neuronas como categorías a clasificar.</p></li>
<li><p>Usa <strong>Softmax</strong> para convertir las salidas en probabilidades, asegurando que la suma sea 1 y permitiendo la clasificación de la imagen en una categoría específica.</p></li>
</ul></li>
</ul>
</section>
<section id="matriz-de-confusión-1" class="level5" data-number="4.2.5.2.2">
<h5 data-number="4.2.5.2.2" class="anchored" data-anchor-id="matriz-de-confusión-1"><span class="header-section-number">4.2.5.2.2</span> Matriz de confusión</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="confusion2.png" class="img-fluid figure-img"></p>
<figcaption>Matriz de confusión modelo preentrenado. Elaboración propia.</figcaption>
</figure>
</div>
</section>
<section id="evolución-métricas" class="level5" data-number="4.2.5.2.3">
<h5 data-number="4.2.5.2.3" class="anchored" data-anchor-id="evolución-métricas"><span class="header-section-number">4.2.5.2.3</span> Evolución métricas</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rendimeinto2.png" class="img-fluid figure-img"></p>
<figcaption>Evolución de la precisión y la pérdida en entrenamiento y validación. Elaboración propia.</figcaption>
</figure>
</div>
</section>
<section id="reporte-de-clasificación-1" class="level5" data-number="4.2.5.2.4">
<h5 data-number="4.2.5.2.4" class="anchored" data-anchor-id="reporte-de-clasificación-1"><span class="header-section-number">4.2.5.2.4</span> Reporte de clasificación</h5>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Clase</th>
<th>Precisión</th>
<th>Recall</th>
<th>F1-Score</th>
<th>Soporte</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Jeans</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>40</td>
</tr>
<tr class="even">
<td>Sofa</td>
<td>1.00</td>
<td>1.00</td>
<td>1.00</td>
<td>40</td>
</tr>
<tr class="odd">
<td>T-Shirt</td>
<td>1.00</td>
<td>1.00</td>
<td>0.99</td>
<td>40</td>
</tr>
<tr class="even">
<td>TV</td>
<td>1.00</td>
<td>0.97</td>
<td>0.99</td>
<td>40</td>
</tr>
<tr class="odd">
<td><strong>Accuracy</strong></td>
<td></td>
<td></td>
<td><strong>0.99</strong></td>
<td><strong>160</strong></td>
</tr>
<tr class="even">
<td><strong>Macro Avg</strong></td>
<td>0.99</td>
<td>0.99</td>
<td>0.99</td>
<td>160</td>
</tr>
<tr class="odd">
<td><strong>Weighted Avg</strong></td>
<td>0.99</td>
<td>0.99</td>
<td>0.99</td>
<td>160</td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
</section>
<section id="módulo-de-recomendaciones-personalizadas" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="módulo-de-recomendaciones-personalizadas"><span class="header-section-number">4.3</span> Módulo de recomendaciones personalizadas</h2>
<p>Se desarrolló un modelo basado en redes neuronales y embeddings. Estos embeddings nos permiten representar datos categóricos o secuenciales, como las palabras, en espacios continuos donde pueden ser representados como vectores numéricos que capturen relaciones semánticas y similitudes.</p>
<section id="limpieza-de-los-datos" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="limpieza-de-los-datos"><span class="header-section-number">4.3.1</span> Limpieza de los datos</h3>
<p>Se eliminaron los símbolos y comas de los precios para convertirlos a valores numéricos. Luego, se codifican las variables categóricas, como el nombre del producto, la categoría principal y la subcategoría, utilizando <code>LabelEncoder</code>. Se convierten las variables <code>ratings</code> y <code>no_of_ratings</code> a tipo flotante para su correcto procesamiento.</p>
<p>Posteriormente, se normalizan los precios, las calificaciones y el número de valoraciones para escalarlos entre 0 y 1, lo que facilita el entrenamiento del modelo. Finalmente, los datos se dividen en conjuntos de entrenamiento y prueba, asegurando una correcta evaluación del modelo en datos no vistos.</p>
</section>
<section id="arquitectura-del-modelo" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="arquitectura-del-modelo"><span class="header-section-number">4.3.2</span> Arquitectura del modelo</h3>
<section id="embeddings" class="level4" data-number="4.3.2.1">
<h4 data-number="4.3.2.1" class="anchored" data-anchor-id="embeddings"><span class="header-section-number">4.3.2.1</span> Embeddings</h4>
<ul>
<li><p><strong>Producto</strong> - Representado con un embedding de 50 dimensiones.</p></li>
<li><p><strong>Categoría principal</strong> - Representado con un embedding de 10 dimensiones.</p></li>
<li><p><strong>Subcategoría</strong> - Representado con un embedding de 10 dimensiones.</p></li>
</ul>
<p>Cada una de las entradas categóricas se convierte en un vector a través de una <strong>capa de embedding</strong> y se aplana con <code>Flatten()</code>. Luego, estos vectores se concatenan con las características numéricas.</p>
</section>
<section id="características-numéricas" class="level4" data-number="4.3.2.2">
<h4 data-number="4.3.2.2" class="anchored" data-anchor-id="características-numéricas"><span class="header-section-number">4.3.2.2</span> Características numéricas</h4>
<p>Incluye las características de <code>discount_price</code>, <code>actual_price</code> y <code>no_of_ratings</code>.</p>
</section>
<section id="capas-modelo" class="level4" data-number="4.3.2.3">
<h4 data-number="4.3.2.3" class="anchored" data-anchor-id="capas-modelo"><span class="header-section-number">4.3.2.3</span> Capas modelo</h4>
<ul>
<li><p><strong>Capas de Entrada</strong>:</p>
<ul>
<li><code>product_input</code>, <code>main_cat_input</code>, <code>sub_cat_input</code>, <code>numeric_input</code>: Cuatro capas de entrada que reciben diferentes tipos de datos (producto, categoría principal, subcategoría y características numéricas).</li>
</ul></li>
<li><p><strong>Capas de Embedding</strong>:</p>
<ul>
<li><p><code>product_embedding</code>: Convierte el ID del producto en un vector de 50 dimensiones (11,867,600 parámetros).</p></li>
<li><p><code>main_cat_embedding</code>: Convierte la categoría principal en un vector de 10 dimensiones (200 parámetros).</p></li>
<li><p><code>sub_cat_embedding</code>: Convierte la subcategoría en un vector de 10 dimensiones (1,120 parámetros).</p></li>
</ul></li>
<li><p><strong>Capas de Flatten</strong>:</p>
<ul>
<li><code>flatten</code>, <code>flatten_1</code>, <code>flatten_2</code>: Aplanan los embeddings en vectores de una sola dimensión para facilitar la concatenación con los datos numéricos.</li>
</ul></li>
<li><p><strong>Capa de Concatenación</strong>:</p>
<ul>
<li><code>concatenate</code>: Une todas las características transformadas en un único vector de 73 dimensiones.</li>
</ul></li>
<li><p><strong>Capas Densas y Dropout</strong>:</p>
<ul>
<li><p><code>dense</code>: Capa densa con 128 neuronas y 9,472 parámetros.</p></li>
<li><p><code>dropout</code>: Capa de dropout para regularización.</p></li>
<li><p><code>dense_1</code>: Capa densa con 64 neuronas y 8,256 parámetros.</p></li>
<li><p><code>dropout_1</code>: Otra capa de dropout para reducir sobreajuste.</p></li>
</ul></li>
<li><p><strong>Capa de Salida</strong>:</p>
<ul>
<li><code>output</code>: Capa densa con 1 neurona para la predicción final (65 parámetros).</li>
</ul></li>
</ul>
</section>
</section>
<section id="métricas-obtenidas-por-el-modelo" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="métricas-obtenidas-por-el-modelo"><span class="header-section-number">4.3.3</span> Métricas obtenidas por el modelo</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="mae.png" class="img-fluid figure-img"></p>
<figcaption>Evolución de la pérdida y el MAE para el modelo de recomendación. Elaboración propia.</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="herramienta-web" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Herramienta web</h1>
<p>De acuerdo a lo que se ha venido presentando a lo largo de este ejercicio, los modelos de redes neuronales entrenados han sido desplegados en el sitio web titulado [título], donde la compañía de comercio electrónico y sus usuarios pueden acceder a los siguientes servicios:</p>
<ul>
<li>Visualización de gráficos de predicción de la demanda.</li>
<li>Ver clasificación automática de un producto, dada su imagen.</li>
<li>Recepción de recomendaciones personalizadas para diferentes perfiles de usuarios.</li>
</ul>
<section id="despliegue-de-los-modelos" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="despliegue-de-los-modelos"><span class="header-section-number">5.1</span> Despliegue de los modelos</h2>
<p>Los tres modelos que se desarrollaron y se explican en este reporte deben de ser desplegados para poder ponerlos al alcance de los demás y poder ser utilizados en el sitio web. Para lograr lo anterior utilizamos los servicios de <strong>Render</strong> y <strong>Digital Ocean</strong> para desplegar las APIs creadas utilizando FastAPI<strong>.</strong> Es importante reportar la complicación que se tuvo para el tercer modelo, el modelo de recomendación, debido a que computacionalmente es un modelo pesado por lo que el tier gratuito de Render se queda corto antes este modelo, también se intento usar el free tier de AWS sin embargo la memoria RAM que este ofrecía seguía quedándose corta, por lo que Digital Ocean, aprovechando los créditos otorgados por el GitHub Student Pack, nos permitió superar esa dificultad.</p>
</section>
</section>
<section id="resultados-generales-y-discusión" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Resultados generales y discusión</h1>
<p>Podemos ver como el modelo preentrenado para el modelo de visión artificial muestra una mejoría importante, si el modelo que se propuso inicialmente se hubiera utilizado, hubiera presentado problemas para clasificar los televisores, sin embargo, el preentrenado funciona muy bien ante todas estas situaciones.</p>
<p>El modelo de recomendación que se propuso presenta muy buenos resultados gracias al uso de modelos basados en embeddings, sin embargo, el problema que se enfrento aquí, es que computacionalmente es un modelo pesado, por lo que el entrenamiento es lento, y ponerlo a disposición como una API desplegada implica un mayor uso de recursos de los que se suele tener acceso de manera gratuita.</p>
</section>
<section id="conclusiones-y-recomendaciones" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Conclusiones y recomendaciones</h1>
</section>
<section id="anexos" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Anexos</h1>
<section id="videos-explicativos" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="videos-explicativos"><span class="header-section-number">8.1</span> Videos explicativos</h2>
<p>En los videos presentados a continuación se puede encontrar una breve descripción del funcionamiento de cada sección de la aplicación web, con un ejemplo real de utilización y posible interpretación de los resultados obtenidos.</p>
</section>
<section id="aspectos-éticos-de-los-modelos" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="aspectos-éticos-de-los-modelos"><span class="header-section-number">8.2</span> Aspectos éticos de los modelos</h2>
<p>Dentro de los aspectos éticos a considerar de estos modelos, hay dos aspectos principales, como se presenta el modelo y que uso se le da al mismo.</p>
<section id="presentación-del-modelo" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="presentación-del-modelo"><span class="header-section-number">8.2.1</span> Presentación del modelo</h3>
<p>Los modelos suelen presentarse a un público no especializado, por lo cual tratar de dar una presentación optimista del modelo sin que los demás se de den cuenta es posible, lo anterior, en busca de salir del paso, quedar bien, u obtener algún beneficio. Se tiene entonces una responsabilidad con el conocimiento que se posee para generar valor dentro del negocio.</p>
</section>
<section id="uso-de-los-modelos" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="uso-de-los-modelos"><span class="header-section-number">8.2.2</span> Uso de los modelos</h3>
<p>En el trabajo se presentan modelos poderosos que tienen capacidades de resolver el problema, sin embargo, muchas veces se debe tener en cuenta los sesgos que se pueden crear dentro del mismo. Que modelos de clasificación por ejemplo en un entorno bancario, tiendan a negar préstamos a grupos minoritarios basado únicamente en sesgos, lo anterior implica evaluar correctamente el uso de las características del modelo, si bien puede deberse a pensamientos arcaicos que se reflejan en los datos, es deber de la persona encargada de crear el modelo, superar esos retos para generar valor para el negocio adaptado a las necesidades de las nuevas generaciones.</p>
</section>
</section>
<section id="contribuciones-individuales" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="contribuciones-individuales"><span class="header-section-number">8.3</span> Contribuciones individuales</h2>
<p>Las contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo del presente trabajo se pueden observar en el video a continuación:</p>



<!-- -->


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-danielb2023" class="csl-entry" role="listitem">
Bengochea, Daniel. 2023. <span>“Los Retos Más Importantes En eCommerce y Cómo Solucionarlos.”</span> 2023. <a href="https://outvio.com/es/blog/retos-ecommerce/">https://outvio.com/es/blog/retos-ecommerce/</a>.
</div>
<div id="ref-ibm2024" class="csl-entry" role="listitem">
Hayes, Molly, and Amanda Downie. 2024. <span>“¿Qué Es El Comercio Electrónico?”</span> 2024. <a href="https://www.ibm.com/mx-es/topics/ecommerce">https://www.ibm.com/mx-es/topics/ecommerce</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Aplicaciones de Redes Neuronales"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-width: 250px</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    main-container-width: 90%</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-width: 8</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-height: 6</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    math: </span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">      method: mathjax</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">      options:</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">        TeX:</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">          equationNumbers: { autoNumber: "AMS" }</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Julián Castaño Pineda"</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Luis Andrés Altamar Romero"</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Catalina Restrepo Salgado"</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Tomás Rodríguez Taborda"</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2025-02-18"</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [redes neuronales artificiales, desarrollo web, python, series de tiempo, clasificación]</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "image.jpg"</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> ref.bib</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">  cache: true</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>**Aplicaciones de Redes Neuronales en el desarrollo de un Sistema Inteligente Integrado para Predicción, Clasificación y Recomendación en Comercio Electrónico**</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="fu"># Resumen ejecutivo</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introducción</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>El comercio electrónico, que puede definirse según @ibm2024 como el "proceso de compraventa de bienes y servicios a través de internet", se facilitan a través de diferentes plataformas en línea como lo son principalmente las aplicaciones móviles y sitios web. En sus primeros años se definió como un proceso simple que incluía transacciones de compra entre vendedores y sus clientes por medio de sitios web, no obstante, a medida que se han desarrollado tecnologías más complejas y se han ampliado las dinámicas comerciales entre personas y empresas, el comercio electrónico ha comenzado a abarcar otras aplicaciones como:</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Sitios web de comercios minoristas que también tienen tiendas físicas.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Plataformas de economía colaborativa que facilitan la adquisición de servicios.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Sitios de redes sociales, por ejemplo, Facebook Marketplace, donde los usuarios pueden ofrecer y vender bienes y servicios.</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="al">![El comercio masivo presenta nuevos desafíos que con la llegada de la inteligencia artifical aparecen soluciones a la medida de sus problemas. Tomado de &lt;https://www.youtube.com/watch?v=XRRu9cea1sg&gt;](walmart.jpg)</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>Considerando lo anterior, y si se tiene un enfoque especial en la dinámica de comercio electrónico generado por las compañías que ofrecen bienes a través de un sitio web, abarcando grandes multitudes de clientes (y posibles clientes), es posible observar que se presentan una serie de retos a la hora de desarrollar estrategias de marketing adecuadas y que aporten valor al negocio. Algunos de estos retos, definidos después de contrastar con lo dicho por @danielb2023 son:</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>¿Cómo mejorar las actividades logísticas y de gestión del inventario, que pueden verse afectadas a causa de una mala (o nula) estimación de la demanda futura o una clasificación incorrecta de los productos que se ofrecen a los clientes?</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>¿De qué manera mejorar la retención de clientes y brindar una experiencia personalizada a cada comprador, disminuyendo así la pérdida de ventas potenciales y mejorando la reputación en el mercado?</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>Estos retos pueden ser abordados desde diferentes perspectivas. sin embargo, el presente trabajo pretende plantear soluciones desde las temáticas vistas en el curso de Redes Neuronales y Algoritmos Bioinspirados, desarrollando herramientas que puedan servir de ayuda a la hora de tomar decisiones por parte del equipo de mercadeo en la sección dedicada al comercio electrónico de una compañía. Para esto, se plantearán los siguientes objetivos que esperan ser alcanzados a lo largo del trabajo aquí desarrollado.</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>**Objetivo general**</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>Desarrollar un sistema basado en aprendizaje profundo que integre predicción de demanda, clasificación de productos y recomendaciones personalizadas en la dinámica de negocio de una empresa de comercio electrónico.</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>**Objetivos específicos**</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Desarrollar un modelo de redes neuronales que pueda estimar la demanda durante los próximos 30 días de acuerdo con información histórica proporcionada por la tienda de comercio electrónico.</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Desarrollar un modelo de redes neuronales que pueda clasificar automáticamente un producto de acuerdo con categorías previamente establecidas, a fin de facilitar la gesión de inventarios.</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Diseñar un sistema de recomendaciones de productos de acuerdo con el comportamiento presentado por un usuario de la tienda a la hora de navegar a través del sitio web de comercio electrónico.</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="fu"># Metodología</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>Para el desarrollo del presente trabajo se planteó una metodología basada en **Design Thinking**, pues garantiza un enfoque centrado en el usuario (que para este caso, será la tienda de comercio electrónico que requiere una mejora en sus estrategias de marketing para abordar los retos anteriormente mencionados), el cual permitirá comprender sus necesidades y diseñar una solución innovadora. Dicha metodología será desarrollada en las cinco fases que se describena a continuación:</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Empatizar:**</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Análisis del comportamiento de clientes y tendencias de compra en comercio electrónico.</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Identificación de problemas clave mediante análisis de datos históricos.</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Definir:**</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Formulación de los problemas a resolver con base en la información obtenida en la fase de empatización.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Identificación de métricas clave para evaluar el desempeño de los modelos de redes neuronales artificiales.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>**Idear:**</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Propuestas de soluciones utilizando aprendizaje profundo para cada módulo del sistema.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Comparación de enfoques para determinar el más adecuado según los recursos disponibles.</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>**Prototipar:**</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Desarrollo inicial de modelos de predicción de demanda, clasificación de productos y recomendación personalizada.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Construcción de una interfaz web interactiva para visualizar los resultados.</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>**Testear:**</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Evaluación de los modelos con métricas como RMSE, MAE, precisión y F1-score.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Pruebas con usuarios para validar la funcionalidad y usabilidad de la herramienta web.</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>Por medio de este enfoque se espera asegurar que las soluciones implementadas sean funcionales, escalables y alineadas con las necesidades reales de la empresa de comercio electrónico.</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="fu">## Módulos</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>Como se mencionó anteriormente, el trabajo será dividido en los siguientes módulos, con el fin de separar adecuadamente las actividades de diseño y desarrollo relacionadas con cada uno de los objetivos; posteriormente los resultados obtenidos en cada módulo serán unificados para el proceso de análisis de resultados y despliegue de la herramienta web que integrará todo el sistema de soluciones establecido.</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Módulo de **predicción de la demanda**.</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Módulo de **clasificación de productos**.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Módulo de **recomendaciones personalizadas**.</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="fu"># Desarrollo técnico por módulo</span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="fu">## Módulo de predicción de la demanda</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>El problema de predicción de inventario es un desafío recurrente en la industria del comercio electrónico. Modelos de negocio como el *dropshipping* dependen fundamentalmente de una gestión eficiente de inventarios para garantizar entregas rápidas y minimizar costos operativos. Por ello, el análisis de esta problemática se vuelve esencial para la optimización de la cadena de suministro y la mejora en la toma de decisiones estratégicas.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>En esta sección, nos enfocamos en entrenar y desarrollar un producto de inteligencia artificial basado en redes neuronales recurrentes con múltiples salidas, orientado al pronóstico de ventas en almacenes de cadena, específicamente para Walmart. Este problema fue tomado de <span class="co">[</span><span class="ot">Kaggle</span><span class="co">](https://www.kaggle.com/datasets/aslanahmedov/walmart-sales-forecast/data?authuser=1)</span>, en la que sugiere seguir una metodología basada en el **Cross-Industry Standard Process for Data Mining (CRISP-DM)**, un marco ampliamente utilizado en proyectos de minería de datos e inteligencia artificial.</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>Dicha metodología se estructura en las siguientes etapas:</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="fu">### **1. Comprensión del Negocio**</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>Todo producto tecnológico que aspire a ofrecer una solución rentable debe centrarse en el entendimiento del negocio. En el caso del pronóstico de ventas para Walmart, la precisión en la predicción del inventario impacta directamente la rentabilidad y eficiencia operativa. Sin embargo, más allá de este caso específico, es crucial evaluar el impacto de una solución similar en otros modelos de negocio, como pequeñas y medianas empresas o plataformas de comercio electrónico.</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="fu">### **2. Comprensión de los Datos**</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>El insumo inicial de todo modelo de aprendizaje automático (ML) o inteligencia artificial (IA) son los datos. En este caso, más que simplemente utilizarlos como materia prima, buscamos comprenderla y mostrar cuál debería ser la información mínima necesaria para un negocio que aspire a desarrollar un modelo de pronóstico de ventas efectivo, capaz de apoyar la planificación de inventario.</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Análisis Descriptivo</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="fu">### **3. Preparación de los Datos**</span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>En esta etapa, realizamos la limpieza, transformación y estructuración de los datos para su uso en el modelo. Algunas de las tareas clave incluyen:\</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Manejo de valores faltantes y datos atípicos.\</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Generación de características (*feature engineering*), como tendencias de ventas, estacionalidad y efectos de días festivos.\</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Normalización y escalado de variables.\</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>División del conjunto de datos en entrenamiento, validación y prueba.</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="fu">### **4. Modelado**</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>Aquí implementamos una red neuronal recurrente (*Recurrent Neural Network*, RNN) con múltiples salidas, aprovechando su capacidad para capturar patrones temporales en series de tiempo. Se explorarán variantes como *Long Short-Term Memory* (LSTM) y *Gated Recurrent Units* (GRU) para mejorar el rendimiento del modelo. Además, se comparará el desempeño de estos modelos con enfoques más tradicionales, como ARIMA, para evaluar su eficacia.</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="fu">### **5. Evaluación**</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>La validación del modelo se realizará utilizando métricas clave para problemas de series de tiempo, tales como:\</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Error Absoluto Medio (MAE)**\</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Error Porcentual Absoluto Medio (MAPE)**</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>Se evaluará la capacidad del modelo para capturar tendencias de ventas y su estabilidad en distintos escenarios, incluyendo cambios en la demanda y eventos atípicos.</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="fu">### **6. Despliegue**</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>Finalmente, el modelo se integrará en un sistema de producción que permita generar pronósticos segun los inputs suminisrados. Para ello, se desarrolló:\</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**API en FastAPI** para servir las predicciones.</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Dashboards interactivos** una herramienta web que permitirá visualizar pronósticos y tomar decisiones estratégicas en la gestión de inventario para este ejemplo particular.</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="fu">## Módulo de clasificación de productos</span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>Frente a los avances en la calidad de las imágenes digitales, junto con la facilidad de acceso a GPUs, clasificar de maner automática productos es una opción muy atractiva para la mayoría de empresas. Una tarea que anteriormente debía ser manual, hoy en día es automática y cada vez más fácil de desarrollar, lo que se permite disminuir la cantidad de errores que tengan un impacto económico en el negocio.</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>Para afrontar este problema se desarrollo un modelo de visión artificial utilizando el dataset propuesto, conformado por imágenes etiquetadas en camisetas, jeans, sofas y televisiones. Inicialmente se puede observar como el dataset es bastante pequeno, lo que puede dificultar tener un modelo que pueda generalizarse hacia nuevas imágenes. Se propone un modelo basado en redes neuronales convolucionales debido a sus altas capacidades para clasificar correctamente datos del tipo de imágenes.</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>Para afrontar este problema, y el desarrollo general del modelo se hizo lo siguiente:</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Limpieza del dataset</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>Si observamos algunos grupos, especialmente el de televisiones, tienen imágenes que no estan relacionadas con la temática, por lo que las eliminamos para no crear sesgos durante el entrenamiento.</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preprocesamiento de las imágenes</span></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Normalización de las imágenes</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>Se recorren las carpetas de diferentes categorías de productos para cargar las imágenes disponibles. Para garantizar una uniformidad en los datos, cada imagen se convierte al formato **RGB** (tres canales de color) y se redimensiona a un tamaño estándar de **224x224 píxeles**. Posteriormente, se normalizan los valores de los píxeles dividiéndolos entre 255, lo que los escala a un rango entre **0 y 1**, mejorando la estabilidad del entrenamiento de la red neuronal.</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Conversión a arrays numéricos</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>Una vez procesadas, las imágenes se almacenan en un arreglo de NumPy para facilitar su manipulación y procesamiento. De manera similar, las etiquetas correspondientes a cada imagen se almacenan en otro arreglo.</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Augmentation</span></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>Para mejorar la generalización del modelo y reducir el sobreajuste, se aplica **data augmentation** en las imágenes de entrenamiento. Se utilizan técnicas como:</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Rotaciones de hasta 30 grados.</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Desplazamientos horizontales y verticales (20% del tamaño de la imagen).</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Transformaciones de corte y zoom.</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Reflejo de las imágenes</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>Estas modificaciones permiten simular nuevas imágenes a partir del conjunto de entrenamiento existente, ayudando al modelo a aprender características más robustas, lo cual es especialmente útil para el algoritmo del descenso del gradiente estocástico ya que al procesarse en batches permite distorsionar las imágenes en el bache que se esta procesando y no es necesario almacenar las nuevas imágenes.</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>Con esta técnica las 636 imágenes que había para cada batch se vuelven 20352, lo que permite obtener mayor información durante el entrenamiento.</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a><span class="fu">### Arquitectura de una red neuronal convolucional</span></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>Las redes neuronales convolucionales surgieron debido a la aparición de bases de datos masivas clasificadas en una gran variedad de posibilidades, y se mostraron como una alternativa muy poderosa para este tipo de problemas.</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="al">![Ilustración acerca del funcionamiento de una red neuronal convolucional. Tomado de An Introduction to Statistical Learning.](funcionamiento_cnn.png)</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>Como se puede ver en la ilustración, estas redes imitan hasta cierto punto el comportamiento para reconocer patrones basado en características específicas, parten desde características diminutas como los bordes, el color y similares, y empiezan a evolucionar a características más notables como las orejas, los ojos y similares.</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Capas convolucionales</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>Se basan en filtros convolucionales los cuales consisten en plantillas que determinan la presencia de alguna característica particular en la imagen. Para lograr lo anterior se basan en la operación llamada convolución, donde ilustramos su funcionamiento de la siguiente manera:</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="sc">\[</span></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix} </span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>a &amp; b &amp; c <span class="sc">\\</span> </span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>d &amp; e &amp; f <span class="sc">\\</span> </span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>g &amp; h &amp; i <span class="sc">\\</span> </span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>j &amp; k &amp; l</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="sc">\]</span></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>\text{Filtro de convolución}</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="sc">\[</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix}</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>\alpha &amp; \beta <span class="sc">\\</span> </span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>\gamma &amp; \delta</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="sc">\]</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>\text{Imagen convolucionada}</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a><span class="sc">\[</span></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>\begin{bmatrix}</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>a\alpha + b\beta + d\gamma + e\delta &amp; b\alpha + c\beta + e\gamma + f\delta <span class="sc">\\</span> </span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>d\alpha + e\beta + g\gamma + h\delta &amp; e\alpha + f\beta + h\gamma + i\delta <span class="sc">\\</span> </span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>g\alpha + h\beta + j\gamma + k\delta &amp; h\alpha + i\beta + k\gamma + l\delta</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>\end{bmatrix}</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="sc">\]</span></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>La convolución en imágenes consiste en aplicar un filtro pequeño sobre submatrices de la imagen original, multiplicando cada elemento correspondiente y sumando los resultados. Si una región de la imagen se parece al filtro, el valor resultante será alto, resaltando esa zona. Si no se parece, el valor será bajo. Este proceso permite detectar patrones y se usa en redes neuronales convolucionales (CNNs) para reconocimiento de imágenes.</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Capas de pooling</span></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>Para condensar imágenes en un resumen más pequeño utilizando técnicas como **max pooling** y **average pooling**.</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Max pooling** selecciona el valor **máximo** dentro de cada bloque de la imagen (por ejemplo, de 2 \times 2), lo que ayuda a resaltar las características más importantes.</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Average pooling** en cambio, calcula el **promedio** de los valores en cada bloque, produciendo una versión más suavizada de la imagen.</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Capa de Activación (ReLU)**</span></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>Se utiliza la función ReLU (Rectified Linear Unit) para introducir no linealidad y mejorar la capacidad de aprendizaje de la red.&nbsp;Convierte valores negativos en cero, manteniendo los positivos sin cambios.</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Capas de Flattening</span></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>Permite transformar las matrices de características que se forman al procesar las imágenes en vectores que pueden ser procesadas por capas completamente conectadas</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Capas completamente conectadas**</span></span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>Estas capas actúan como un **clasificador**, combinando la información extraída en las capas previas para hacer predicciones. Suele utilizarse la función softmax para clasificación múltiple y la función sigmoide para clasificación binaria.</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a><span class="al">![Arquitectura de una red neuronal convolucional. Tomado de https://developersbreach.com/convolution-neural-network-deep-learning/](cnn_arquitectura.webp)</span></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="fu">### Aplicación en el dataset</span></span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Arquitectura propia</span></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>Desarrollamos la siguiente arquitectura propia:</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capas Convolucionales y de Normalización**</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se aplican **convoluciones** con filtros de 3×33 \times 33×3 para detectar patrones en la imagen.</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se usa **Batch Normalization** después de cada convolución para estabilizar el aprendizaje y mejorar la convergencia.</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se emplea **Max Pooling** (2×22 \times 22×2) después de cada bloque convolucional para reducir la dimensionalidad.</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Bloques Convolucionales**</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Bloque 1:** 32 filtros, seguido de normalización y max pooling.</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Bloque 2:** 64 filtros, normalización y max pooling.</span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Bloque 3:** 128 filtros, normalización y max pooling.</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Bloque 4 :** 256 filtros, normalización y max pooling.</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Aplanamiento y Capas Densas**</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se aplanan las características extraídas en un vector de entrada para la parte densa.</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se añade una **capa densa** de 128 neuronas con **ReLU**.</span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se incorpora **Dropout (50%)** para reducir el overfitting.</span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capa de Salida**</span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>La última capa tiene tantas neuronas como clases en la clasificación.</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se usa la activación **Softmax** para generar probabilidades sobre cada categoría.</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Compilación del Modelo**</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se emplea el optimizador **Adam** para el entrenamiento.</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>La función de pérdida es **categorical crossentropy** (o **sparse categorical crossentropy** si las etiquetas no están en formato one-hot).</span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se mide la precisión (**accuracy**) como métrica principal.</span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Matriz de confusión</span></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a><span class="al">![Matriz de confusión para la red neuronal convolucional. Elaboración propia.](confusion1.png)</span></span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a>Podemos ver como para la clase 1, el modelo no es capaz de reconocerla bien, como se observa en el reporte de clasificación, esta corresponde a los sofas, con lo cual el modelo presenta una gran cantidad de errores para ese tipo de imágenes.</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Métricas obtenidas</span></span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="al">![Evolución de la precisión y la función de pérdida en el entrenamiento y la validación. Elaboración propia.](rendimiento.png)</span></span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Reporte de clasificación</span></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a>| Clase            | Precisión | Recall | F1-Score | Soporte |</span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a>|------------------|-----------|--------|----------|---------|</span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a>| Jeans            | 0.95      | 0.97   | 0.96     | 40      |</span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>| Sofa             | 1.00      | 0.07   | 0.14     | 40      |</span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>| T-Shirt          | 1.00      | 0.95   | 0.97     | 40      |</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a>| TV               | 0.49      | 0.95   | 0.64     | 40      |</span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a>| **Accuracy**     |           |        | **0.74** | **160** |</span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>| **Macro Avg**    | 0.86      | 0.74   | 0.68     | 160     |</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a>| **Weighted Avg** | 0.86      | 0.74   | 0.68     | 160     |</span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Modelo preentrenado</span></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a>Debido a los problemas presentados con el problema propio, desarrollamos también un modelo preentrenado en Imagenet, lo cual es una alternativa muy atractiva al ser un conjunto de datos pequeno, por lo que esto puede ayudar a mejorar el rendimiento del modelo.</span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Arquitectura agregada al modelo preentrenado</span></span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**GlobalAveragePooling2D**</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Reduce la dimensionalidad de los mapas de características mediante el cálculo del promedio de cada filtro convolucional.</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Ayuda a disminuir el número de parámetros y mejora la eficiencia del modelo.</span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capa Densa (128 neuronas, ReLU)**</span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Introduce una capa completamente conectada para aprender combinaciones avanzadas de características.</span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>La activación **ReLU** mejora la capacidad de aprendizaje al introducir no linealidad.</span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Dropout (50%)**</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Apaga aleatoriamente el 50% de las neuronas en cada iteración durante el entrenamiento.</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Reduce el riesgo de sobreajuste, haciendo que la red sea más robusta y generalizable.</span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capa de Salida (Softmax)**</span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Tiene tantas neuronas como categorías a clasificar.</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Usa **Softmax** para convertir las salidas en probabilidades, asegurando que la suma sea 1 y permitiendo la clasificación de la imagen en una categoría específica.</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Matriz de confusión</span></span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a><span class="al">![Matriz de confusión modelo preentrenado. Elaboración propia.](confusion2.png)</span></span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Evolución métricas</span></span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a><span class="al">![Evolución de la precisión y la pérdida en entrenamiento y validación. Elaboración propia.](rendimeinto2.png)</span></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Reporte de clasificación</span></span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a>| Clase            | Precisión | Recall | F1-Score | Soporte |</span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>|------------------|-----------|--------|----------|---------|</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a>| Jeans            | 1.00      | 1.00   | 1.00     | 40      |</span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a>| Sofa             | 1.00      | 1.00   | 1.00     | 40      |</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a>| T-Shirt          | 1.00      | 1.00   | 0.99     | 40      |</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a>| TV               | 1.00      | 0.97   | 0.99     | 40      |</span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a>| **Accuracy**     |           |        | **0.99** | **160** |</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a>| **Macro Avg**    | 0.99      | 0.99   | 0.99     | 160     |</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a>| **Weighted Avg** | 0.99      | 0.99   | 0.99     | 160     |</span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a><span class="fu">## Módulo de recomendaciones personalizadas</span></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>Se desarrolló un modelo basado en redes neuronales y embeddings. Estos embeddings nos permiten representar datos categóricos o secuenciales, como las palabras, en espacios continuos donde pueden ser representados como vectores numéricos que capturen relaciones semánticas y similitudes.</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a><span class="fu">### Limpieza de los datos</span></span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a>Se eliminaron los símbolos y comas de los precios para convertirlos a valores numéricos. Luego, se codifican las variables categóricas, como el nombre del producto, la categoría principal y la subcategoría, utilizando <span class="in">`LabelEncoder`</span>. Se convierten las variables <span class="in">`ratings`</span> y <span class="in">`no_of_ratings`</span> a tipo flotante para su correcto procesamiento.</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a>Posteriormente, se normalizan los precios, las calificaciones y el número de valoraciones para escalarlos entre 0 y 1, lo que facilita el entrenamiento del modelo. Finalmente, los datos se dividen en conjuntos de entrenamiento y prueba, asegurando una correcta evaluación del modelo en datos no vistos.</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a><span class="fu">### Arquitectura del modelo</span></span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Embeddings</span></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Producto** - Representado con un embedding de 50 dimensiones.</span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Categoría principal** - Representado con un embedding de 10 dimensiones.</span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Subcategoría** - Representado con un embedding de 10 dimensiones.</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>Cada una de las entradas categóricas se convierte en un vector a través de una **capa de embedding** y se aplana con <span class="in">`Flatten()`</span>. Luego, estos vectores se concatenan con las características numéricas.</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Características numéricas</span></span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a>Incluye las características de <span class="in">`discount_price`</span>, <span class="in">`actual_price`</span> y <span class="in">`no_of_ratings`</span>.</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Capas modelo</span></span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capas de Entrada**:</span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`product_input`</span>, <span class="in">`main_cat_input`</span>, <span class="in">`sub_cat_input`</span>, <span class="in">`numeric_input`</span>: Cuatro capas de entrada que reciben diferentes tipos de datos (producto, categoría principal, subcategoría y características numéricas).</span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capas de Embedding**:</span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`product_embedding`</span>: Convierte el ID del producto en un vector de 50 dimensiones (11,867,600 parámetros).</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`main_cat_embedding`</span>: Convierte la categoría principal en un vector de 10 dimensiones (200 parámetros).</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`sub_cat_embedding`</span>: Convierte la subcategoría en un vector de 10 dimensiones (1,120 parámetros).</span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capas de Flatten**:</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`flatten`</span>, <span class="in">`flatten_1`</span>, <span class="in">`flatten_2`</span>: Aplanan los embeddings en vectores de una sola dimensión para facilitar la concatenación con los datos numéricos.</span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capa de Concatenación**:</span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`concatenate`</span>: Une todas las características transformadas en un único vector de 73 dimensiones.</span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capas Densas y Dropout**:</span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`dense`</span>: Capa densa con 128 neuronas y 9,472 parámetros.</span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`dropout`</span>: Capa de dropout para regularización.</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`dense_1`</span>: Capa densa con 64 neuronas y 8,256 parámetros.</span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`dropout_1`</span>: Otra capa de dropout para reducir sobreajuste.</span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Capa de Salida**:</span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span><span class="in">`output`</span>: Capa densa con 1 neurona para la predicción final (65 parámetros).</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="fu">### Métricas obtenidas por el modelo</span></span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a><span class="al">![Evolución de la pérdida y el MAE para el modelo de recomendación. Elaboración propia.](mae.png)</span></span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="fu"># Herramienta web</span></span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a>De acuerdo a lo que se ha venido presentando a lo largo de este ejercicio, los modelos de redes neuronales entrenados han sido desplegados en el sitio web titulado <span class="sc">\[</span>título<span class="sc">\]</span>, donde la compañía de comercio electrónico y sus usuarios pueden acceder a los siguientes servicios:</span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Visualización de gráficos de predicción de la demanda.</span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Ver clasificación automática de un producto, dada su imagen.</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Recepción de recomendaciones personalizadas para diferentes perfiles de usuarios.</span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-449"><a href="#cb1-449" aria-hidden="true" tabindex="-1"></a><span class="fu">## Despliegue de los modelos</span></span>
<span id="cb1-450"><a href="#cb1-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-451"><a href="#cb1-451" aria-hidden="true" tabindex="-1"></a>Los tres modelos que se desarrollaron y se explican en este reporte deben de ser desplegados para poder ponerlos al alcance de los demás y poder ser utilizados en el sitio web. Para lograr lo anterior utilizamos los servicios de **Render** y **Digital Ocean** para desplegar las APIs creadas utilizando FastAPI**.** Es importante reportar la complicación que se tuvo para el tercer modelo, el modelo de recomendación, debido a que computacionalmente es un modelo pesado por lo que el tier gratuito de Render se queda corto antes este modelo, también se intento usar el free tier de AWS sin embargo la memoria RAM que este ofrecía seguía quedándose corta, por lo que Digital Ocean, aprovechando los créditos otorgados por el GitHub Student Pack, nos permitió superar esa dificultad.</span>
<span id="cb1-452"><a href="#cb1-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-453"><a href="#cb1-453" aria-hidden="true" tabindex="-1"></a><span class="fu"># Resultados generales y discusión</span></span>
<span id="cb1-454"><a href="#cb1-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-455"><a href="#cb1-455" aria-hidden="true" tabindex="-1"></a>Podemos ver como el modelo preentrenado para el modelo de visión artificial muestra una mejoría importante, si el modelo que se propuso inicialmente se hubiera utilizado, hubiera presentado problemas para clasificar los televisores, sin embargo, el preentrenado funciona muy bien ante todas estas situaciones.</span>
<span id="cb1-456"><a href="#cb1-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-457"><a href="#cb1-457" aria-hidden="true" tabindex="-1"></a>El modelo de recomendación que se propuso presenta muy buenos resultados gracias al uso de modelos basados en embeddings, sin embargo, el problema que se enfrento aquí, es que computacionalmente es un modelo pesado, por lo que el entrenamiento es lento, y ponerlo a disposición como una API desplegada implica un mayor uso de recursos de los que se suele tener acceso de manera gratuita.</span>
<span id="cb1-458"><a href="#cb1-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-459"><a href="#cb1-459" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusiones y recomendaciones</span></span>
<span id="cb1-460"><a href="#cb1-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-461"><a href="#cb1-461" aria-hidden="true" tabindex="-1"></a><span class="fu"># Anexos</span></span>
<span id="cb1-462"><a href="#cb1-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-463"><a href="#cb1-463" aria-hidden="true" tabindex="-1"></a><span class="fu">## Videos explicativos</span></span>
<span id="cb1-464"><a href="#cb1-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-465"><a href="#cb1-465" aria-hidden="true" tabindex="-1"></a>En los videos presentados a continuación se puede encontrar una breve descripción del funcionamiento de cada sección de la aplicación web, con un ejemplo real de utilización y posible interpretación de los resultados obtenidos.</span>
<span id="cb1-466"><a href="#cb1-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-467"><a href="#cb1-467" aria-hidden="true" tabindex="-1"></a><span class="fu">## Aspectos éticos de los modelos</span></span>
<span id="cb1-468"><a href="#cb1-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-469"><a href="#cb1-469" aria-hidden="true" tabindex="-1"></a>Dentro de los aspectos éticos a considerar de estos modelos, hay dos aspectos principales, como se presenta el modelo y que uso se le da al mismo.</span>
<span id="cb1-470"><a href="#cb1-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-471"><a href="#cb1-471" aria-hidden="true" tabindex="-1"></a><span class="fu">### Presentación del modelo</span></span>
<span id="cb1-472"><a href="#cb1-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-473"><a href="#cb1-473" aria-hidden="true" tabindex="-1"></a>Los modelos suelen presentarse a un público no especializado, por lo cual tratar de dar una presentación optimista del modelo sin que los demás se de den cuenta es posible, lo anterior, en busca de salir del paso, quedar bien, u obtener algún beneficio. Se tiene entonces una responsabilidad con el conocimiento que se posee para generar valor dentro del negocio.</span>
<span id="cb1-474"><a href="#cb1-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-475"><a href="#cb1-475" aria-hidden="true" tabindex="-1"></a><span class="fu">### Uso de los modelos</span></span>
<span id="cb1-476"><a href="#cb1-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-477"><a href="#cb1-477" aria-hidden="true" tabindex="-1"></a>En el trabajo se presentan modelos poderosos que tienen capacidades de resolver el problema, sin embargo, muchas veces se debe tener en cuenta los sesgos que se pueden crear dentro del mismo. Que modelos de clasificación por ejemplo en un entorno bancario, tiendan a negar préstamos a grupos minoritarios basado únicamente en sesgos, lo anterior implica evaluar correctamente el uso de las características del modelo, si bien puede deberse a pensamientos arcaicos que se reflejan en los datos, es deber de la persona encargada de crear el modelo, superar esos retos para generar valor para el negocio adaptado a las necesidades de las nuevas generaciones.</span>
<span id="cb1-478"><a href="#cb1-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-479"><a href="#cb1-479" aria-hidden="true" tabindex="-1"></a><span class="fu">## Contribuciones individuales</span></span>
<span id="cb1-480"><a href="#cb1-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-481"><a href="#cb1-481" aria-hidden="true" tabindex="-1"></a>Las contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo del presente trabajo se pueden observar en el video a continuación:</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>