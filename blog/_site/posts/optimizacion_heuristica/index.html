<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.36">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Julián Castaño Pineda">
<meta name="author" content="Luis Andrés Altamar Romero">
<meta name="author" content="Catalina Restrepo Salgado">
<meta name="author" content="Tomás Rodríguez Taborda">
<meta name="dcterms.date" content="2024-11-29">

<title>Optimización Heurística – Redes Neuronales Artificiales y Algoritmos Bioinspirados</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-01c78b5cd655e4cd89133cf59d535862.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-474c6d7e63be50eb6972897072b39b27.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-818b32141788da5f3afc8302f6e847b9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-1851c9bb8f3f4849af8ba858f06152b9.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Redes Neuronales Artificiales y Algoritmos Bioinspirados</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Acerca de</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/RNA-y-Algo-Bioinsp-2024-02/blog"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Optimización Heurística</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">optimización</div>
                <div class="quarto-category">métodos heurísticos</div>
                <div class="quarto-category">python</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Julián Castaño Pineda </p>
               <p>Luis Andrés Altamar Romero </p>
               <p>Catalina Restrepo Salgado </p>
               <p>Tomás Rodríguez Taborda </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 29, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#funciones-a-optimizar" id="toc-funciones-a-optimizar" class="nav-link active" data-scroll-target="#funciones-a-optimizar"><span class="header-section-number">1</span> Funciones a optimizar</a></li>
  <li><a href="#proceso-de-optimización" id="toc-proceso-de-optimización" class="nav-link" data-scroll-target="#proceso-de-optimización"><span class="header-section-number">2</span> Proceso de optimización</a>
  <ul class="collapse">
  <li><a href="#optimización-por-descenso-del-gradiente" id="toc-optimización-por-descenso-del-gradiente" class="nav-link" data-scroll-target="#optimización-por-descenso-del-gradiente"><span class="header-section-number">2.1</span> Optimización por descenso del gradiente</a></li>
  <li><a href="#agoritmo-genético" id="toc-agoritmo-genético" class="nav-link" data-scroll-target="#agoritmo-genético"><span class="header-section-number">2.2</span> Agoritmo genético</a>
  <ul class="collapse">
  <li><a href="#concepto-general" id="toc-concepto-general" class="nav-link" data-scroll-target="#concepto-general"><span class="header-section-number">2.2.1</span> Concepto General</a></li>
  <li><a href="#etapas" id="toc-etapas" class="nav-link" data-scroll-target="#etapas"><span class="header-section-number">2.2.2</span> Etapas</a></li>
  <li><a href="#observaciones" id="toc-observaciones" class="nav-link" data-scroll-target="#observaciones"><span class="header-section-number">2.2.3</span> Observaciones</a></li>
  </ul></li>
  <li><a href="#optimización-de-partículas" id="toc-optimización-de-partículas" class="nav-link" data-scroll-target="#optimización-de-partículas"><span class="header-section-number">2.3</span> Optimización de partículas</a>
  <ul class="collapse">
  <li><a href="#concepto-básico-y-analogía" id="toc-concepto-básico-y-analogía" class="nav-link" data-scroll-target="#concepto-básico-y-analogía"><span class="header-section-number">2.3.1</span> Concepto Básico y Analogía</a></li>
  </ul></li>
  <li><a href="#optimización-diferencial" id="toc-optimización-diferencial" class="nav-link" data-scroll-target="#optimización-diferencial"><span class="header-section-number">2.4</span> Optimización diferencial</a></li>
  </ul></li>
  <li><a href="#resultados" id="toc-resultados" class="nav-link" data-scroll-target="#resultados"><span class="header-section-number">3</span> Resultados</a></li>
  <li><a href="#conclusiones-y-comentarios" id="toc-conclusiones-y-comentarios" class="nav-link" data-scroll-target="#conclusiones-y-comentarios"><span class="header-section-number">4</span> Conclusiones y comentarios</a></li>
  <li><a href="#discusión" id="toc-discusión" class="nav-link" data-scroll-target="#discusión"><span class="header-section-number">5</span> Discusión</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div id="460b91a8" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.animation <span class="im">import</span> FuncAnimation</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image <span class="im">as</span> IPImage</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.</p>
<p>Al final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas.</p>
<section id="funciones-a-optimizar" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Funciones a optimizar</h1>
<p>Se seleccionaron seis funciones comúnmente empleadas para evaluar métodos de optimización, debido a sus características particulares. Estas funciones presentan desafíos como la existencia de un mínimo global acompañado de múltiples mínimos locales, así como valles que pueden dificultar la convergencia de los algoritmos. A continuación, se describen dichas funciones, incluyendo su forma funcional generalizada para <span class="math inline">\(d\)</span> dimensiones, su representación gráfica en 2 dimensiones, el valor del mínimo global, una breve descripción de cada función y el rango de evaluación sugerido por diversos autores. Las gráficas fueron generadas a partir de la funcion <code>plot_function()</code> que se muestra en la pestaña de <code>Code</code> sugerida.</p>
<div id="d265d6d1" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_function(f, x1_range, x2_range, title<span class="op">=</span><span class="st">"Function Plot"</span>, x1_point<span class="op">=</span><span class="va">None</span>, x2_point<span class="op">=</span><span class="va">None</span>, elev<span class="op">=</span><span class="dv">30</span>, azim<span class="op">=</span><span class="dv">45</span> ):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> np.linspace(x1_range[<span class="dv">0</span>], x1_range[<span class="dv">1</span>], <span class="dv">400</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> np.linspace(x2_range[<span class="dv">0</span>], x2_range[<span class="dv">1</span>], <span class="dv">400</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    X1, X2 <span class="op">=</span> np.meshgrid(x1, x2)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> f(np.array([X1,X2]))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3D plot</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    ax1.plot_surface(X1, X2, Z)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="ss">f'3D Plot of </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'X1'</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'X2'</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    ax1.set_zlabel(<span class="st">'Z'</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    ax1.view_init(elev<span class="op">=</span>elev, azim<span class="op">=</span>azim)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x1_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> x2_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        z_point <span class="op">=</span> f(np.array([x1_point, x2_point])[:, <span class="va">None</span>, <span class="va">None</span>])[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        ax1.plot([x1_point], [x2_point], [z_point], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">5</span>, linewidth<span class="op">=</span><span class="dv">0</span>, label<span class="op">=</span><span class="st">"Mínimo global"</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        ax1.legend()</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Contour plot</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    contour <span class="op">=</span> ax2.contour(X1, X2, Z, levels <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="ss">f'Contour Plot of </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'X1'</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'X2'</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    fig.colorbar(contour, ax<span class="op">=</span>ax2)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x1_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> x2_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        ax2.plot([x1_point], [x2_point], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">5</span>, linewidth<span class="op">=</span><span class="dv">0</span>, label<span class="op">=</span><span class="st">"Mínimo global"</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        ax2.legend()</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Función de Rosenbrock</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Función de Rastrigin</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Función de Schwefel</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" role="tab" aria-controls="tabset-1-4" aria-selected="false">Función de Griewank</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-5" role="tab" aria-controls="tabset-1-5" aria-selected="false">Función Goldstein-Price</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-6" role="tab" aria-controls="tabset-1-6" aria-selected="false">Función de las seis jorobas de camello</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p><span class="math display">\[
f(\mathbf{x}) = \sum_{i=1}^{d-1} \left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right] \tag{1}
\]</span></p>
<p><strong>Figura 1.</strong></p>
<p><em>Representación gráfica de la función de Rosenbrock.</em></p>
<div id="467e14e1" class="cell" height="auto" width="100%" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Rosenbrock</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock(x, a<span class="op">=</span><span class="dv">1</span>, b<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de Rosenbrock.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">    x: vector de entrada (numpy array)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    a, b: parámetros de la función</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="bu">sum</span>(b <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> (x[:<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> a)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plot_function(rosenbrock, x1_range<span class="op">=</span>(<span class="op">-</span><span class="fl">2.048</span>, <span class="fl">2.048</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="fl">2.048</span>, <span class="fl">2.048</span>), title<span class="op">=</span><span class="st">"Función Rosenbrock"</span>, x1_point<span class="op">=</span><span class="dv">1</span>, x2_point<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-4-output-1.png" width="661" height="376" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Elaboración propia.</p>
<p>En 2 dimensiones se puede definir como se muestra en la Ecuación (2).</p>
<p><span class="math display">\[
f(x_1, x_2) = (a - x_1)^2 + b(x_2 - x_1^2)^2 \tag{2}
\]</span></p>
<p>La Función de Rosenbrock, también conocida como función del valle o del plátano, es ampliamente utilizada para evaluar algoritmos de optimización basados en gradientes. Esta función es unimodal y presenta su mínimo global en un valle parabólico estrecho, lo que facilita su localización. Sin embargo, según <span class="citation" data-cites="simonfraser_rosenbrock">Simon Fraser University (<a href="#ref-simonfraser_rosenbrock" role="doc-biblioref">n.d.</a>)</span> citando a <span class="citation" data-cites="picheny2012benchmark">Picheny, Wagner, and Ginsbourger (<a href="#ref-picheny2012benchmark" role="doc-biblioref">2012</a>)</span>, la convergencia hacia este mínimo puede ser desafiante debido a la naturaleza del valle.</p>
<p>La función se evalúa generalmente en el hipercubo <span class="math inline">\(x_i \in [-5, 10]\)</span> y tiene un mínimo global en <span class="math inline">\(f(1,...,1) = 0\)</span></p>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left[ x_i^2 - 10 \cos(2\pi x_i) \right] \tag{3}
\]</span></p>
<p><strong>Figura 2.</strong></p>
<p><em>Representación gráfica de la función de Rastrigin.</em></p>
<div id="1dc795da" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Rastrigin</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rastrigin(x):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de Rastrigin.</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    x: vector de entrada (numpy array)</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">10</span> <span class="op">*</span> d <span class="op">+</span> <span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">10</span> <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plot_function(rastrigin, x1_range<span class="op">=</span>(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>), title<span class="op">=</span><span class="st">"Función Rastrigin"</span>, x1_point<span class="op">=</span><span class="dv">0</span>, x2_point<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" width="638" height="377" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Elaboración propia.</p>
<p>Segun <span class="citation" data-cites="simonfraser_rosenbrock">Simon Fraser University (<a href="#ref-simonfraser_rosenbrock" role="doc-biblioref">n.d.</a>)</span>, la función de Rastrigin tiene varios mínimos locales. Es altamente multimodal, pero las ubicaciones de los mínimos se distribuyen regularmente. La función generalmente se evalúa en el hipercubo <span class="math inline">\(x_i \in [-5.12, 5.12]\)</span> y su mínimo local se encuentra en <span class="math inline">\(f(0,...,0)=0\)</span>.</p>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}
\]</span></p>
<p><strong>Figura 3.</strong></p>
<p><em>Representación gráfica de la función de Schwefel.</em></p>
<div id="0e675663" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Schwefel</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> schwefel(x):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de Schwefel.</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">    x: vector de entrada (numpy array)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">418.9829</span> <span class="op">*</span> d <span class="op">-</span> <span class="bu">sum</span>(x <span class="op">*</span> np.sin(np.sqrt(np.<span class="bu">abs</span>(x))))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plot_function(schwefel, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">500</span>, <span class="dv">500</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">500</span>, <span class="dv">500</span>), title<span class="op">=</span><span class="st">"Función Schwefel"</span>, x1_point<span class="op">=</span><span class="fl">420.9687</span>, x2_point<span class="op">=</span><span class="fl">420.9687</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="662" height="376" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Elaboración propia.</p>
<p>Segun <span class="citation" data-cites="simonfraser_rosenbrock">Simon Fraser University (<a href="#ref-simonfraser_rosenbrock" role="doc-biblioref">n.d.</a>)</span> La función de Schwefel es compleja, con muchos mínimos locales. Normalmente se evalpúa en el hipercubo <span class="math inline">\(x_i \in [-500,500]\)</span>. Su minimo global está en <span class="math inline">\(f(420.9687,...,420.9687)=0\)</span></p>
</div>
<div id="tabset-1-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-4-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}
\]</span></p>
<p><strong>Figura 4.</strong></p>
<p><em>Representación gráfica de la función de Griewank.</em></p>
<div id="9f23f916" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Griewank</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> griewank(x):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función Griewank.</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">    x: numpy array unidimensional (1D) o un array con forma (d, n1, n2) para evaluaciones vectorizadas.</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Retorna:</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - Un valor escalar si `x` es 1D.</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - Una matriz (n1, n2) si `x` tiene forma (d, n1, n2).</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.asarray(x)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Caso 1D: calcular para un solo vector</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>        sum_term <span class="op">=</span> np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">4000</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        product_term <span class="op">=</span> np.prod(np.cos(x <span class="op">/</span> np.sqrt(np.arange(<span class="dv">1</span>, d <span class="op">+</span> <span class="dv">1</span>))))</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span> <span class="op">+</span> sum_term <span class="op">-</span> product_term</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> x.ndim <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Caso ND: calcular para una cuadrícula (vectorizado)</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        i_indices <span class="op">=</span> np.arange(<span class="dv">1</span>, d <span class="op">+</span> <span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>        sum_term <span class="op">=</span> np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="dv">4000</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        product_term <span class="op">=</span> np.prod(np.cos(x <span class="op">/</span> np.sqrt(i_indices)), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span> <span class="op">+</span> sum_term <span class="op">-</span> product_term</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"La entrada debe ser un array 1D o un array con forma (d, n1, n2)."</span>)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>plot_function(griewank, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>), title<span class="op">=</span><span class="st">"Función Griewank"</span>, x1_point<span class="op">=</span><span class="dv">0</span>, x2_point<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-7-output-1.png" width="649" height="376" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Elaboración propia.</p>
<p>Segun <span class="citation" data-cites="simonfraser_rosenbrock">Simon Fraser University (<a href="#ref-simonfraser_rosenbrock" role="doc-biblioref">n.d.</a>)</span> la función de Griewank tiene muchos mínimos locales generalizados, que se distribuyen de forma regular. Lo que hace compleja su optimización al minimo global. Normalmente se evalua en el hipercubo <span class="math inline">\(x_i \in [-600,600]\)</span>. Su minimo global está en <span class="math inline">\(f(0,...,0)=0\)</span></p>
</div>
<div id="tabset-1-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-5-tab">
<p><span class="math display">\[
\begin{align}
f(x_1, x_2) = &amp; \left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right] \\
         &amp; \left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right]
\end{align} \tag{6}
\]</span></p>
<p><strong>Figura 5.</strong></p>
<p><em>Representación gráfica de la función de Goldstein-Price.</em></p>
<div id="8bac86ca" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función Goldstein-Price</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> goldstein_price(x):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función Goldstein-Price.</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">    x1, x2: coordenadas en 2D</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    x1<span class="op">=</span>x[<span class="dv">0</span>]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    x2<span class="op">=</span>x[<span class="dv">1</span>]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    term1 <span class="op">=</span> (<span class="dv">1</span> <span class="op">+</span> (x1 <span class="op">+</span> x2 <span class="op">+</span> <span class="dv">1</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">19</span> <span class="op">-</span> <span class="dv">14</span> <span class="op">*</span> x1 <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">14</span> <span class="op">*</span> x2 <span class="op">+</span> <span class="dv">6</span> <span class="op">*</span> x1 <span class="op">*</span> x2 <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    term2 <span class="op">=</span> (<span class="dv">30</span> <span class="op">+</span> (<span class="dv">2</span> <span class="op">*</span> x1 <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> x2)<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">18</span> <span class="op">-</span> <span class="dv">32</span> <span class="op">*</span> x1 <span class="op">+</span> <span class="dv">12</span> <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">48</span> <span class="op">*</span> x2 <span class="op">-</span> <span class="dv">36</span> <span class="op">*</span> x1 <span class="op">*</span> x2 <span class="op">+</span> <span class="dv">27</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> term1 <span class="op">*</span> term2</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plot_function(goldstein_price, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), title<span class="op">=</span><span class="st">"Función Goldstein price"</span>, x1_point<span class="op">=</span><span class="dv">0</span>, x2_point<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.png" width="644" height="377" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Elaboración propia.</p>
<p>La función Goldstein-Price es una función en 2 dimensiones y tiene varios mínimos locales. Segun <span class="citation" data-cites="molga2005test">Molga and Smutnicki (<a href="#ref-molga2005test" role="doc-biblioref">2005</a>)</span>, la función generalmente se evalúa en el cuadrado <span class="math inline">\(x_1 \in [-2, 2]\)</span> y <span class="math inline">\(x_1 \in [-2, 2]\)</span> . Su mínimo global es <span class="math inline">\(f(0,-1) = 3\)</span></p>
</div>
<div id="tabset-1-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-6-tab">
<p><span class="math display">\[
f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}
\]</span></p>
<p><strong>Figura 6.</strong></p>
<p><em>Representación gráfica de la función de las seis jorobas del camello.</em></p>
<div id="ecc4df05" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de las seis jorobas de camello</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> camel_six_humps(x):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de las seis jorobas de camello.</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    x1, x2: coordenadas en 2D</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> x[<span class="dv">0</span>]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> x[<span class="dv">1</span>]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    term1 <span class="op">=</span> (<span class="dv">4</span> <span class="op">-</span> <span class="fl">2.1</span> <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> x1<span class="op">**</span><span class="dv">4</span> <span class="op">/</span> <span class="dv">3</span>) <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    term2 <span class="op">=</span> x1 <span class="op">*</span> x2</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    term3 <span class="op">=</span> (<span class="op">-</span><span class="dv">4</span> <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> term1 <span class="op">+</span> term2 <span class="op">+</span> term3</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plot_function(camel_six_humps, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), title<span class="op">=</span><span class="st">"Función 6 jorobas de camello"</span>, x1_point<span class="op">=</span><span class="fl">0.0898</span>, x2_point<span class="op">=-</span><span class="fl">0.7126</span>, elev<span class="op">=</span><span class="dv">30</span>, azim<span class="op">=</span><span class="dv">75</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-9-output-1.png" width="654" height="377" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Elaboración propia.</p>
<p>La función de las seis jorobas de camello es una función en 2 dimensiones.Segun <span class="citation" data-cites="molga2005test">Molga and Smutnicki (<a href="#ref-molga2005test" role="doc-biblioref">2005</a>)</span> la función tiene seis mínimos locales, dos de los cuales son globales y recomienda evaluar la función en el rectángulo <span class="math inline">\(x_1 \in [-3, 3], x_2 \in [-2, 2]\)</span>, donde los mínimos globales son <span class="math inline">\(f(0.0898,-0.7126) = -1.0316\)</span> y <span class="math inline">\(f(-0.0898, 0.7126) = -1.0316\)</span></p>
</div>
</div>
</div>
</section>
<section id="proceso-de-optimización" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Proceso de optimización</h1>
<section id="optimización-por-descenso-del-gradiente" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="optimización-por-descenso-del-gradiente"><span class="header-section-number">2.1</span> Optimización por descenso del gradiente</h2>
<p>El descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.</p>
<p>De acuerdo con <span class="citation" data-cites="bishop2006pattern">Bishop (<a href="#ref-bishop2006pattern" role="doc-biblioref">2006</a>)</span>, para una función <span class="math inline">\(f(x)\)</span>, el algoritmo actualiza iterativamente el punto <span class="math inline">\(x\)</span> usando la regla que se observa en la Ecuación 8.</p>
<p><span class="math display">\[
x_{t+1} = x_t - \eta \nabla f(x_t) \tag{8}
\]</span></p>
<p>donde:</p>
<ul>
<li><p><span class="math inline">\(x_t\)</span> es el punto actual</p></li>
<li><p><span class="math inline">\(\eta\)</span> es la tasa de aprendizaje</p></li>
<li><p><span class="math inline">\(\nabla f(x_t)\)</span> es el gradiente de la función en <span class="math inline">\(x_t\)</span></p></li>
</ul>
<p>El gradiente <span class="math inline">\(\nabla f\)</span> es un vector que contiene las derivadas parciales respecto a cada variable, tal como se ilustra en la Ecuación 9: <span class="math display">\[
\nabla f(x_1, x_2) = \begin{bmatrix} \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2} \end{bmatrix} \tag{9}
\]</span></p>
<p>El gradiente <span class="math inline">\(\nabla f\)</span> se puede aproximar numéricamente usando diferencias finitas. <span class="citation" data-cites="bishop2006pattern">Bishop (<a href="#ref-bishop2006pattern" role="doc-biblioref">2006</a>)</span> plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función <span class="math inline">\(f(x_1, x_2)\)</span>, las derivadas parciales se calculan como se muestra en las Ecuaciones 10 y 11.</p>
<p><span class="math display">\[
\frac{\partial f}{\partial x_1} \approx \frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \tag{10}
\]</span></p>
<p><span class="math display">\[
\frac{\partial f}{\partial x_2} \approx \frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \tag{11}
\]</span></p>
<p>donde <span class="math inline">\(h\)</span> es un pequeño incremento (típicamente <span class="math inline">\(10^{-7}\)</span> o <span class="math inline">\(10^{-8}\)</span>).</p>
<div id="bc052e36" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> partial_derivative(x0, func, i, h, <span class="op">*</span>args):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  e <span class="op">=</span> np.zeros(<span class="bu">len</span>(x0))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  e[i] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (func(x0<span class="op">+</span>h<span class="op">*</span>e, <span class="op">*</span>args) <span class="op">-</span> func(x0<span class="op">-</span>h<span class="op">*</span>e, <span class="op">*</span>args))<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>h)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> numerical_gradient(x0, func, h, <span class="op">*</span>args):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  gradient <span class="op">=</span> np.zeros(<span class="bu">len</span>(x0))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x0)):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    gradient[i] <span class="op">=</span> partial_derivative(x0, func, i, h, <span class="op">*</span>args)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> gradient</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, <span class="op">*</span>args):</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">  Perform gradient descent with numerical derivatives for a multi-dimensional function.</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co">  Parameters:</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co">      x0 (array-like): Initial guess for the variables.</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co">      eta (float): Learning rate.</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co">      func (callable): Function to minimize.</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co">      h (float): Step size for numerical gradient calculation.</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co">      max_iter (int): Maximum number of iterations.</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co">      *args: Additional arguments for the function.</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co">  Returns:</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co">      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co">                                containing the trajectory of points.</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>  x_old <span class="op">=</span> np.array(x0)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>  x_hist <span class="op">=</span> []  <span class="co"># List to store the history of x and f(x)</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Calculate the gradient numerically</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>      gradient <span class="op">=</span> numerical_gradient(x_old, func, h, <span class="op">*</span>args)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Update x based on gradient descent rule</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>      x_new <span class="op">=</span> x_old <span class="op">-</span> eta <span class="op">*</span> gradient</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Append current x and function value to history</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>      x_hist.append([x_old[<span class="dv">0</span>], x_old[<span class="dv">1</span>], func(x_old, <span class="op">*</span>args)])</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Update x_old</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>      x_old <span class="op">=</span> x_new</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add the final position and function value</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>  x_hist.append([x_new[<span class="dv">0</span>], x_new[<span class="dv">1</span>], func(x_new, <span class="op">*</span>args)])</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert history to a pandas DataFrame</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>  result_df <span class="op">=</span> pd.DataFrame(x_hist, columns<span class="op">=</span>[<span class="st">'x1'</span>, <span class="st">'x2'</span>, <span class="st">'f(x1,x2)'</span>])</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Función de Rosenbrock</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Función de Rastrigin</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">Función de Schwefel</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-4" role="tab" aria-controls="tabset-2-4" aria-selected="false">Función de Griewank</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-5" role="tab" aria-controls="tabset-2-5" aria-selected="false">Función Goldstein-Price</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-6" role="tab" aria-controls="tabset-2-6" aria-selected="false">Función de las seis jorobas de camello</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p><span class="math display">\[
f(\mathbf{x}) = \sum_{i=1}^{d-1} \left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right] \tag{1}
\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x_{1_0}\)</span></th>
<th><span class="math inline">\(x_{2_0}\)</span></th>
<th><span class="math inline">\(\eta\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-1.5</td>
<td>-1.7</td>
<td>0.001</td>
<td>30</td>
</tr>
</tbody>
</table>
<p><strong>Figura 7.</strong></p>
<p><em>Aplicación del descenso del gradiente en la función de Rosenbrok.</em> <img src="images/rosenbrock.gif" class="img-fluid" alt="Aplicación del descenso del gradiente en la función de Rosenbrok"> Elaboración propia.</p>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left[ x_i^2 - 10 \cos(2\pi x_i) \right] \tag{3}
\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x_{1_0}\)</span></th>
<th><span class="math inline">\(x_{2_0}\)</span></th>
<th><span class="math inline">\(\eta\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-0.46</td>
<td>0.46</td>
<td>0.005</td>
<td>30</td>
</tr>
</tbody>
</table>
<p><strong>Figura 8.</strong></p>
<p><em>Aplicación del descenso del gradiente en la función de Rastrigin.</em> <img src="images/rastrigin.gif" class="img-fluid" alt="Aplicación del descenso del gradiente en la función de Rastrigin"> Elaboración propia.</p>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}
\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x_{1_0}\)</span></th>
<th><span class="math inline">\(x_{2_0}\)</span></th>
<th><span class="math inline">\(\eta\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>310</td>
<td>310</td>
<td>0.8</td>
<td>30</td>
</tr>
</tbody>
</table>
<p><strong>Figura 9.</strong></p>
<p><em>Aplicación del descenso del gradiente en la función de Schwefel.</em> <img src="images/schwefel.gif" class="img-fluid" alt="Aplicación del descenso del gradiente en la función de Schwefel"> Elaboración propia.</p>
</div>
<div id="tabset-2-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-4-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}
\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x_{1_0}\)</span></th>
<th><span class="math inline">\(x_{2_0}\)</span></th>
<th><span class="math inline">\(\eta\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-500</td>
<td>500</td>
<td>70</td>
<td>33</td>
</tr>
</tbody>
</table>
<p><strong>Figura 10.</strong></p>
<p><em>Aplicación del descenso del gradiente en la función de Griewank.</em> <img src="images/griewank.gif" class="img-fluid" alt="Aplicación del descenso del gradiente en la función de Griewank"> Elaboración propia.</p>
</div>
<div id="tabset-2-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-5-tab">
<p><span class="math display">\[
\begin{align}
f(x_1, x_2) = &amp; \left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right] \\
         &amp; \left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right]
\end{align} \tag{6}
\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x_{1_0}\)</span></th>
<th><span class="math inline">\(x_{2_0}\)</span></th>
<th><span class="math inline">\(\eta\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.5</td>
<td>-1.5</td>
<td>0.00005</td>
<td>50</td>
</tr>
</tbody>
</table>
<p><strong>Figura 11.</strong></p>
<p><em>Aplicación del descenso del gradiente en la función de Goldstein-Price.</em> <img src="images/goldstein_price.gif" class="img-fluid" alt="Aplicación del descenso del gradiente en la función de Goldstein-Price"> Elaboración propia.</p>
</div>
<div id="tabset-2-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-6-tab">
<p><span class="math display">\[
f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}
\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><span class="math inline">\(x_{1_0}\)</span></th>
<th><span class="math inline">\(x_{2_0}\)</span></th>
<th><span class="math inline">\(\eta\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>-1</td>
<td>-1</td>
<td>0.015</td>
<td>33</td>
</tr>
</tbody>
</table>
<p><strong>Figura 12.</strong></p>
<p><em>Aplicación del descenso del gradiente en la función de las seis jorobas del camello.</em> <img src="images/camel_six_humps.gif" class="img-fluid" alt="Aplicación del descenso del gradiente en la función de las seis jorobas del camello"> Elaboración propia.</p>
</div>
</div>
</div>
<p>El método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.</p>
<p>Para garantizar que este método sea eficiente, es importante considerar lo siguiente:</p>
<ul>
<li><p><strong>Tasa de aprendizaje</strong>: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.</p></li>
<li><p><strong>Punto inicial</strong>: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.</p></li>
<li><p><strong>Criterio de parada</strong>: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia).</p></li>
</ul>
</section>
<section id="agoritmo-genético" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="agoritmo-genético"><span class="header-section-number">2.2</span> Agoritmo genético</h2>
<p>Un algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la <strong>selección natural</strong> y la <strong>evolución biológica</strong>, propuesto inicialmente por <span class="citation" data-cites="holland1975adaptation">Holland (<a href="#ref-holland1975adaptation" role="doc-biblioref">1975</a>)</span>. Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.</p>
<section id="concepto-general" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="concepto-general"><span class="header-section-number">2.2.1</span> Concepto General</h3>
<p>El algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:</p>
<ul>
<li><p><strong>Selección</strong>: Elegir individuos con mayor <em>fitness</em>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p></li>
<li><p><strong>Cruce</strong>: Combinar soluciones para generar descendencia.</p></li>
<li><p><strong>Mutación</strong>: Introducir variación genética.</p></li>
</ul>
<p>Matemáticamente, en un problema de minimización, el objetivo es encontrar:</p>
<p><span class="math display">\[
x^* = \arg\min_{x \in \mathbb{R}^n} f(x) \tag{12}
\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(x\)</span> representa un individuo en el espacio de búsqueda.</li>
<li><span class="math inline">\(f(x)\)</span> es la función objetivo que evalúa la calidad de <span class="math inline">\(x\)</span>.</li>
</ul>
<p>Cada solución candidata se representa como un <strong>individuo</strong>, que puede ser un vector real o un cromosoma binario, tal como se ilustra en la Ecuación 13:</p>
<p><span class="math display">\[
x = (x_1, x_2, \ldots, x_n) \in \mathbb{R}^n \tag{13}
\]</span></p>
<p>La función objetivo, mostrada en la Ecuación 14, mide qué tan buena es una solución.</p>
<p><span class="math display">\[
\text{Fitness}(x) = f(x) \tag{14}
\]</span></p>
<p>Para problemas de <strong>minimización</strong>, menor <span class="math inline">\(f(x)\)</span> implica mejor fitness.</p>
<hr>
</section>
<section id="etapas" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="etapas"><span class="header-section-number">2.2.2</span> Etapas</h3>
<p><strong>Inicialización de la Población</strong></p>
<p>Se genera una población inicial de <span class="math inline">\(P\)</span> individuos de forma aleatoria dentro de un intervalo <span class="math inline">\([a, b]\)</span>:</p>
<p><span class="math display">\[
x_{ij} \sim \text{U}(a, b), \quad \forall i \in \{1, 2, \ldots, P\}, \; j \in \{1, 2, \ldots, n\} \tag{15}
\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(x_{ij}\)</span> es la <span class="math inline">\(j-ésima\)</span> coordenada del <span class="math inline">\(i-ésimo\)</span> individuo.</li>
</ul>
<div id="e31afafa" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inicializar población</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_population(size, dim, bounds):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.uniform(bounds[<span class="dv">0</span>], bounds[<span class="dv">1</span>], (size, dim))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<p><strong>Evaluación del Fitness</strong></p>
<p>Cada individuo de la población es evaluado usando la función objetivo mostrada a continuación, en la Ecuación 16.</p>
<p><span class="math display">\[
\text{Fitness}_i = f(x_i) \tag{16}
\]</span></p>
<div id="559a158b" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar fitness</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_fitness(population,fitness_function):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([fitness_function(ind) <span class="cf">for</span> ind <span class="kw">in</span> population])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<p><strong>Selección</strong></p>
<p>Se seleccionan individuos para reproducirse basándose en su fitness. Un métodos común es el método de torneo, observado en la Ecuación 17, donde primero se seleccionan <span class="math inline">\(k\)</span> individuos al azar y luego se elige al mejor de ellos (quien tenga el mejor fitness):</p>
<p><span class="math display">\[
\text{Individuo seleccionado} = \arg\min_{j \in S} \text{Fitness}_j, \; S \subseteq \{1, \ldots, P\}, \; |S| = k \tag{17}
\]</span></p>
<div id="028b99c5" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Selección por torneo</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tournament_selection(population, fitness, k<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    selected <span class="op">=</span> []</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(population)):</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        candidates <span class="op">=</span> np.random.choice(<span class="bu">range</span>(<span class="bu">len</span>(population)), k, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        winner <span class="op">=</span> candidates[np.argmin(fitness[candidates])]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        selected.append(population[winner])</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(selected)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<p><strong>Cruce (Recombinación)</strong></p>
<p>Dos individuos (padres) se combinan para generar descendencia. Un método común es <strong>punto de corte único</strong>, donde primero se elige un punto de cruce aleatorio <span class="math inline">\(k\)</span> y después se genera la descendencia mezclando las características de los padres, como se observa en las Ecuaciones 18 y 19.</p>
<p><span class="math display">\[
\text{Hijo 1} = (\text{Padre}_1[:k], \text{Padre}_2[k:]) \tag{18}
\]</span></p>
<p><span class="math display">\[
\text{Hijo 2} = (\text{Padre}_2[:k], \text{Padre}_1[k:]) \tag{19}
\]</span></p>
<p>La probabilidad de realizar un cruce está determinada por <span class="math inline">\(p_c\)</span> (tasa de cruce).</p>
<div id="d96bf086" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cruce</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crossover(parent1, parent2, crossover_rate):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> crossover_rate:</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        point <span class="op">=</span> np.random.randint(<span class="dv">1</span>, <span class="bu">len</span>(parent1))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        child <span class="op">=</span> np.concatenate([parent1[:point], parent2[point:]])</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> child</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> parent1 <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> <span class="fl">0.5</span> <span class="cf">else</span> parent2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<p><strong>Mutación</strong></p>
<p>Se introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad <span class="math inline">\(p_m\)</span>:</p>
<p><span class="math display">\[
x_{ij} = x_{ij} + \Delta, \quad \Delta \sim \text{U}(-\delta, \delta) \tag{20}
\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(\Delta\)</span> es una perturbación aleatoria.</li>
<li><span class="math inline">\(x_{ij}\)</span> se restringe a los límites del problema.</li>
</ul>
<div id="7dde67cd" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mutación</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutate(individual, bounds, mutation_rate, delta):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(individual)):</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> mutation_rate:</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>            individual[i] <span class="op">+=</span> np.random.uniform(<span class="op">-</span>delta, delta)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>            individual[i] <span class="op">=</span> np.clip(individual[i], bounds[<span class="dv">0</span>], bounds[<span class="dv">1</span>])</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> individual</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<p><strong>Evaluación y Sustitución</strong></p>
<p>La nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.</p>
<div id="3a8bbea3" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Algoritmo completo</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> initialize_population(population_size, dim, bounds)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    best_individual <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    trajectory <span class="op">=</span> []</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    populations <span class="op">=</span> []</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> generation <span class="kw">in</span> <span class="bu">range</span>(generations):</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        populations.append(population.copy())</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        fitness <span class="op">=</span> evaluate_fitness(population, fitness_function)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_individual <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> np.<span class="bu">min</span>(fitness) <span class="op">&lt;</span> fitness_function(best_individual):</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>            best_individual <span class="op">=</span> population[np.argmin(fitness)]</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Guardar la mejor solución de esta generación</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        trajectory.append((<span class="op">*</span>best_individual, fitness_function(best_individual)))</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Selección</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        selected_population <span class="op">=</span> tournament_selection(population, fitness)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cruce y mutación</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        new_population <span class="op">=</span> []</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(selected_population), <span class="dv">2</span>):</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> <span class="bu">len</span>(selected_population):</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>                child1 <span class="op">=</span> crossover(selected_population[i], selected_population[i<span class="op">+</span><span class="dv">1</span>], crossover_rate)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>                child2 <span class="op">=</span> crossover(selected_population[i<span class="op">+</span><span class="dv">1</span>], selected_population[i], crossover_rate)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>                new_population.extend([child1, child2])</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>                new_population.append(selected_population[i])</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>        population <span class="op">=</span> np.array([mutate(ind, bounds, mutation_rate, delta) <span class="cf">for</span> ind <span class="kw">in</span> new_population])</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convertir la trayectoria a DataFrame</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    columns <span class="op">=</span> [<span class="ss">f'x</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(dim)] <span class="op">+</span> [<span class="st">'f(x)'</span>]</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(trajectory, columns<span class="op">=</span>columns)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_individual, fitness_function(best_individual), df, populations</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Función de Rosenbrock</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Función de Rastrigin</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Función de Schwefel</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-4" role="tab" aria-controls="tabset-3-4" aria-selected="false">Función de Griewank</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-5" role="tab" aria-controls="tabset-3-5" aria-selected="false">Función Goldstein-Price</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-6" role="tab" aria-controls="tabset-3-6" aria-selected="false">Función de las seis jorobas de camello</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p><span class="math display">\[
f(\mathbf{x}) = \sum_{i=1}^{d-1} \left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right] \tag{1}
\]</span></p>
<p><strong>Figura 13.</strong></p>
<p><em>Aplicación del algoritmo genético sobre la función de Rosenbrok.</em> <img src="images/Rosenbrock_population_animation.gif" class="img-fluid" alt="Aplicación del algoritmo genético sobre la función de Rosenbrok"> Elaboración propia.</p>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left[ x_i^2 - 10 \cos(2\pi x_i) \right] \tag{3}
\]</span></p>
<p><strong>Figura 14.</strong></p>
<p><em>Aplicación del algoritmo genético sobre la función de Rastrigin.</em> <img src="images/Rastrigin_population_animation.gif" class="img-fluid" alt="Aplicación del algoritmo genético sobre la función de Rastrigin"> Elaboración propia.</p>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}
\]</span></p>
<p><strong>Figura 15.</strong></p>
<p><em>Aplicación del algoritmo genético sobre la función de Schwefel.</em> <img src="images/Schwefel_population_animation.gif" class="img-fluid" alt="Aplicación del algoritmo genético sobre la función de Schwefel"> Elaboración propia.</p>
</div>
<div id="tabset-3-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-4-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}
\]</span></p>
<p><strong>Figura 16.</strong></p>
<p><em>Aplicación del algoritmo genético sobre la función de Griewank.</em> <img src="images/Griewank_population_animation.gif" class="img-fluid" alt="Aplicación del algoritmo genético sobre la función de Griewank"> Elaboración propia.</p>
</div>
<div id="tabset-3-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-5-tab">
<p><span class="math display">\[
\begin{align}
f(x_1, x_2) = &amp; \left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right] \\
         &amp; \left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right]
\end{align} \tag{6}
\]</span></p>
<p><strong>Figura 17.</strong></p>
<p><em>Aplicación del algoritmo genético sobre la función de Goldstein-Price.</em> <img src="images/Goldstein_Price_population_animation.gif" class="img-fluid" alt="Aplicación del algoritmo genético sobre la función de Goldstein-Price"> Elaboración propia.</p>
</div>
<div id="tabset-3-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-6-tab">
<p><span class="math display">\[
f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}
\]</span></p>
<p><strong>Figura 18.</strong></p>
<p><em>Aplicación del algoritmo genético sobre la función de las seis jorobas del camello.</em> <img src="images/Camel_Six_Humps_population_animation.gif" class="img-fluid" alt="Aplicación del algoritmo genético sobre la función de las seis jorobas del camello"> Elaboración propia.</p>
</div>
</div>
</div>
<p>Los algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: <strong>exploración</strong>, que consiste en descubrir nuevas regiones del espacio de búsqueda, y <strong>explotación</strong>, enfocada en refinar y mejorar las soluciones existentes.</p>
<p>Para las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación <span class="math inline">\(\delta\)</span> se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.</p>
</section>
<section id="observaciones" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="observaciones"><span class="header-section-number">2.2.3</span> Observaciones</h3>
<p>Ventajas:</p>
<ul>
<li>No requiere derivadas ni condiciones específicas en <span class="math inline">\(f(x)\)</span> .</li>
<li>Es efectivo en espacios de búsqueda multimodales o no convexos.</li>
<li>Adaptable a diversos problemas.</li>
</ul>
<p>Desventajas:</p>
<ul>
<li>Puede ser computacionalmente costoso.</li>
<li>No garantiza convergencia al óptimo global.</li>
<li>Requiere ajuste cuidadoso de parámetros.</li>
</ul>
</section>
</section>
<section id="optimización-de-partículas" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="optimización-de-partículas"><span class="header-section-number">2.3</span> Optimización de partículas</h2>
<section id="concepto-básico-y-analogía" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="concepto-básico-y-analogía"><span class="header-section-number">2.3.1</span> Concepto Básico y Analogía</h3>
<p>De acuerdo con <span class="citation" data-cites="kennedy1995particle">Kennedy and Eberhart (<a href="#ref-kennedy1995particle" role="doc-biblioref">1995</a>)</span>, puede decirse que la Optimización por Enjambre de Partículas (PSO) es una técnica metaheurística inspirada en el comportamiento social de los animales, como los pájaros o los peces. En PSO, cada solución potencial al problema se representa como una partícula que se mueve en un espacio de búsqueda multidimensional. Cada partícula ajusta su posición y velocidad en cada iteración, basándose en su propia mejor posición encontrada (pBest) y la mejor posición encontrada por todo el enjambre (gBest).</p>
<p>Los métodos PSO se atribuyen originalmente a los investigadores <span class="citation" data-cites="kennedy1997particle">Kennedy (<a href="#ref-kennedy1997particle" role="doc-biblioref">1997</a>)</span>. En un principio fueron concebidos para elaborar modelos de conductas sociales,​como el movimiento descrito por los organismos vivos en una bandada de aves o un banco de peces. Posteriormente el algoritmo se simplificó y se comprobó que era adecuado para problemas de optimización.</p>
<p><strong>Funcionamiento de PSOz</strong></p>
<p>En el algoritmo PSO (Particle Swarm Optimization), cada partícula, que representa un individuo, posee una posición <em>p</em>⃗&nbsp; ​ dentro del espacio de búsqueda y una velocidad <em>v</em>⃗&nbsp;que determina su desplazamiento. Estas partículas, al igual que objetos en un entorno físico, cuentan con una inercia <em>w</em>, la cual conserva su movimiento en la dirección previamente seguida.</p>
<div id="ecef50a3" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.positions <span class="op">=</span> np.random.uniform(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bounds[:, <span class="dv">0</span>],</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bounds[:, <span class="dv">1</span>],</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span>(n_particles, dimensions)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.velocities <span class="op">=</span> np.zeros((n_particles, dimensions))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar posiciones iniciales</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.scores <span class="op">=</span> np.array([<span class="va">self</span>.objective_function(p) <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.positions])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Además, su aceleración, que representa un cambio en la velocidad, está influenciada por dos factores principales:</p>
<ul>
<li><p>Atracción hacia su mejor posición personal: Cada partícula tiende a moverse hacia la mejor ubicación que ha identificado en su trayectoria histórica (<em>pbest).</em></p></li>
<li><p>Atracción hacia la mejor posición global: Las partículas también se dirigen hacia la mejor ubicación encontrada por el grupo completo en el espacio de búsqueda (<em>pgbest</em>).</p></li>
</ul>
<p><em>Ilustración del funcionamiento del algoritmo PSO.</em> <img src="images/paste-1.png" class="img-fluid" alt="Ilustración del funcionamiento del algoritmo PSO"></p>
<p>Adaptado de <span class="citation" data-cites="sancho_pso_image">Sancho Caparrini (<a href="#ref-sancho_pso_image" role="doc-biblioref">2024</a>)</span></p>
<div id="6515efa3" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.max_iter):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar velocidades</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    r1, r2 <span class="op">=</span> np.random.rand(<span class="dv">2</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.velocities <span class="op">=</span> (<span class="va">self</span>.w <span class="op">*</span> <span class="va">self</span>.velocities <span class="op">+</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.c1 <span class="op">*</span> r1 <span class="op">*</span> (<span class="va">self</span>.p_best <span class="op">-</span> <span class="va">self</span>.positions) <span class="op">+</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.c2 <span class="op">*</span> r2 <span class="op">*</span> (<span class="va">self</span>.g_best <span class="op">-</span> <span class="va">self</span>.positions))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar posiciones</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.positions <span class="op">+=</span> <span class="va">self</span>.velocities</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mantener partículas dentro de los límites</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.positions <span class="op">=</span> np.clip(</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positions,</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bounds[:, <span class="dv">0</span>],</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bounds[:, <span class="dv">1</span>]</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluar nuevas posiciones</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.scores <span class="op">=</span> np.array([<span class="va">self</span>.objective_function(p) <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.positions])</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar mejores posiciones personales</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    improved_mask <span class="op">=</span> <span class="va">self</span>.scores <span class="op">&lt;</span> <span class="va">self</span>.p_best_scores</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.p_best[improved_mask] <span class="op">=</span> <span class="va">self</span>.positions[improved_mask]</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.p_best_scores[improved_mask] <span class="op">=</span> <span class="va">self</span>.scores[improved_mask]</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar mejor posición global</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    min_score_idx <span class="op">=</span> np.argmin(<span class="va">self</span>.p_best_scores)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.p_best_scores[min_score_idx] <span class="op">&lt;</span> <span class="va">self</span>.g_best_score:</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.g_best <span class="op">=</span> <span class="va">self</span>.p_best[min_score_idx].copy()</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.g_best_score <span class="op">=</span> <span class="va">self</span>.p_best_scores[min_score_idx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El algoritmo se detiene cuando se alcanza un número máximo de iteraciones, o cuando la mejora en la función objetivo es menor a un umbral predefinido.</p>
<p>Al implementar el algoritmo, se presentó un comportamiento oscilatorio donde las partículas convergían inicialmente pero luego se dispersaban de manera repentina. El análisis reveló cuatro posibles causas: velocidades excesivas de las partículas, coeficientes de aprendizaje mal ajustados, peso de inercia estático y ausencia de un mecanismo de estabilización.</p>
<p>La solución implementada aborda estos problemas mediante cuatro modificaciones: Se &nbsp;limitó la velocidad máxima al 10% del espacio de búsqueda para evitar saltos excesivos, se optimizaron los coeficientes cognitivo y social a un valor de 2.0 para balancear exploración y explotación, se implementó un peso de inercia dinámico que decrece linealmente de 0.9 a 0.4 durante la optimización y se añadió un factor de constricción calculado a partir de los coeficientes de aprendizaje para garantizar convergencia matemática.</p>
<div id="ff9caf05" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Control de Velocidad Máxima</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>v_max <span class="op">=</span> <span class="fl">0.1</span> <span class="op">*</span> (bounds[:, <span class="dv">1</span>] <span class="op">-</span> bounds[:, <span class="dv">0</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>velocities <span class="op">=</span> np.clip(velocities, <span class="op">-</span>v_max, v_max)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Peso de Inercia Dinámico</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> w_max <span class="op">-</span> (w_max <span class="op">-</span> w_min) <span class="op">*</span> (iteracion <span class="op">/</span> max_iter)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Factor de Constricción</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>phi <span class="op">=</span> c1 <span class="op">+</span> c2</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>chi <span class="op">=</span> <span class="dv">2</span> <span class="op">/</span> <span class="bu">abs</span>(<span class="dv">2</span> <span class="op">-</span> phi <span class="op">-</span> np.sqrt(phi <span class="op">*</span> phi <span class="op">-</span> <span class="dv">4</span> <span class="op">*</span> phi))</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Parámetros Optimizados</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>c1 <span class="op">=</span> c2 <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>w_max <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>w_min <span class="op">=</span> <span class="fl">0.4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Estas modificaciones resultaron en una mejora significativa en la estabilidad del algoritmo, con una transición más suave entre las fases de exploración y explotación, y una convergencia más consistente hacia el óptimo global.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Función de Rosenbrock</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Función de Rastrigin</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">Función de Schwefel</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-4" role="tab" aria-controls="tabset-4-4" aria-selected="false">Función de Griewank</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-5" role="tab" aria-controls="tabset-4-5" aria-selected="false">Función Goldstein-Price</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-6" role="tab" aria-controls="tabset-4-6" aria-selected="false">Función de las seis jorobas de camello</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<p><span class="math display">\[
f(\mathbf{x}) = \sum_{i=1}^{d-1} \left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right] \tag{1}
\]</span></p>
<p><strong>Figura 19.</strong></p>
<p><em>Aplicación de optimización de partículas sobre la función de Rosenbrock.</em> <img src="images/Rosenbrock_particulas_animation.gif" class="img-fluid" alt="Aplicación de optimización de partículas sobre la función de Rosenbrock"> Elaboración propia.</p>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left[ x_i^2 - 10 \cos(2\pi x_i) \right] \tag{3}
\]</span></p>
<p><strong>Figura 20.</strong></p>
<p><em>Aplicación de optimización de partículas sobre la función de Rastrigin.</em> <img src="images/Rastrigin_particulas_animation.gif" class="img-fluid" alt="Aplicación de optimización de partículas sobre la función de Rastrigin"> Elaboración propia.</p>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}
\]</span></p>
<p><strong>Figura 21.</strong></p>
<p><em>Aplicación de optimización de partículas sobre la función de Schwefel.</em> <img src="images/Schwefel_particulas_animation.gif" class="img-fluid" alt="Aplicación de optimización de partículas sobre la función de Schwefel"> Elaboración propia.</p>
</div>
<div id="tabset-4-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-4-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}
\]</span></p>
<p><strong>Figura 22.</strong></p>
<p><em>Aplicación de optimización de partículas sobre la función de Griewank.</em> <img src="images/Griewank_particulas_animation.gif" class="img-fluid" alt="Aplicación de optimización de partículas sobre la función de Griewank"> Elaboración propia.</p>
</div>
<div id="tabset-4-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-5-tab">
<p><span class="math display">\[
\begin{align}
f(x_1, x_2) = &amp; \left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right] \\
         &amp; \left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right]
\end{align} \tag{6}
\]</span></p>
<p><strong>Figura 23.</strong></p>
<p><em>Aplicación de optimización de partículas sobre la función de Goldstein-Price.</em> <img src="images/Goldstein_Price_particulas_animation.gif" class="img-fluid" alt="Aplicación de optimización de partículas sobre la función de Goldstein-Price"> Elaboración propia.</p>
</div>
<div id="tabset-4-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-6-tab">
<p><span class="math display">\[
f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}
\]</span></p>
<p><strong>Figura 24.</strong></p>
<p><em>Aplicación de optimización de partículas sobre la función de las seis jorobas del camello.</em> <img src="images/Camel_Six_Humps_particulas_animation.gif" class="img-fluid" alt="Aplicación de optimización de partículas sobre la función de las seis jorobas del camello"> Elaboración propia.</p>
</div>
</div>
</div>
</section>
</section>
<section id="optimización-diferencial" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="optimización-diferencial"><span class="header-section-number">2.4</span> Optimización diferencial</h2>
<p><strong>Funcionamiento Básico</strong></p>
<p>La Evolución Diferencial (ED) es un algoritmo de optimización poblacional inspirado en los procesos evolutivos naturales. Al igual que otros algoritmos de esta categoría, la ED mantiene una población de soluciones candidatas, las cuales se recombinan y mutan para producir nuevos individuos los cuales serán elegidos de acuerdo al valor de su función de desempeño. Lo que caracteriza a la ED es el uso de vectores de prueba, los cuales compiten con los individuos de la población actual a fin de sobrevivir. <span class="citation" data-cites="price1995differential">(<a href="#ref-price1995differential" role="doc-biblioref">Price and Storn 1995</a>)</span></p>
<p><strong>Pasos clave:</strong></p>
<ul>
<li><p><strong>Inicialización de la población:</strong></p>
<ul>
<li><p>Se genera aleatoriamente una población inicial de individuos (soluciones potenciales).</p></li>
<li><p>Cada individuo es un vector que representa un punto en el espacio de búsqueda.</p></li>
</ul></li>
</ul>
<div id="881817cb" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_population(<span class="va">self</span>):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Inicializa la población de manera aleatoria dentro de los límites especificados</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - Matriz numpy con población inicial</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crea una matriz de ceros con el tamaño de la población</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> np.zeros((<span class="va">self</span>.population_size, <span class="va">self</span>.dimension))</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Genera valores aleatorios para cada dimensión</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.dimension):</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        population[:, i] <span class="op">=</span> np.random.uniform(</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bounds[i][<span class="dv">0</span>],  <span class="co"># Límite inferior</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bounds[i][<span class="dv">1</span>],  <span class="co"># Límite superior</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>            size<span class="op">=</span><span class="va">self</span>.population_size  <span class="co"># Número de individuos</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li><p><strong>Evaluación de la población:</strong></p>
<ul>
<li>Se evalúa el valor de la función objetivo para cada individuo de la población</li>
</ul></li>
<li><p><strong>Generación de nuevos individuos:</strong></p>
<ul>
<li><strong>Mutación:</strong> Se crea un vector mutante sumando a un individuo objetivo una diferencia escalada entre otros dos individuos de la población.</li>
</ul></li>
</ul>
<div id="252c6934" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutation(<span class="va">self</span>, population):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Aplica la estrategia de mutación DE/rand/1</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - population: Población actual</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - Población mutada</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crea una matriz para almacenar la población mutada</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    mutation_pop <span class="op">=</span> np.zeros_like(population)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.population_size):</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Selecciona tres individuos aleatorios diferentes</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        candidates <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="va">self</span>.population_size))</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        candidates.remove(i)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        r1, r2, r3 <span class="op">=</span> np.random.choice(candidates, <span class="dv">3</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera un nuevo vector mediante mutación</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        mutation_pop[i] <span class="op">=</span> population[r1] <span class="op">+</span> <span class="va">self</span>.F <span class="op">*</span> (population[r2] <span class="op">-</span> </span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>                                                               population[r3])</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Asegura que los valores estén dentro de los límites</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.dimension):</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>            mutation_pop[i, j] <span class="op">=</span> np.clip(</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>                mutation_pop[i, j],</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.bounds[j][<span class="dv">0</span>],</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.bounds[j][<span class="dv">1</span>]</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mutation_pop</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li><strong>Cruce:</strong> Se crea un vector de prueba combinando el vector mutante y el individuo objetivo mediante un operador de cruce.</li>
</ul>
<div id="2acdebb2" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crossover(<span class="va">self</span>, population, mutation_pop):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Aplica el cruce binomial (crossover)</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - population: Población actual</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - mutation_pop: Población mutada</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - Población de prueba tras el cruce</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crea una matriz para almacenar la población de prueba</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    trial_pop <span class="op">=</span> np.zeros_like(population)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.population_size):</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera puntos de cruce basados en CR</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        cross_points <span class="op">=</span> np.random.rand(<span class="va">self</span>.dimension) <span class="op">&lt;=</span> <span class="va">self</span>.CR</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Asegura al menos un punto de cruce</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        cross_points[np.random.randint(<span class="dv">0</span>, <span class="va">self</span>.dimension)] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera vector de prueba</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        trial_pop[i] <span class="op">=</span> np.where(cross_points, mutation_pop[i], population[i])</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> trial_pop</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li><strong>Selección:</strong> Se compara el valor de la función objetivo del vector de prueba con el del individuo objetivo. El mejor de los dos se selecciona para la siguiente generación.</li>
</ul>
<div id="9b84a3c8" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> selection(<span class="va">self</span>, population, trial_pop):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Selección de los mejores individuos</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">    - population: Población actual</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - trial_pop: Población de prueba</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">    - Nueva población y sus valores de aptitud</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcula la aptitud de la población actual y de prueba</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    pop_fitness <span class="op">=</span> np.array([<span class="va">self</span>.func(ind) <span class="cf">for</span> ind <span class="kw">in</span> population])</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    trial_fitness <span class="op">=</span> np.array([<span class="va">self</span>.func(ind) <span class="cf">for</span> ind <span class="kw">in</span> trial_pop])</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Identifica qué individuos de prueba son mejores</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    better_indices <span class="op">=</span> trial_fitness <span class="op">&lt;</span> pop_fitness</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    population[better_indices] <span class="op">=</span> trial_pop[better_indices]</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population, np.minimum(pop_fitness, trial_fitness)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li><p><strong>Criterio de parada</strong>:</p>
<ul>
<li>Se repiten los pasos 3 y 4 hasta que se cumpla un criterio de parada (número máximo de generaciones, mejora mínima en la función objetivo, etc.), de acuerdo con <span class="citation" data-cites="martinez2019evolucion">Martínez Zecua et al. (<a href="#ref-martinez2019evolucion" role="doc-biblioref">2019</a>)</span>.</li>
</ul></li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Función de Rosenbrock</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Función de Rastrigin</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-3" role="tab" aria-controls="tabset-5-3" aria-selected="false">Función de Schwefel</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-4" role="tab" aria-controls="tabset-5-4" aria-selected="false">Función de Griewank</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-5" role="tab" aria-controls="tabset-5-5" aria-selected="false">Función Goldstein-Price</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-6" role="tab" aria-controls="tabset-5-6" aria-selected="false">Función de las seis jorobas de camello</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<p><span class="math display">\[
f(\mathbf{x}) = \sum_{i=1}^{d-1} \left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right] \tag{1}
\]</span></p>
<p><strong>Figura 25.</strong></p>
<p><em>Aplicación de optimización diferencial sobre la función de Rosenbrock.</em> <img src="images/Rosenbrock_diferential_evolution_animation.gif" class="img-fluid" alt="Aplicación de optimización diferencial sobre la función de Rosenbrock"> Elaboración propia.</p>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left[ x_i^2 - 10 \cos(2\pi x_i) \right] \tag{3}
\]</span></p>
<p><strong>Figura 26.</strong></p>
<p><em>Aplicación de optimización diferencial sobre la función de Rastrigin.</em> <img src="images/Rastrigin_diferential_evolution_animation.gif" class="img-fluid" alt="Aplicación de optimización diferencial sobre la función de Rastrigin"> Elaboración propia.</p>
</div>
<div id="tabset-5-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-3-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}
\]</span></p>
<p><strong>Figura 27.</strong></p>
<p><em>Aplicación de optimización diferencial sobre la función de Schwefel.</em> <img src="images/Schwefel_diferential_evolution_animation.gif" class="img-fluid" alt="Aplicación de optimización diferencial sobre la función de Schwefel"> Elaboración propia.</p>
</div>
<div id="tabset-5-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-4-tab">
<p><span class="math display">\[
f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}
\]</span></p>
<p><strong>Figura 28.</strong></p>
<p><em>Aplicación de optimización diferencial sobre la función de Griewank.</em> <img src="images/Griewank_diferential_evolution_animation.gif" class="img-fluid" alt="Aplicación de optimización diferencial sobre la función de Griewank"> Elaboración propia.</p>
</div>
<div id="tabset-5-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-5-tab">
<p><span class="math display">\[
\begin{align} f(x_1, x_2) = &amp; \left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right] \\          &amp; \left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right] \end{align} \tag{6}
\]</span></p>
<p><strong>Figura 29.</strong></p>
<p><em>Aplicación de optimización diferencial sobre la función de Goldstein-Price.</em> <img src="images/Goldstein_Price_diferential_evolution_animation.gif" class="img-fluid" alt="Aplicación de optimización diferencial sobre la función de Goldstein-Price"> Elaboración propia.</p>
</div>
<div id="tabset-5-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-6-tab">
<p><span class="math display">\[
f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}
\]</span></p>
<p><strong>Figura 30.</strong></p>
<p><em>Aplicación de optimización diferencial sobre la función de las seis jorobas del camello.</em> <img src="images/Camel_Six_Humps_diferential_evolution_animation.gif" class="img-fluid" alt="Aplicación de optimización diferencial sobre la función de las seis jorobas del camello"> Elaboración propia.</p>
</div>
</div>
</div>
</section>
</section>
<section id="resultados" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Resultados</h1>
<p>Como se puede observar, en la mayoría de los casos de optimización para una única corrida los puntos óptimos conergen a mínimos locales, lo que indica que los resultados óptimos pueden estar fuertemente influenciados por los valores iniciales de <span class="math inline">\(x\)</span> o las condiciones de inicio de los algoritmos. Por esta razón, para evaluar el rendimiento y el comportamiento de los algoritmos en un entorno más general, se realizarán múltiples ejecuciones. En cada corrida, los algoritmos partirán de valores iniciales distintos generados aleatoriamente. Con esto se verá cuánto tardan los algoritmos en mejorar la evaluación de la función objetivo y cuáles pueden ser algunos comentarios particulares a realizar. Los resultados se presentarán para los casos de 2 y 3 dimensiones de las funciones.</p>
<p>(Tabla o gráfica de resutlados)</p>
</section>
<section id="conclusiones-y-comentarios" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Conclusiones y comentarios</h1>
</section>
<section id="discusión" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Discusión</h1>
<p>Reflexione sobre los siguientes puntos:</p>
<p>¿Qué aportaron los métodos de <strong>descenso por gradiente</strong> y qué aportaron los <strong>métodos heurísticos</strong>? Para responder a esta pregunta, considere:</p>
<ul>
<li>El <strong>valor final</strong> de la función objetivo.</li>
<li>El <strong>número de evaluaciones</strong> de la función objetivo.</li>
</ul>
<p>Es posible que se requiera realizar <strong>varias corridas</strong> de los algoritmos para obtener conclusiones significativas.</p>


<!-- -->


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bishop2006pattern" class="csl-entry" role="listitem">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. Springer.
</div>
<div id="ref-holland1975adaptation" class="csl-entry" role="listitem">
Holland, John H. 1975. <em>Adaptation in Natural and Artificial Systems</em>. University of Michigan Press.
</div>
<div id="ref-kennedy1997particle" class="csl-entry" role="listitem">
Kennedy, J. 1997. <span>“The Particle Swarm: Social Adaptation of Knowledge.”</span> In <em>Proceedings of the IEEE International Conference on Evolutionary Computation</em>, 303–8.
</div>
<div id="ref-kennedy1995particle" class="csl-entry" role="listitem">
Kennedy, J., and R. Eberhart. 1995. <span>“Particle Swarm Optimization.”</span> In <em>Proceedings of the IEEE International Conference on Neural Networks (ICNN)</em>, 4:1942–48.
</div>
<div id="ref-martinez2019evolucion" class="csl-entry" role="listitem">
Martínez Zecua, M. Y., L. A. Salamanca Vázquez, L. Flores Pulido, E. A. Portilla Flores, and A. Ortíz Arroyo. 2019. <span>“Evolución Diferencial Para La Optimización Global de Procesos de Ingeniería Química.”</span> <em>Research in Computing Science</em> 148 (8).
</div>
<div id="ref-molga2005test" class="csl-entry" role="listitem">
Molga, M., and C. Smutnicki. 2005. <span>“Test Functions for Optimization Needs.”</span> <a href="http://www.zsd.ict.pwr.wroc.pl/files/docs/functions.pdf">http://www.zsd.ict.pwr.wroc.pl/files/docs/functions.pdf</a>.
</div>
<div id="ref-picheny2012benchmark" class="csl-entry" role="listitem">
Picheny, V., T. Wagner, and D. Ginsbourger. 2012. <span>“A Benchmark of Kriging-Based Infill Criteria for Noisy Optimization.”</span> <em>Computational Statistics &amp; Data Analysis</em>.
</div>
<div id="ref-price1995differential" class="csl-entry" role="listitem">
Price, Kenneth, and Rainer Storn. 1995. <span>“Differential Evolution: A Simple and Efficient Adaptive Scheme for Global Optimization over Continuous Spaces.”</span> Technical Report. International Computer Science Institute.
</div>
<div id="ref-sancho_pso_image" class="csl-entry" role="listitem">
Sancho Caparrini, Fernando. 2024. <span>“Imagen Sobre PSO.”</span> 2024. <a href="https://www.cs.us.es/~fsancho/Blog/posts/PSO.md">https://www.cs.us.es/~fsancho/Blog/posts/PSO.md</a>.
</div>
<div id="ref-simonfraser_rosenbrock" class="csl-entry" role="listitem">
Simon Fraser University. n.d. <span>“Rosenbrock Function.”</span> <a href="https://www.sfu.ca/~ssurjano/rosen.html">https://www.sfu.ca/~ssurjano/rosen.html</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>El <em>fitness</em> representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Optimización Heurística"</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-width: 8      # Ancho de las figuras en pulgadas para HTML</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-height: 6     # Alto de las figuras en pulgadas para HTML</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Julián Castaño Pineda"</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Luis Andrés Altamar Romero"</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Catalina Restrepo Salgado"</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Tomás Rodríguez Taborda"</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-11-29"</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [optimización, métodos heurísticos, python]</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "image.jpg"</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> ref.bib</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co">  cache: true</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.animation <span class="im">import</span> FuncAnimation</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image <span class="im">as</span> IPImage</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>El objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>Al final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas.</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a><span class="fu"># Funciones a optimizar</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>Se seleccionaron seis funciones comúnmente empleadas para evaluar métodos de optimización, debido a sus características particulares. Estas funciones presentan desafíos como la existencia de un mínimo global acompañado de múltiples mínimos locales, así como valles que pueden dificultar la convergencia de los algoritmos. A continuación, se describen dichas funciones, incluyendo su forma funcional generalizada para $d$ dimensiones, su representación gráfica en 2 dimensiones, el valor del mínimo global, una breve descripción de cada función y el rango de evaluación sugerido por diversos autores. Las gráficas fueron generadas a partir de la funcion <span class="in">`plot_function()`</span> que se muestra en la pestaña de <span class="in">`Code`</span> sugerida.</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_function(f, x1_range, x2_range, title<span class="op">=</span><span class="st">"Function Plot"</span>, x1_point<span class="op">=</span><span class="va">None</span>, x2_point<span class="op">=</span><span class="va">None</span>, elev<span class="op">=</span><span class="dv">30</span>, azim<span class="op">=</span><span class="dv">45</span> ):</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> np.linspace(x1_range[<span class="dv">0</span>], x1_range[<span class="dv">1</span>], <span class="dv">400</span>)</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> np.linspace(x2_range[<span class="dv">0</span>], x2_range[<span class="dv">1</span>], <span class="dv">400</span>)</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>    X1, X2 <span class="op">=</span> np.meshgrid(x1, x2)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> f(np.array([X1,X2]))</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3D plot</span></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    ax1.plot_surface(X1, X2, Z)</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="ss">f'3D Plot of </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'X1'</span>)</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'X2'</span>)</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>    ax1.set_zlabel(<span class="st">'Z'</span>)</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>    ax1.view_init(elev<span class="op">=</span>elev, azim<span class="op">=</span>azim)</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x1_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> x2_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>        z_point <span class="op">=</span> f(np.array([x1_point, x2_point])[:, <span class="va">None</span>, <span class="va">None</span>])[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>        ax1.plot([x1_point], [x2_point], [z_point], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">5</span>, linewidth<span class="op">=</span><span class="dv">0</span>, label<span class="op">=</span><span class="st">"Mínimo global"</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>        ax1.legend()</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Contour plot</span></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>)</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>    contour <span class="op">=</span> ax2.contour(X1, X2, Z, levels <span class="op">=</span> <span class="dv">10</span>)</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="ss">f'Contour Plot of </span><span class="sc">{</span>title<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'X1'</span>)</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'X2'</span>)</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>    fig.colorbar(contour, ax<span class="op">=</span>ax2)</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x1_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> x2_point <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>        ax2.plot([x1_point], [x2_point], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">5</span>, linewidth<span class="op">=</span><span class="dv">0</span>, label<span class="op">=</span><span class="st">"Mínimo global"</span>, zorder<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>        ax2.legend()</span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a><span class="fu">## Función de Rosenbrock</span></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = \sum_{i=1}^{d-1} \left<span class="co">[</span><span class="ot"> 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right</span><span class="co">]</span> \tag{1}</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a>**Figura 1.**</span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>*Representación gráfica de la función de Rosenbrock.*</span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a><span class="co">#| width: 100%</span></span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a><span class="co">#| height: auto</span></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Rosenbrock</span></span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock(x, a<span class="op">=</span><span class="dv">1</span>, b<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de Rosenbrock.</span></span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a><span class="co">    x: vector de entrada (numpy array)</span></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a><span class="co">    a, b: parámetros de la función</span></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="bu">sum</span>(b <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> (x[:<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span> a)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>plot_function(rosenbrock, x1_range<span class="op">=</span>(<span class="op">-</span><span class="fl">2.048</span>, <span class="fl">2.048</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="fl">2.048</span>, <span class="fl">2.048</span>), title<span class="op">=</span><span class="st">"Función Rosenbrock"</span>, x1_point<span class="op">=</span><span class="dv">1</span>, x2_point<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>Elaboración propia.</span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>En 2 dimensiones se puede definir como se muestra en la Ecuación (2).</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = (a - x_1)^2 + b(x_2 - x_1^2)^2 \tag{2}</span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a>La Función de Rosenbrock, también conocida como función del valle o del plátano, es ampliamente utilizada para evaluar algoritmos de optimización basados en gradientes. Esta función es unimodal y presenta su mínimo global en un valle parabólico estrecho, lo que facilita su localización. Sin embargo, según @simonfraser_rosenbrock citando a @picheny2012benchmark, la convergencia hacia este mínimo puede ser desafiante debido a la naturaleza del valle.</span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a>La función se evalúa generalmente en el hipercubo $x_i \in <span class="co">[</span><span class="ot">-5, 10</span><span class="co">]</span>$ y tiene un mínimo global en $f(1,...,1) = 0$</span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## Función de Rastrigin</span></span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left<span class="co">[</span><span class="ot"> x_i^2 - 10 \cos(2\pi x_i) \right</span><span class="co">]</span> \tag{3}</span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>**Figura 2.**</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>*Representación gráfica de la función de Rastrigin.*</span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Rastrigin</span></span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rastrigin(x):</span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de Rastrigin.</span></span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a><span class="co">    x: vector de entrada (numpy array)</span></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">10</span> <span class="op">*</span> d <span class="op">+</span> <span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">10</span> <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x))</span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>plot_function(rastrigin, x1_range<span class="op">=</span>(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>), title<span class="op">=</span><span class="st">"Función Rastrigin"</span>, x1_point<span class="op">=</span><span class="dv">0</span>, x2_point<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>Elaboración propia.</span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>Segun @simonfraser_rosenbrock, la función de Rastrigin tiene varios mínimos locales. Es altamente multimodal, pero las ubicaciones de los mínimos se distribuyen regularmente. La función generalmente se evalúa en el hipercubo $x_i \in <span class="co">[</span><span class="ot">-5.12, 5.12</span><span class="co">]</span>$ y su mínimo local se encuentra en $f(0,...,0)=0$.</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a><span class="fu">## Función de Schwefel</span></span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}</span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>**Figura 3.**</span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>*Representación gráfica de la función de Schwefel.*</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Schwefel</span></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> schwefel(x):</span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de Schwefel.</span></span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a><span class="co">    x: vector de entrada (numpy array)</span></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="fl">418.9829</span> <span class="op">*</span> d <span class="op">-</span> <span class="bu">sum</span>(x <span class="op">*</span> np.sin(np.sqrt(np.<span class="bu">abs</span>(x))))</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a>plot_function(schwefel, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">500</span>, <span class="dv">500</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">500</span>, <span class="dv">500</span>), title<span class="op">=</span><span class="st">"Función Schwefel"</span>, x1_point<span class="op">=</span><span class="fl">420.9687</span>, x2_point<span class="op">=</span><span class="fl">420.9687</span>)</span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a>Elaboración propia.</span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a>Segun @simonfraser_rosenbrock La función de Schwefel es compleja, con muchos mínimos locales. Normalmente se evalpúa en el hipercubo $x_i \in <span class="co">[</span><span class="ot">-500,500</span><span class="co">]</span>$. Su minimo global está en $f(420.9687,...,420.9687)=0$</span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a><span class="fu">## Función de Griewank</span></span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}</span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a>**Figura 4.**</span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a>*Representación gráfica de la función de Griewank.*</span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de Griewank</span></span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> griewank(x):</span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función Griewank.</span></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a><span class="co">    x: numpy array unidimensional (1D) o un array con forma (d, n1, n2) para evaluaciones vectorizadas.</span></span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a><span class="co">    Retorna:</span></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a><span class="co">    - Un valor escalar si `x` es 1D.</span></span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a><span class="co">    - Una matriz (n1, n2) si `x` tiene forma (d, n1, n2).</span></span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.asarray(x)</span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x.ndim <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Caso 1D: calcular para un solo vector</span></span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a>        sum_term <span class="op">=</span> np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">4000</span></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a>        product_term <span class="op">=</span> np.prod(np.cos(x <span class="op">/</span> np.sqrt(np.arange(<span class="dv">1</span>, d <span class="op">+</span> <span class="dv">1</span>))))</span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span> <span class="op">+</span> sum_term <span class="op">-</span> product_term</span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> x.ndim <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Caso ND: calcular para una cuadrícula (vectorizado)</span></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a>        i_indices <span class="op">=</span> np.arange(<span class="dv">1</span>, d <span class="op">+</span> <span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>        sum_term <span class="op">=</span> np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="dv">4000</span></span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a>        product_term <span class="op">=</span> np.prod(np.cos(x <span class="op">/</span> np.sqrt(i_indices)), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span> <span class="op">+</span> sum_term <span class="op">-</span> product_term</span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"La entrada debe ser un array 1D o un array con forma (d, n1, n2)."</span>)</span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a>plot_function(griewank, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>), title<span class="op">=</span><span class="st">"Función Griewank"</span>, x1_point<span class="op">=</span><span class="dv">0</span>, x2_point<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a>Elaboración propia.</span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a>Segun @simonfraser_rosenbrock la función de Griewank tiene muchos mínimos locales generalizados, que se distribuyen de forma regular. Lo que hace compleja su optimización al minimo global. Normalmente se evalua en el hipercubo $x_i \in <span class="co">[</span><span class="ot">-600,600</span><span class="co">]</span>$. Su minimo global está en $f(0,...,0)=0$</span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a><span class="fu">## Función Goldstein-Price</span></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = &amp; \left<span class="co">[</span><span class="ot">1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a>         &amp; \left<span class="co">[</span><span class="ot">30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right</span><span class="co">]</span></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a>\end{align} \tag{6}</span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a>**Figura 5.**</span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a>*Representación gráfica de la función de Goldstein-Price.*</span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a><span class="co"># Función Goldstein-Price</span></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> goldstein_price(x):</span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función Goldstein-Price.</span></span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a><span class="co">    x1, x2: coordenadas en 2D</span></span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a>    x1<span class="op">=</span>x[<span class="dv">0</span>]</span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a>    x2<span class="op">=</span>x[<span class="dv">1</span>]</span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a>    term1 <span class="op">=</span> (<span class="dv">1</span> <span class="op">+</span> (x1 <span class="op">+</span> x2 <span class="op">+</span> <span class="dv">1</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">19</span> <span class="op">-</span> <span class="dv">14</span> <span class="op">*</span> x1 <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">14</span> <span class="op">*</span> x2 <span class="op">+</span> <span class="dv">6</span> <span class="op">*</span> x1 <span class="op">*</span> x2 <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a>    term2 <span class="op">=</span> (<span class="dv">30</span> <span class="op">+</span> (<span class="dv">2</span> <span class="op">*</span> x1 <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> x2)<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">18</span> <span class="op">-</span> <span class="dv">32</span> <span class="op">*</span> x1 <span class="op">+</span> <span class="dv">12</span> <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">48</span> <span class="op">*</span> x2 <span class="op">-</span> <span class="dv">36</span> <span class="op">*</span> x1 <span class="op">*</span> x2 <span class="op">+</span> <span class="dv">27</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> term1 <span class="op">*</span> term2</span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a>plot_function(goldstein_price, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), title<span class="op">=</span><span class="st">"Función Goldstein price"</span>, x1_point<span class="op">=</span><span class="dv">0</span>, x2_point<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a>Elaboración propia.</span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a>La función Goldstein-Price es una función en 2 dimensiones y tiene varios mínimos locales. Segun @molga2005test, la función generalmente se evalúa en el cuadrado $x_1 \in <span class="co">[</span><span class="ot">-2, 2</span><span class="co">]</span>$ y $x_1 \in <span class="co">[</span><span class="ot">-2, 2</span><span class="co">]</span>$ . Su mínimo global es $f(0,-1) = 3$</span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a><span class="fu">## Función de las seis jorobas de camello</span></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}</span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a>**Figura 6.**</span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a>*Representación gráfica de la función de las seis jorobas del camello.*</span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de las seis jorobas de camello</span></span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> camel_six_humps(x):</span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el valor de la función de las seis jorobas de camello.</span></span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a><span class="co">    x1, x2: coordenadas en 2D</span></span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a>    x1 <span class="op">=</span> x[<span class="dv">0</span>]</span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a>    x2 <span class="op">=</span> x[<span class="dv">1</span>]</span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a>    term1 <span class="op">=</span> (<span class="dv">4</span> <span class="op">-</span> <span class="fl">2.1</span> <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> x1<span class="op">**</span><span class="dv">4</span> <span class="op">/</span> <span class="dv">3</span>) <span class="op">*</span> x1<span class="op">**</span><span class="dv">2</span></span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a>    term2 <span class="op">=</span> x1 <span class="op">*</span> x2</span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a>    term3 <span class="op">=</span> (<span class="op">-</span><span class="dv">4</span> <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> x2<span class="op">**</span><span class="dv">2</span></span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> term1 <span class="op">+</span> term2 <span class="op">+</span> term3</span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a>plot_function(camel_six_humps, x1_range<span class="op">=</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>), x2_range<span class="op">=</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), title<span class="op">=</span><span class="st">"Función 6 jorobas de camello"</span>, x1_point<span class="op">=</span><span class="fl">0.0898</span>, x2_point<span class="op">=-</span><span class="fl">0.7126</span>, elev<span class="op">=</span><span class="dv">30</span>, azim<span class="op">=</span><span class="dv">75</span> )</span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a>Elaboración propia.</span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a>La función de las seis jorobas de camello es una función en 2 dimensiones.Segun @molga2005test la función tiene seis mínimos locales, dos de los cuales son globales y recomienda evaluar la función en el rectángulo $x_1 \in <span class="co">[</span><span class="ot">-3, 3</span><span class="co">]</span>, x_2 \in <span class="co">[</span><span class="ot">-2, 2</span><span class="co">]</span>$, donde los mínimos globales son $f(0.0898,-0.7126) = -1.0316$ y $f(-0.0898, 0.7126) = -1.0316$</span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a><span class="fu"># Proceso de optimización</span></span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimización por descenso del gradiente</span></span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a>El descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.</span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a>De acuerdo con @bishop2006pattern, para una función $f(x)$, el algoritmo actualiza iterativamente el punto $x$ usando la regla que se observa en la Ecuación 8.</span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a>x_{t+1} = x_t - \eta \nabla f(x_t) \tag{8}</span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a>donde:</span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x_t$ es el punto actual</span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\eta$ es la tasa de aprendizaje</span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\nabla f(x_t)$ es el gradiente de la función en $x_t$</span>
<span id="cb23-320"><a href="#cb23-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-321"><a href="#cb23-321" aria-hidden="true" tabindex="-1"></a>El gradiente $\nabla f$ es un vector que contiene las derivadas parciales respecto a cada variable, tal como se ilustra en la Ecuación 9: </span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a>\nabla f(x_1, x_2) = \begin{bmatrix} \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2} \end{bmatrix} \tag{9}</span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a>El gradiente $\nabla f$ se puede aproximar numéricamente usando diferencias finitas. @bishop2006pattern plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función $f(x_1, x_2)$, las derivadas parciales se calculan como se muestra en las Ecuaciones 10 y 11.</span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a>\frac{\partial f}{\partial x_1} \approx \frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \tag{10}</span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a>\frac{\partial f}{\partial x_2} \approx \frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \tag{11}</span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a>donde $h$ es un pequeño incremento (típicamente $10^{-7}$ o $10^{-8}$).</span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> partial_derivative(x0, func, i, h, <span class="op">*</span>args):</span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a>  e <span class="op">=</span> np.zeros(<span class="bu">len</span>(x0))</span>
<span id="cb23-344"><a href="#cb23-344" aria-hidden="true" tabindex="-1"></a>  e[i] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb23-345"><a href="#cb23-345" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (func(x0<span class="op">+</span>h<span class="op">*</span>e, <span class="op">*</span>args) <span class="op">-</span> func(x0<span class="op">-</span>h<span class="op">*</span>e, <span class="op">*</span>args))<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>h)</span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> numerical_gradient(x0, func, h, <span class="op">*</span>args):</span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a>  gradient <span class="op">=</span> np.zeros(<span class="bu">len</span>(x0))</span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x0)):</span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a>    gradient[i] <span class="op">=</span> partial_derivative(x0, func, i, h, <span class="op">*</span>args)</span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> gradient</span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, <span class="op">*</span>args):</span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a><span class="co">  Perform gradient descent with numerical derivatives for a multi-dimensional function.</span></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a><span class="co">  Parameters:</span></span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a><span class="co">      x0 (array-like): Initial guess for the variables.</span></span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a><span class="co">      eta (float): Learning rate.</span></span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a><span class="co">      func (callable): Function to minimize.</span></span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a><span class="co">      h (float): Step size for numerical gradient calculation.</span></span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a><span class="co">      max_iter (int): Maximum number of iterations.</span></span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a><span class="co">      *args: Additional arguments for the function.</span></span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a><span class="co">  Returns:</span></span>
<span id="cb23-366"><a href="#cb23-366" aria-hidden="true" tabindex="-1"></a><span class="co">      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']</span></span>
<span id="cb23-367"><a href="#cb23-367" aria-hidden="true" tabindex="-1"></a><span class="co">                                containing the trajectory of points.</span></span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a>  x_old <span class="op">=</span> np.array(x0)</span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a>  x_hist <span class="op">=</span> []  <span class="co"># List to store the history of x and f(x)</span></span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Calculate the gradient numerically</span></span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a>      gradient <span class="op">=</span> numerical_gradient(x_old, func, h, <span class="op">*</span>args)</span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Update x based on gradient descent rule</span></span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a>      x_new <span class="op">=</span> x_old <span class="op">-</span> eta <span class="op">*</span> gradient</span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Append current x and function value to history</span></span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a>      x_hist.append([x_old[<span class="dv">0</span>], x_old[<span class="dv">1</span>], func(x_old, <span class="op">*</span>args)])</span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Update x_old</span></span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a>      x_old <span class="op">=</span> x_new</span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add the final position and function value</span></span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a>  x_hist.append([x_new[<span class="dv">0</span>], x_new[<span class="dv">1</span>], func(x_new, <span class="op">*</span>args)])</span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert history to a pandas DataFrame</span></span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a>  result_df <span class="op">=</span> pd.DataFrame(x_hist, columns<span class="op">=</span>[<span class="st">'x1'</span>, <span class="st">'x2'</span>, <span class="st">'f(x1,x2)'</span>])</span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> result_df</span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a>A continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.</span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rosenbrock</span></span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = \sum_{i=1}^{d-1} \left<span class="co">[</span><span class="ot"> 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right</span><span class="co">]</span> \tag{1}</span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a>| $x_{1_0}$ | $x_{2_0}$ | $\eta$ | $n$ |</span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a>|-----------|-----------|--------|-----|</span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a>| -1.5      | -1.7      | 0.001  | 30  |</span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a>**Figura 7.**</span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a>*Aplicación del descenso del gradiente en la función de Rosenbrok.* <span class="al">![Aplicación del descenso del gradiente en la función de Rosenbrok](images/rosenbrock.gif)</span> Elaboración propia.</span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rastrigin</span></span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-413"><a href="#cb23-413" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-414"><a href="#cb23-414" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left<span class="co">[</span><span class="ot"> x_i^2 - 10 \cos(2\pi x_i) \right</span><span class="co">]</span> \tag{3}</span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a>| $x_{1_0}$ | $x_{2_0}$ | $\eta$ | $n$ |</span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a>|-----------|-----------|--------|-----|</span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a>| -0.46     | 0.46      | 0.005  | 30  |</span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a>**Figura 8.**</span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a>*Aplicación del descenso del gradiente en la función de Rastrigin.* <span class="al">![Aplicación del descenso del gradiente en la función de Rastrigin](images/rastrigin.gif)</span> Elaboración propia.</span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Schwefel</span></span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-428"><a href="#cb23-428" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}</span>
<span id="cb23-429"><a href="#cb23-429" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a>| $x_{1_0}$ | $x_{2_0}$ | $\eta$ | $n$ |</span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a>|-----------|-----------|--------|-----|</span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a>| 310       | 310       | 0.8    | 30  |</span>
<span id="cb23-434"><a href="#cb23-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-435"><a href="#cb23-435" aria-hidden="true" tabindex="-1"></a>**Figura 9.**</span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-437"><a href="#cb23-437" aria-hidden="true" tabindex="-1"></a>*Aplicación del descenso del gradiente en la función de Schwefel.* <span class="al">![Aplicación del descenso del gradiente en la función de Schwefel](images/schwefel.gif)</span> Elaboración propia.</span>
<span id="cb23-438"><a href="#cb23-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Griewank</span></span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}</span>
<span id="cb23-443"><a href="#cb23-443" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-444"><a href="#cb23-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a>| $x_{1_0}$ | $x_{2_0}$ | $\eta$ | $n$ |</span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a>|-----------|-----------|--------|-----|</span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a>| -500      | 500       | 70     | 33  |</span>
<span id="cb23-448"><a href="#cb23-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-449"><a href="#cb23-449" aria-hidden="true" tabindex="-1"></a>**Figura 10.**</span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a>*Aplicación del descenso del gradiente en la función de Griewank.* <span class="al">![Aplicación del descenso del gradiente en la función de Griewank](images/griewank.gif)</span> Elaboración propia.</span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función Goldstein-Price</span></span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb23-457"><a href="#cb23-457" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = &amp; \left<span class="co">[</span><span class="ot">1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb23-458"><a href="#cb23-458" aria-hidden="true" tabindex="-1"></a>         &amp; \left<span class="co">[</span><span class="ot">30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right</span><span class="co">]</span></span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a>\end{align} \tag{6}</span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a>| $x_{1_0}$ | $x_{2_0}$ | $\eta$  | $n$ |</span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a>|-----------|-----------|---------|-----|</span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a>| 0.5       | -1.5      | 0.00005 | 50  |</span>
<span id="cb23-465"><a href="#cb23-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-466"><a href="#cb23-466" aria-hidden="true" tabindex="-1"></a>**Figura 11.**</span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a>*Aplicación del descenso del gradiente en la función de Goldstein-Price.* <span class="al">![Aplicación del descenso del gradiente en la función de Goldstein-Price](images/goldstein_price.gif)</span> Elaboración propia.</span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de las seis jorobas de camello</span></span>
<span id="cb23-471"><a href="#cb23-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-472"><a href="#cb23-472" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}</span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a>| $x_{1_0}$ | $x_{2_0}$ | $\eta$ | $n$ |</span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a>|-----------|-----------|--------|-----|</span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a>| -1        | -1        | 0.015  | 33  |</span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-480"><a href="#cb23-480" aria-hidden="true" tabindex="-1"></a>**Figura 12.**</span>
<span id="cb23-481"><a href="#cb23-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a>*Aplicación del descenso del gradiente en la función de las seis jorobas del camello.* <span class="al">![Aplicación del descenso del gradiente en la función de las seis jorobas del camello](images/camel_six_humps.gif)</span> Elaboración propia.</span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a>El método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.</span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a>Para garantizar que este método sea eficiente, es importante considerar lo siguiente:</span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-489"><a href="#cb23-489" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Tasa de aprendizaje**: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.</span>
<span id="cb23-490"><a href="#cb23-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Punto inicial**: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.</span>
<span id="cb23-492"><a href="#cb23-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-493"><a href="#cb23-493" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Criterio de parada**: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia).</span>
<span id="cb23-494"><a href="#cb23-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-495"><a href="#cb23-495" aria-hidden="true" tabindex="-1"></a><span class="fu">## Agoritmo genético</span></span>
<span id="cb23-496"><a href="#cb23-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-497"><a href="#cb23-497" aria-hidden="true" tabindex="-1"></a>Un algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la **selección natural** y la **evolución biológica**, propuesto inicialmente por @holland1975adaptation. Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.</span>
<span id="cb23-498"><a href="#cb23-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-499"><a href="#cb23-499" aria-hidden="true" tabindex="-1"></a><span class="fu">### Concepto General</span></span>
<span id="cb23-500"><a href="#cb23-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-501"><a href="#cb23-501" aria-hidden="true" tabindex="-1"></a>El algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:</span>
<span id="cb23-502"><a href="#cb23-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-503"><a href="#cb23-503" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Selección**: Elegir individuos con mayor *fitness*.<span class="ot">[^1]</span></span>
<span id="cb23-504"><a href="#cb23-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-505"><a href="#cb23-505" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Cruce**: Combinar soluciones para generar descendencia.</span>
<span id="cb23-506"><a href="#cb23-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-507"><a href="#cb23-507" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Mutación**: Introducir variación genética.</span>
<span id="cb23-508"><a href="#cb23-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-509"><a href="#cb23-509" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>El *fitness* representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.</span>
<span id="cb23-510"><a href="#cb23-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-511"><a href="#cb23-511" aria-hidden="true" tabindex="-1"></a>Matemáticamente, en un problema de minimización, el objetivo es encontrar:</span>
<span id="cb23-512"><a href="#cb23-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-513"><a href="#cb23-513" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-514"><a href="#cb23-514" aria-hidden="true" tabindex="-1"></a>x^* = \arg\min_{x \in \mathbb{R}^n} f(x) \tag{12}</span>
<span id="cb23-515"><a href="#cb23-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-516"><a href="#cb23-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-517"><a href="#cb23-517" aria-hidden="true" tabindex="-1"></a>donde:</span>
<span id="cb23-518"><a href="#cb23-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-519"><a href="#cb23-519" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x$ representa un individuo en el espacio de búsqueda.</span>
<span id="cb23-520"><a href="#cb23-520" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$f(x)$ es la función objetivo que evalúa la calidad de $x$.</span>
<span id="cb23-521"><a href="#cb23-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-522"><a href="#cb23-522" aria-hidden="true" tabindex="-1"></a>Cada solución candidata se representa como un **individuo**, que puede ser un vector real o un cromosoma binario, tal como se ilustra en la Ecuación 13:</span>
<span id="cb23-523"><a href="#cb23-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-524"><a href="#cb23-524" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-525"><a href="#cb23-525" aria-hidden="true" tabindex="-1"></a>x = (x_1, x_2, \ldots, x_n) \in \mathbb{R}^n \tag{13}</span>
<span id="cb23-526"><a href="#cb23-526" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-527"><a href="#cb23-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-528"><a href="#cb23-528" aria-hidden="true" tabindex="-1"></a>La función objetivo, mostrada en la Ecuación 14, mide qué tan buena es una solución.</span>
<span id="cb23-529"><a href="#cb23-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-530"><a href="#cb23-530" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-531"><a href="#cb23-531" aria-hidden="true" tabindex="-1"></a>\text{Fitness}(x) = f(x) \tag{14}</span>
<span id="cb23-532"><a href="#cb23-532" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-533"><a href="#cb23-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-534"><a href="#cb23-534" aria-hidden="true" tabindex="-1"></a>Para problemas de **minimización**, menor $f(x)$ implica mejor fitness.</span>
<span id="cb23-535"><a href="#cb23-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-536"><a href="#cb23-536" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-537"><a href="#cb23-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-538"><a href="#cb23-538" aria-hidden="true" tabindex="-1"></a><span class="fu">### Etapas</span></span>
<span id="cb23-539"><a href="#cb23-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-540"><a href="#cb23-540" aria-hidden="true" tabindex="-1"></a>**Inicialización de la Población**</span>
<span id="cb23-541"><a href="#cb23-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-542"><a href="#cb23-542" aria-hidden="true" tabindex="-1"></a>Se genera una población inicial de $P$ individuos de forma aleatoria dentro de un intervalo $<span class="co">[</span><span class="ot">a, b</span><span class="co">]</span>$:</span>
<span id="cb23-543"><a href="#cb23-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-544"><a href="#cb23-544" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-545"><a href="#cb23-545" aria-hidden="true" tabindex="-1"></a>x_{ij} \sim \text{U}(a, b), \quad \forall i \in <span class="sc">\{</span>1, 2, \ldots, P<span class="sc">\}</span>, \; j \in <span class="sc">\{</span>1, 2, \ldots, n<span class="sc">\}</span> \tag{15}</span>
<span id="cb23-546"><a href="#cb23-546" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-547"><a href="#cb23-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-548"><a href="#cb23-548" aria-hidden="true" tabindex="-1"></a>donde:</span>
<span id="cb23-549"><a href="#cb23-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-550"><a href="#cb23-550" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x_{ij}$ es la $j-ésima$ coordenada del $i-ésimo$ individuo.</span>
<span id="cb23-551"><a href="#cb23-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-554"><a href="#cb23-554" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-555"><a href="#cb23-555" aria-hidden="true" tabindex="-1"></a><span class="co"># Inicializar población</span></span>
<span id="cb23-556"><a href="#cb23-556" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_population(size, dim, bounds):</span>
<span id="cb23-557"><a href="#cb23-557" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.uniform(bounds[<span class="dv">0</span>], bounds[<span class="dv">1</span>], (size, dim))</span>
<span id="cb23-558"><a href="#cb23-558" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-559"><a href="#cb23-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-560"><a href="#cb23-560" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-561"><a href="#cb23-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-562"><a href="#cb23-562" aria-hidden="true" tabindex="-1"></a>**Evaluación del Fitness**</span>
<span id="cb23-563"><a href="#cb23-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-564"><a href="#cb23-564" aria-hidden="true" tabindex="-1"></a>Cada individuo de la población es evaluado usando la función objetivo mostrada a continuación, en la Ecuación 16.</span>
<span id="cb23-565"><a href="#cb23-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-566"><a href="#cb23-566" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-567"><a href="#cb23-567" aria-hidden="true" tabindex="-1"></a>\text{Fitness}_i = f(x_i) \tag{16}</span>
<span id="cb23-568"><a href="#cb23-568" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-569"><a href="#cb23-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-572"><a href="#cb23-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-573"><a href="#cb23-573" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar fitness</span></span>
<span id="cb23-574"><a href="#cb23-574" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_fitness(population,fitness_function):</span>
<span id="cb23-575"><a href="#cb23-575" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([fitness_function(ind) <span class="cf">for</span> ind <span class="kw">in</span> population])</span>
<span id="cb23-576"><a href="#cb23-576" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-577"><a href="#cb23-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-578"><a href="#cb23-578" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-579"><a href="#cb23-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-580"><a href="#cb23-580" aria-hidden="true" tabindex="-1"></a>**Selección**</span>
<span id="cb23-581"><a href="#cb23-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-582"><a href="#cb23-582" aria-hidden="true" tabindex="-1"></a>Se seleccionan individuos para reproducirse basándose en su fitness. Un métodos común es el método de torneo, observado en la Ecuación 17, donde primero se seleccionan $k$ individuos al azar y luego se elige al mejor de ellos (quien tenga el mejor fitness):</span>
<span id="cb23-583"><a href="#cb23-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-584"><a href="#cb23-584" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-585"><a href="#cb23-585" aria-hidden="true" tabindex="-1"></a>\text{Individuo seleccionado} = \arg\min_{j \in S} \text{Fitness}_j, \; S \subseteq <span class="sc">\{</span>1, \ldots, P<span class="sc">\}</span>, \; |S| = k \tag{17}</span>
<span id="cb23-586"><a href="#cb23-586" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-587"><a href="#cb23-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-590"><a href="#cb23-590" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-591"><a href="#cb23-591" aria-hidden="true" tabindex="-1"></a><span class="co"># Selección por torneo</span></span>
<span id="cb23-592"><a href="#cb23-592" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tournament_selection(population, fitness, k<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb23-593"><a href="#cb23-593" aria-hidden="true" tabindex="-1"></a>    selected <span class="op">=</span> []</span>
<span id="cb23-594"><a href="#cb23-594" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(population)):</span>
<span id="cb23-595"><a href="#cb23-595" aria-hidden="true" tabindex="-1"></a>        candidates <span class="op">=</span> np.random.choice(<span class="bu">range</span>(<span class="bu">len</span>(population)), k, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-596"><a href="#cb23-596" aria-hidden="true" tabindex="-1"></a>        winner <span class="op">=</span> candidates[np.argmin(fitness[candidates])]</span>
<span id="cb23-597"><a href="#cb23-597" aria-hidden="true" tabindex="-1"></a>        selected.append(population[winner])</span>
<span id="cb23-598"><a href="#cb23-598" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(selected)</span>
<span id="cb23-599"><a href="#cb23-599" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-600"><a href="#cb23-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-601"><a href="#cb23-601" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-602"><a href="#cb23-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-603"><a href="#cb23-603" aria-hidden="true" tabindex="-1"></a>**Cruce (Recombinación)**</span>
<span id="cb23-604"><a href="#cb23-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-605"><a href="#cb23-605" aria-hidden="true" tabindex="-1"></a>Dos individuos (padres) se combinan para generar descendencia. Un método común es **punto de corte único**, donde primero se elige un punto de cruce aleatorio $k$ y después se genera la descendencia mezclando las características de los padres, como se observa en las Ecuaciones 18 y 19.</span>
<span id="cb23-606"><a href="#cb23-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-607"><a href="#cb23-607" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-608"><a href="#cb23-608" aria-hidden="true" tabindex="-1"></a>\text{Hijo 1} = (\text{Padre}_1<span class="co">[</span><span class="ot">:k</span><span class="co">]</span>, \text{Padre}_2<span class="co">[</span><span class="ot">k:</span><span class="co">]</span>) \tag{18}</span>
<span id="cb23-609"><a href="#cb23-609" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-610"><a href="#cb23-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-611"><a href="#cb23-611" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-612"><a href="#cb23-612" aria-hidden="true" tabindex="-1"></a>\text{Hijo 2} = (\text{Padre}_2<span class="co">[</span><span class="ot">:k</span><span class="co">]</span>, \text{Padre}_1<span class="co">[</span><span class="ot">k:</span><span class="co">]</span>) \tag{19}</span>
<span id="cb23-613"><a href="#cb23-613" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-614"><a href="#cb23-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-615"><a href="#cb23-615" aria-hidden="true" tabindex="-1"></a>La probabilidad de realizar un cruce está determinada por $p_c$ (tasa de cruce).</span>
<span id="cb23-616"><a href="#cb23-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-619"><a href="#cb23-619" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-620"><a href="#cb23-620" aria-hidden="true" tabindex="-1"></a><span class="co"># Cruce</span></span>
<span id="cb23-621"><a href="#cb23-621" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crossover(parent1, parent2, crossover_rate):</span>
<span id="cb23-622"><a href="#cb23-622" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> crossover_rate:</span>
<span id="cb23-623"><a href="#cb23-623" aria-hidden="true" tabindex="-1"></a>        point <span class="op">=</span> np.random.randint(<span class="dv">1</span>, <span class="bu">len</span>(parent1))</span>
<span id="cb23-624"><a href="#cb23-624" aria-hidden="true" tabindex="-1"></a>        child <span class="op">=</span> np.concatenate([parent1[:point], parent2[point:]])</span>
<span id="cb23-625"><a href="#cb23-625" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> child</span>
<span id="cb23-626"><a href="#cb23-626" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> parent1 <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> <span class="fl">0.5</span> <span class="cf">else</span> parent2</span>
<span id="cb23-627"><a href="#cb23-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-628"><a href="#cb23-628" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-629"><a href="#cb23-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-630"><a href="#cb23-630" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-631"><a href="#cb23-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-632"><a href="#cb23-632" aria-hidden="true" tabindex="-1"></a>**Mutación**</span>
<span id="cb23-633"><a href="#cb23-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-634"><a href="#cb23-634" aria-hidden="true" tabindex="-1"></a>Se introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad $p_m$:</span>
<span id="cb23-635"><a href="#cb23-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-636"><a href="#cb23-636" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-637"><a href="#cb23-637" aria-hidden="true" tabindex="-1"></a>x_{ij} = x_{ij} + \Delta, \quad \Delta \sim \text{U}(-\delta, \delta) \tag{20}</span>
<span id="cb23-638"><a href="#cb23-638" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-639"><a href="#cb23-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-640"><a href="#cb23-640" aria-hidden="true" tabindex="-1"></a>donde:</span>
<span id="cb23-641"><a href="#cb23-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-642"><a href="#cb23-642" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\Delta$ es una perturbación aleatoria.</span>
<span id="cb23-643"><a href="#cb23-643" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$x_{ij}$ se restringe a los límites del problema.</span>
<span id="cb23-644"><a href="#cb23-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-647"><a href="#cb23-647" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-648"><a href="#cb23-648" aria-hidden="true" tabindex="-1"></a><span class="co"># Mutación</span></span>
<span id="cb23-649"><a href="#cb23-649" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutate(individual, bounds, mutation_rate, delta):</span>
<span id="cb23-650"><a href="#cb23-650" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(individual)):</span>
<span id="cb23-651"><a href="#cb23-651" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> mutation_rate:</span>
<span id="cb23-652"><a href="#cb23-652" aria-hidden="true" tabindex="-1"></a>            individual[i] <span class="op">+=</span> np.random.uniform(<span class="op">-</span>delta, delta)</span>
<span id="cb23-653"><a href="#cb23-653" aria-hidden="true" tabindex="-1"></a>            individual[i] <span class="op">=</span> np.clip(individual[i], bounds[<span class="dv">0</span>], bounds[<span class="dv">1</span>])</span>
<span id="cb23-654"><a href="#cb23-654" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> individual</span>
<span id="cb23-655"><a href="#cb23-655" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-656"><a href="#cb23-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-657"><a href="#cb23-657" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-658"><a href="#cb23-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-659"><a href="#cb23-659" aria-hidden="true" tabindex="-1"></a>**Evaluación y Sustitución**</span>
<span id="cb23-660"><a href="#cb23-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-661"><a href="#cb23-661" aria-hidden="true" tabindex="-1"></a>La nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.</span>
<span id="cb23-662"><a href="#cb23-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-665"><a href="#cb23-665" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-666"><a href="#cb23-666" aria-hidden="true" tabindex="-1"></a><span class="co"># Algoritmo completo</span></span>
<span id="cb23-667"><a href="#cb23-667" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):</span>
<span id="cb23-668"><a href="#cb23-668" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> initialize_population(population_size, dim, bounds)</span>
<span id="cb23-669"><a href="#cb23-669" aria-hidden="true" tabindex="-1"></a>    best_individual <span class="op">=</span> <span class="va">None</span></span>
<span id="cb23-670"><a href="#cb23-670" aria-hidden="true" tabindex="-1"></a>    trajectory <span class="op">=</span> []</span>
<span id="cb23-671"><a href="#cb23-671" aria-hidden="true" tabindex="-1"></a>    populations <span class="op">=</span> []</span>
<span id="cb23-672"><a href="#cb23-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-673"><a href="#cb23-673" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> generation <span class="kw">in</span> <span class="bu">range</span>(generations):</span>
<span id="cb23-674"><a href="#cb23-674" aria-hidden="true" tabindex="-1"></a>        populations.append(population.copy())</span>
<span id="cb23-675"><a href="#cb23-675" aria-hidden="true" tabindex="-1"></a>        fitness <span class="op">=</span> evaluate_fitness(population, fitness_function)</span>
<span id="cb23-676"><a href="#cb23-676" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-677"><a href="#cb23-677" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> best_individual <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> np.<span class="bu">min</span>(fitness) <span class="op">&lt;</span> fitness_function(best_individual):</span>
<span id="cb23-678"><a href="#cb23-678" aria-hidden="true" tabindex="-1"></a>            best_individual <span class="op">=</span> population[np.argmin(fitness)]</span>
<span id="cb23-679"><a href="#cb23-679" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-680"><a href="#cb23-680" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Guardar la mejor solución de esta generación</span></span>
<span id="cb23-681"><a href="#cb23-681" aria-hidden="true" tabindex="-1"></a>        trajectory.append((<span class="op">*</span>best_individual, fitness_function(best_individual)))</span>
<span id="cb23-682"><a href="#cb23-682" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-683"><a href="#cb23-683" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Selección</span></span>
<span id="cb23-684"><a href="#cb23-684" aria-hidden="true" tabindex="-1"></a>        selected_population <span class="op">=</span> tournament_selection(population, fitness)</span>
<span id="cb23-685"><a href="#cb23-685" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-686"><a href="#cb23-686" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cruce y mutación</span></span>
<span id="cb23-687"><a href="#cb23-687" aria-hidden="true" tabindex="-1"></a>        new_population <span class="op">=</span> []</span>
<span id="cb23-688"><a href="#cb23-688" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(selected_population), <span class="dv">2</span>):</span>
<span id="cb23-689"><a href="#cb23-689" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> <span class="bu">len</span>(selected_population):</span>
<span id="cb23-690"><a href="#cb23-690" aria-hidden="true" tabindex="-1"></a>                child1 <span class="op">=</span> crossover(selected_population[i], selected_population[i<span class="op">+</span><span class="dv">1</span>], crossover_rate)</span>
<span id="cb23-691"><a href="#cb23-691" aria-hidden="true" tabindex="-1"></a>                child2 <span class="op">=</span> crossover(selected_population[i<span class="op">+</span><span class="dv">1</span>], selected_population[i], crossover_rate)</span>
<span id="cb23-692"><a href="#cb23-692" aria-hidden="true" tabindex="-1"></a>                new_population.extend([child1, child2])</span>
<span id="cb23-693"><a href="#cb23-693" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb23-694"><a href="#cb23-694" aria-hidden="true" tabindex="-1"></a>                new_population.append(selected_population[i])</span>
<span id="cb23-695"><a href="#cb23-695" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-696"><a href="#cb23-696" aria-hidden="true" tabindex="-1"></a>        population <span class="op">=</span> np.array([mutate(ind, bounds, mutation_rate, delta) <span class="cf">for</span> ind <span class="kw">in</span> new_population])</span>
<span id="cb23-697"><a href="#cb23-697" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-698"><a href="#cb23-698" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convertir la trayectoria a DataFrame</span></span>
<span id="cb23-699"><a href="#cb23-699" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-700"><a href="#cb23-700" aria-hidden="true" tabindex="-1"></a>    columns <span class="op">=</span> [<span class="ss">f'x</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(dim)] <span class="op">+</span> [<span class="st">'f(x)'</span>]</span>
<span id="cb23-701"><a href="#cb23-701" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(trajectory, columns<span class="op">=</span>columns)</span>
<span id="cb23-702"><a href="#cb23-702" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_individual, fitness_function(best_individual), df, populations</span>
<span id="cb23-703"><a href="#cb23-703" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-704"><a href="#cb23-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-705"><a href="#cb23-705" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb23-706"><a href="#cb23-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-707"><a href="#cb23-707" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb23-708"><a href="#cb23-708" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rosenbrock</span></span>
<span id="cb23-709"><a href="#cb23-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-710"><a href="#cb23-710" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-711"><a href="#cb23-711" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = \sum_{i=1}^{d-1} \left<span class="co">[</span><span class="ot"> 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right</span><span class="co">]</span> \tag{1}</span>
<span id="cb23-712"><a href="#cb23-712" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-713"><a href="#cb23-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-714"><a href="#cb23-714" aria-hidden="true" tabindex="-1"></a>**Figura 13.**</span>
<span id="cb23-715"><a href="#cb23-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-716"><a href="#cb23-716" aria-hidden="true" tabindex="-1"></a>*Aplicación del algoritmo genético sobre la función de Rosenbrok.* <span class="al">![Aplicación del algoritmo genético sobre la función de Rosenbrok](images/Rosenbrock_population_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-717"><a href="#cb23-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-718"><a href="#cb23-718" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rastrigin</span></span>
<span id="cb23-719"><a href="#cb23-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-720"><a href="#cb23-720" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-721"><a href="#cb23-721" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left<span class="co">[</span><span class="ot"> x_i^2 - 10 \cos(2\pi x_i) \right</span><span class="co">]</span> \tag{3}</span>
<span id="cb23-722"><a href="#cb23-722" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-723"><a href="#cb23-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-724"><a href="#cb23-724" aria-hidden="true" tabindex="-1"></a>**Figura 14.**</span>
<span id="cb23-725"><a href="#cb23-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-726"><a href="#cb23-726" aria-hidden="true" tabindex="-1"></a>*Aplicación del algoritmo genético sobre la función de Rastrigin.* <span class="al">![Aplicación del algoritmo genético sobre la función de Rastrigin](images/Rastrigin_population_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-727"><a href="#cb23-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-728"><a href="#cb23-728" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Schwefel</span></span>
<span id="cb23-729"><a href="#cb23-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-730"><a href="#cb23-730" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-731"><a href="#cb23-731" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}</span>
<span id="cb23-732"><a href="#cb23-732" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-733"><a href="#cb23-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-734"><a href="#cb23-734" aria-hidden="true" tabindex="-1"></a>**Figura 15.**</span>
<span id="cb23-735"><a href="#cb23-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-736"><a href="#cb23-736" aria-hidden="true" tabindex="-1"></a>*Aplicación del algoritmo genético sobre la función de Schwefel.* <span class="al">![Aplicación del algoritmo genético sobre la función de Schwefel](images/Schwefel_population_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-737"><a href="#cb23-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-738"><a href="#cb23-738" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Griewank</span></span>
<span id="cb23-739"><a href="#cb23-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-740"><a href="#cb23-740" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-741"><a href="#cb23-741" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}</span>
<span id="cb23-742"><a href="#cb23-742" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-743"><a href="#cb23-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-744"><a href="#cb23-744" aria-hidden="true" tabindex="-1"></a>**Figura 16.**</span>
<span id="cb23-745"><a href="#cb23-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-746"><a href="#cb23-746" aria-hidden="true" tabindex="-1"></a>*Aplicación del algoritmo genético sobre la función de Griewank.* <span class="al">![Aplicación del algoritmo genético sobre la función de Griewank](images/Griewank_population_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-747"><a href="#cb23-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-748"><a href="#cb23-748" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función Goldstein-Price</span></span>
<span id="cb23-749"><a href="#cb23-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-750"><a href="#cb23-750" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-751"><a href="#cb23-751" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb23-752"><a href="#cb23-752" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = &amp; \left<span class="co">[</span><span class="ot">1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb23-753"><a href="#cb23-753" aria-hidden="true" tabindex="-1"></a>         &amp; \left<span class="co">[</span><span class="ot">30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right</span><span class="co">]</span></span>
<span id="cb23-754"><a href="#cb23-754" aria-hidden="true" tabindex="-1"></a>\end{align} \tag{6}</span>
<span id="cb23-755"><a href="#cb23-755" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-756"><a href="#cb23-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-757"><a href="#cb23-757" aria-hidden="true" tabindex="-1"></a>**Figura 17.**</span>
<span id="cb23-758"><a href="#cb23-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-759"><a href="#cb23-759" aria-hidden="true" tabindex="-1"></a>*Aplicación del algoritmo genético sobre la función de Goldstein-Price.* <span class="al">![Aplicación del algoritmo genético sobre la función de Goldstein-Price](images/Goldstein_Price_population_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-760"><a href="#cb23-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-761"><a href="#cb23-761" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de las seis jorobas de camello</span></span>
<span id="cb23-762"><a href="#cb23-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-763"><a href="#cb23-763" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-764"><a href="#cb23-764" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}</span>
<span id="cb23-765"><a href="#cb23-765" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-766"><a href="#cb23-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-767"><a href="#cb23-767" aria-hidden="true" tabindex="-1"></a>**Figura 18.**</span>
<span id="cb23-768"><a href="#cb23-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-769"><a href="#cb23-769" aria-hidden="true" tabindex="-1"></a>*Aplicación del algoritmo genético sobre la función de las seis jorobas del camello.* <span class="al">![Aplicación del algoritmo genético sobre la función de las seis jorobas del camello](images/Camel_Six_Humps_population_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-770"><a href="#cb23-770" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-771"><a href="#cb23-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-772"><a href="#cb23-772" aria-hidden="true" tabindex="-1"></a>Los algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: **exploración**, que consiste en descubrir nuevas regiones del espacio de búsqueda, y **explotación**, enfocada en refinar y mejorar las soluciones existentes.</span>
<span id="cb23-773"><a href="#cb23-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-774"><a href="#cb23-774" aria-hidden="true" tabindex="-1"></a>Para las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación $\delta$ se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.</span>
<span id="cb23-775"><a href="#cb23-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-776"><a href="#cb23-776" aria-hidden="true" tabindex="-1"></a><span class="fu">### Observaciones</span></span>
<span id="cb23-777"><a href="#cb23-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-778"><a href="#cb23-778" aria-hidden="true" tabindex="-1"></a>Ventajas:</span>
<span id="cb23-779"><a href="#cb23-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-780"><a href="#cb23-780" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>No requiere derivadas ni condiciones específicas en $f(x)$ .</span>
<span id="cb23-781"><a href="#cb23-781" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Es efectivo en espacios de búsqueda multimodales o no convexos.</span>
<span id="cb23-782"><a href="#cb23-782" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Adaptable a diversos problemas.</span>
<span id="cb23-783"><a href="#cb23-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-784"><a href="#cb23-784" aria-hidden="true" tabindex="-1"></a>Desventajas:</span>
<span id="cb23-785"><a href="#cb23-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-786"><a href="#cb23-786" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Puede ser computacionalmente costoso.</span>
<span id="cb23-787"><a href="#cb23-787" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>No garantiza convergencia al óptimo global.</span>
<span id="cb23-788"><a href="#cb23-788" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Requiere ajuste cuidadoso de parámetros.</span>
<span id="cb23-789"><a href="#cb23-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-790"><a href="#cb23-790" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimización de partículas</span></span>
<span id="cb23-791"><a href="#cb23-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-792"><a href="#cb23-792" aria-hidden="true" tabindex="-1"></a><span class="fu">### Concepto Básico y Analogía</span></span>
<span id="cb23-793"><a href="#cb23-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-794"><a href="#cb23-794" aria-hidden="true" tabindex="-1"></a>De acuerdo con @kennedy1995particle, puede decirse que la Optimización por Enjambre de Partículas (PSO) es una técnica metaheurística inspirada en el comportamiento social de los animales, como los pájaros o los peces. En PSO, cada solución potencial al problema se representa como una partícula que se mueve en un espacio de búsqueda multidimensional. Cada partícula ajusta su posición y velocidad en cada iteración, basándose en su propia mejor posición encontrada (pBest) y la mejor posición encontrada por todo el enjambre (gBest).</span>
<span id="cb23-795"><a href="#cb23-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-796"><a href="#cb23-796" aria-hidden="true" tabindex="-1"></a>Los métodos PSO se atribuyen originalmente a los investigadores @kennedy1997particle. En un principio fueron concebidos para elaborar modelos de conductas sociales,​como el movimiento descrito por los organismos vivos en una bandada de aves o un banco de peces. Posteriormente el algoritmo se simplificó y se comprobó que era adecuado para problemas de optimización.</span>
<span id="cb23-797"><a href="#cb23-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-798"><a href="#cb23-798" aria-hidden="true" tabindex="-1"></a>**Funcionamiento de PSOz**</span>
<span id="cb23-799"><a href="#cb23-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-800"><a href="#cb23-800" aria-hidden="true" tabindex="-1"></a>En el algoritmo PSO (Particle Swarm Optimization), cada partícula, que representa un individuo, posee una posición *p*⃗&nbsp; ​ dentro del espacio de búsqueda y una velocidad *v*⃗&nbsp;que determina su desplazamiento. Estas partículas, al igual que objetos en un entorno físico, cuentan con una inercia *w*, la cual conserva su movimiento en la dirección previamente seguida.</span>
<span id="cb23-801"><a href="#cb23-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-804"><a href="#cb23-804" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-805"><a href="#cb23-805" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-806"><a href="#cb23-806" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.positions <span class="op">=</span> np.random.uniform(</span>
<span id="cb23-807"><a href="#cb23-807" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bounds[:, <span class="dv">0</span>],</span>
<span id="cb23-808"><a href="#cb23-808" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.bounds[:, <span class="dv">1</span>],</span>
<span id="cb23-809"><a href="#cb23-809" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span>(n_particles, dimensions)</span>
<span id="cb23-810"><a href="#cb23-810" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-811"><a href="#cb23-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-812"><a href="#cb23-812" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.velocities <span class="op">=</span> np.zeros((n_particles, dimensions))</span>
<span id="cb23-813"><a href="#cb23-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-814"><a href="#cb23-814" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluar posiciones iniciales</span></span>
<span id="cb23-815"><a href="#cb23-815" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.scores <span class="op">=</span> np.array([<span class="va">self</span>.objective_function(p) <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.positions])</span>
<span id="cb23-816"><a href="#cb23-816" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-817"><a href="#cb23-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-818"><a href="#cb23-818" aria-hidden="true" tabindex="-1"></a>Además, su aceleración, que representa un cambio en la velocidad, está influenciada por dos factores principales:</span>
<span id="cb23-819"><a href="#cb23-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-820"><a href="#cb23-820" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Atracción hacia su mejor posición personal: Cada partícula tiende a moverse hacia la mejor ubicación que ha identificado en su trayectoria histórica (*pbest).*</span>
<span id="cb23-821"><a href="#cb23-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-822"><a href="#cb23-822" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Atracción hacia la mejor posición global: Las partículas también se dirigen hacia la mejor ubicación encontrada por el grupo completo en el espacio de búsqueda (*pgbest*).</span>
<span id="cb23-823"><a href="#cb23-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-824"><a href="#cb23-824" aria-hidden="true" tabindex="-1"></a>*Ilustración del funcionamiento del algoritmo PSO.* <span class="al">![Ilustración del funcionamiento del algoritmo PSO](images/paste-1.png)</span></span>
<span id="cb23-825"><a href="#cb23-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-826"><a href="#cb23-826" aria-hidden="true" tabindex="-1"></a>Adaptado de @sancho_pso_image</span>
<span id="cb23-827"><a href="#cb23-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-830"><a href="#cb23-830" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-831"><a href="#cb23-831" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-832"><a href="#cb23-832" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.max_iter):</span>
<span id="cb23-833"><a href="#cb23-833" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar velocidades</span></span>
<span id="cb23-834"><a href="#cb23-834" aria-hidden="true" tabindex="-1"></a>    r1, r2 <span class="op">=</span> np.random.rand(<span class="dv">2</span>)</span>
<span id="cb23-835"><a href="#cb23-835" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.velocities <span class="op">=</span> (<span class="va">self</span>.w <span class="op">*</span> <span class="va">self</span>.velocities <span class="op">+</span></span>
<span id="cb23-836"><a href="#cb23-836" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.c1 <span class="op">*</span> r1 <span class="op">*</span> (<span class="va">self</span>.p_best <span class="op">-</span> <span class="va">self</span>.positions) <span class="op">+</span></span>
<span id="cb23-837"><a href="#cb23-837" aria-hidden="true" tabindex="-1"></a>                     <span class="va">self</span>.c2 <span class="op">*</span> r2 <span class="op">*</span> (<span class="va">self</span>.g_best <span class="op">-</span> <span class="va">self</span>.positions))</span>
<span id="cb23-838"><a href="#cb23-838" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-839"><a href="#cb23-839" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar posiciones</span></span>
<span id="cb23-840"><a href="#cb23-840" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.positions <span class="op">+=</span> <span class="va">self</span>.velocities</span>
<span id="cb23-841"><a href="#cb23-841" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-842"><a href="#cb23-842" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mantener partículas dentro de los límites</span></span>
<span id="cb23-843"><a href="#cb23-843" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.positions <span class="op">=</span> np.clip(</span>
<span id="cb23-844"><a href="#cb23-844" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positions,</span>
<span id="cb23-845"><a href="#cb23-845" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bounds[:, <span class="dv">0</span>],</span>
<span id="cb23-846"><a href="#cb23-846" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bounds[:, <span class="dv">1</span>]</span>
<span id="cb23-847"><a href="#cb23-847" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-848"><a href="#cb23-848" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-849"><a href="#cb23-849" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluar nuevas posiciones</span></span>
<span id="cb23-850"><a href="#cb23-850" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.scores <span class="op">=</span> np.array([<span class="va">self</span>.objective_function(p) <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.positions])</span>
<span id="cb23-851"><a href="#cb23-851" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-852"><a href="#cb23-852" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar mejores posiciones personales</span></span>
<span id="cb23-853"><a href="#cb23-853" aria-hidden="true" tabindex="-1"></a>    improved_mask <span class="op">=</span> <span class="va">self</span>.scores <span class="op">&lt;</span> <span class="va">self</span>.p_best_scores</span>
<span id="cb23-854"><a href="#cb23-854" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.p_best[improved_mask] <span class="op">=</span> <span class="va">self</span>.positions[improved_mask]</span>
<span id="cb23-855"><a href="#cb23-855" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.p_best_scores[improved_mask] <span class="op">=</span> <span class="va">self</span>.scores[improved_mask]</span>
<span id="cb23-856"><a href="#cb23-856" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-857"><a href="#cb23-857" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actualizar mejor posición global</span></span>
<span id="cb23-858"><a href="#cb23-858" aria-hidden="true" tabindex="-1"></a>    min_score_idx <span class="op">=</span> np.argmin(<span class="va">self</span>.p_best_scores)</span>
<span id="cb23-859"><a href="#cb23-859" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.p_best_scores[min_score_idx] <span class="op">&lt;</span> <span class="va">self</span>.g_best_score:</span>
<span id="cb23-860"><a href="#cb23-860" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.g_best <span class="op">=</span> <span class="va">self</span>.p_best[min_score_idx].copy()</span>
<span id="cb23-861"><a href="#cb23-861" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.g_best_score <span class="op">=</span> <span class="va">self</span>.p_best_scores[min_score_idx]</span>
<span id="cb23-862"><a href="#cb23-862" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-863"><a href="#cb23-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-864"><a href="#cb23-864" aria-hidden="true" tabindex="-1"></a>El algoritmo se detiene cuando se alcanza un número máximo de iteraciones, o cuando la mejora en la función objetivo es menor a un umbral predefinido.</span>
<span id="cb23-865"><a href="#cb23-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-866"><a href="#cb23-866" aria-hidden="true" tabindex="-1"></a>Al implementar el algoritmo, se presentó un comportamiento oscilatorio donde las partículas convergían inicialmente pero luego se dispersaban de manera repentina. El análisis reveló cuatro posibles causas: velocidades excesivas de las partículas, coeficientes de aprendizaje mal ajustados, peso de inercia estático y ausencia de un mecanismo de estabilización.</span>
<span id="cb23-867"><a href="#cb23-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-868"><a href="#cb23-868" aria-hidden="true" tabindex="-1"></a>La solución implementada aborda estos problemas mediante cuatro modificaciones: Se &nbsp;limitó la velocidad máxima al 10% del espacio de búsqueda para evitar saltos excesivos, se optimizaron los coeficientes cognitivo y social a un valor de 2.0 para balancear exploración y explotación, se implementó un peso de inercia dinámico que decrece linealmente de 0.9 a 0.4 durante la optimización y se añadió un factor de constricción calculado a partir de los coeficientes de aprendizaje para garantizar convergencia matemática.</span>
<span id="cb23-869"><a href="#cb23-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-872"><a href="#cb23-872" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-873"><a href="#cb23-873" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb23-874"><a href="#cb23-874" aria-hidden="true" tabindex="-1"></a><span class="co"># Control de Velocidad Máxima</span></span>
<span id="cb23-875"><a href="#cb23-875" aria-hidden="true" tabindex="-1"></a>v_max <span class="op">=</span> <span class="fl">0.1</span> <span class="op">*</span> (bounds[:, <span class="dv">1</span>] <span class="op">-</span> bounds[:, <span class="dv">0</span>])</span>
<span id="cb23-876"><a href="#cb23-876" aria-hidden="true" tabindex="-1"></a>velocities <span class="op">=</span> np.clip(velocities, <span class="op">-</span>v_max, v_max)</span>
<span id="cb23-877"><a href="#cb23-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-878"><a href="#cb23-878" aria-hidden="true" tabindex="-1"></a><span class="co"># Peso de Inercia Dinámico</span></span>
<span id="cb23-879"><a href="#cb23-879" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> w_max <span class="op">-</span> (w_max <span class="op">-</span> w_min) <span class="op">*</span> (iteracion <span class="op">/</span> max_iter)</span>
<span id="cb23-880"><a href="#cb23-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-881"><a href="#cb23-881" aria-hidden="true" tabindex="-1"></a><span class="co"># Factor de Constricción</span></span>
<span id="cb23-882"><a href="#cb23-882" aria-hidden="true" tabindex="-1"></a>phi <span class="op">=</span> c1 <span class="op">+</span> c2</span>
<span id="cb23-883"><a href="#cb23-883" aria-hidden="true" tabindex="-1"></a>chi <span class="op">=</span> <span class="dv">2</span> <span class="op">/</span> <span class="bu">abs</span>(<span class="dv">2</span> <span class="op">-</span> phi <span class="op">-</span> np.sqrt(phi <span class="op">*</span> phi <span class="op">-</span> <span class="dv">4</span> <span class="op">*</span> phi))</span>
<span id="cb23-884"><a href="#cb23-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-885"><a href="#cb23-885" aria-hidden="true" tabindex="-1"></a><span class="co"># Parámetros Optimizados</span></span>
<span id="cb23-886"><a href="#cb23-886" aria-hidden="true" tabindex="-1"></a>c1 <span class="op">=</span> c2 <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb23-887"><a href="#cb23-887" aria-hidden="true" tabindex="-1"></a>w_max <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb23-888"><a href="#cb23-888" aria-hidden="true" tabindex="-1"></a>w_min <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb23-889"><a href="#cb23-889" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-890"><a href="#cb23-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-891"><a href="#cb23-891" aria-hidden="true" tabindex="-1"></a>Estas modificaciones resultaron en una mejora significativa en la estabilidad del algoritmo, con una transición más suave entre las fases de exploración y explotación, y una convergencia más consistente hacia el óptimo global.</span>
<span id="cb23-892"><a href="#cb23-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-893"><a href="#cb23-893" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb23-894"><a href="#cb23-894" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rosenbrock</span></span>
<span id="cb23-895"><a href="#cb23-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-896"><a href="#cb23-896" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-897"><a href="#cb23-897" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = \sum_{i=1}^{d-1} \left<span class="co">[</span><span class="ot"> 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right</span><span class="co">]</span> \tag{1}</span>
<span id="cb23-898"><a href="#cb23-898" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-899"><a href="#cb23-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-900"><a href="#cb23-900" aria-hidden="true" tabindex="-1"></a>**Figura 19.**</span>
<span id="cb23-901"><a href="#cb23-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-902"><a href="#cb23-902" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización de partículas sobre la función de Rosenbrock.* <span class="al">![Aplicación de optimización de partículas sobre la función de Rosenbrock](images/Rosenbrock_particulas_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-903"><a href="#cb23-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-904"><a href="#cb23-904" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rastrigin</span></span>
<span id="cb23-905"><a href="#cb23-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-906"><a href="#cb23-906" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-907"><a href="#cb23-907" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left<span class="co">[</span><span class="ot"> x_i^2 - 10 \cos(2\pi x_i) \right</span><span class="co">]</span> \tag{3}</span>
<span id="cb23-908"><a href="#cb23-908" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-909"><a href="#cb23-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-910"><a href="#cb23-910" aria-hidden="true" tabindex="-1"></a>**Figura 20.**</span>
<span id="cb23-911"><a href="#cb23-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-912"><a href="#cb23-912" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización de partículas sobre la función de Rastrigin.* <span class="al">![Aplicación de optimización de partículas sobre la función de Rastrigin](images/Rastrigin_particulas_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-913"><a href="#cb23-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-914"><a href="#cb23-914" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Schwefel</span></span>
<span id="cb23-915"><a href="#cb23-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-916"><a href="#cb23-916" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-917"><a href="#cb23-917" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}</span>
<span id="cb23-918"><a href="#cb23-918" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-919"><a href="#cb23-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-920"><a href="#cb23-920" aria-hidden="true" tabindex="-1"></a>**Figura 21.**</span>
<span id="cb23-921"><a href="#cb23-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-922"><a href="#cb23-922" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización de partículas sobre la función de Schwefel.* <span class="al">![Aplicación de optimización de partículas sobre la función de Schwefel](images/Schwefel_particulas_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-923"><a href="#cb23-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-924"><a href="#cb23-924" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Griewank</span></span>
<span id="cb23-925"><a href="#cb23-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-926"><a href="#cb23-926" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-927"><a href="#cb23-927" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}</span>
<span id="cb23-928"><a href="#cb23-928" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-929"><a href="#cb23-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-930"><a href="#cb23-930" aria-hidden="true" tabindex="-1"></a>**Figura 22.**</span>
<span id="cb23-931"><a href="#cb23-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-932"><a href="#cb23-932" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización de partículas sobre la función de Griewank.* <span class="al">![Aplicación de optimización de partículas sobre la función de Griewank](images/Griewank_particulas_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-933"><a href="#cb23-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-934"><a href="#cb23-934" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función Goldstein-Price</span></span>
<span id="cb23-935"><a href="#cb23-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-936"><a href="#cb23-936" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-937"><a href="#cb23-937" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb23-938"><a href="#cb23-938" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = &amp; \left<span class="co">[</span><span class="ot">1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb23-939"><a href="#cb23-939" aria-hidden="true" tabindex="-1"></a>         &amp; \left<span class="co">[</span><span class="ot">30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right</span><span class="co">]</span></span>
<span id="cb23-940"><a href="#cb23-940" aria-hidden="true" tabindex="-1"></a>\end{align} \tag{6}</span>
<span id="cb23-941"><a href="#cb23-941" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-942"><a href="#cb23-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-943"><a href="#cb23-943" aria-hidden="true" tabindex="-1"></a>**Figura 23.**</span>
<span id="cb23-944"><a href="#cb23-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-945"><a href="#cb23-945" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización de partículas sobre la función de Goldstein-Price.* <span class="al">![Aplicación de optimización de partículas sobre la función de Goldstein-Price](images/Goldstein_Price_particulas_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-946"><a href="#cb23-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-947"><a href="#cb23-947" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de las seis jorobas de camello</span></span>
<span id="cb23-948"><a href="#cb23-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-949"><a href="#cb23-949" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-950"><a href="#cb23-950" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}</span>
<span id="cb23-951"><a href="#cb23-951" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-952"><a href="#cb23-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-953"><a href="#cb23-953" aria-hidden="true" tabindex="-1"></a>**Figura 24.**</span>
<span id="cb23-954"><a href="#cb23-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-955"><a href="#cb23-955" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización de partículas sobre la función de las seis jorobas del camello.* <span class="al">![Aplicación de optimización de partículas sobre la función de las seis jorobas del camello](images/Camel_Six_Humps_particulas_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-956"><a href="#cb23-956" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-957"><a href="#cb23-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-958"><a href="#cb23-958" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimización diferencial</span></span>
<span id="cb23-959"><a href="#cb23-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-960"><a href="#cb23-960" aria-hidden="true" tabindex="-1"></a>**Funcionamiento Básico**</span>
<span id="cb23-961"><a href="#cb23-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-962"><a href="#cb23-962" aria-hidden="true" tabindex="-1"></a>La Evolución Diferencial (ED) es un algoritmo de optimización poblacional inspirado en los procesos evolutivos naturales. Al igual que otros algoritmos de esta categoría, la ED mantiene una población de soluciones candidatas, las cuales se recombinan y mutan para producir nuevos individuos los cuales serán elegidos de acuerdo al valor de su función de desempeño. Lo que caracteriza a la ED es el uso de vectores de prueba, los cuales compiten con los individuos de la población actual a fin de sobrevivir. <span class="co">[</span><span class="ot">@price1995differential</span><span class="co">]</span></span>
<span id="cb23-963"><a href="#cb23-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-964"><a href="#cb23-964" aria-hidden="true" tabindex="-1"></a>**Pasos clave:**</span>
<span id="cb23-965"><a href="#cb23-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-966"><a href="#cb23-966" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Inicialización de la población:**</span>
<span id="cb23-967"><a href="#cb23-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-968"><a href="#cb23-968" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se genera aleatoriamente una población inicial de individuos (soluciones potenciales).</span>
<span id="cb23-969"><a href="#cb23-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-970"><a href="#cb23-970" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Cada individuo es un vector que representa un punto en el espacio de búsqueda.</span>
<span id="cb23-971"><a href="#cb23-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-974"><a href="#cb23-974" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-975"><a href="#cb23-975" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_population(<span class="va">self</span>):</span>
<span id="cb23-976"><a href="#cb23-976" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-977"><a href="#cb23-977" aria-hidden="true" tabindex="-1"></a><span class="co">    Inicializa la población de manera aleatoria dentro de los límites especificados</span></span>
<span id="cb23-978"><a href="#cb23-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-979"><a href="#cb23-979" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb23-980"><a href="#cb23-980" aria-hidden="true" tabindex="-1"></a><span class="co">    - Matriz numpy con población inicial</span></span>
<span id="cb23-981"><a href="#cb23-981" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-982"><a href="#cb23-982" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crea una matriz de ceros con el tamaño de la población</span></span>
<span id="cb23-983"><a href="#cb23-983" aria-hidden="true" tabindex="-1"></a>    population <span class="op">=</span> np.zeros((<span class="va">self</span>.population_size, <span class="va">self</span>.dimension))</span>
<span id="cb23-984"><a href="#cb23-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-985"><a href="#cb23-985" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Genera valores aleatorios para cada dimensión</span></span>
<span id="cb23-986"><a href="#cb23-986" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.dimension):</span>
<span id="cb23-987"><a href="#cb23-987" aria-hidden="true" tabindex="-1"></a>        population[:, i] <span class="op">=</span> np.random.uniform(</span>
<span id="cb23-988"><a href="#cb23-988" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bounds[i][<span class="dv">0</span>],  <span class="co"># Límite inferior</span></span>
<span id="cb23-989"><a href="#cb23-989" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.bounds[i][<span class="dv">1</span>],  <span class="co"># Límite superior</span></span>
<span id="cb23-990"><a href="#cb23-990" aria-hidden="true" tabindex="-1"></a>            size<span class="op">=</span><span class="va">self</span>.population_size  <span class="co"># Número de individuos</span></span>
<span id="cb23-991"><a href="#cb23-991" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-992"><a href="#cb23-992" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population</span>
<span id="cb23-993"><a href="#cb23-993" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-994"><a href="#cb23-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-995"><a href="#cb23-995" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Evaluación de la población:**</span>
<span id="cb23-996"><a href="#cb23-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-997"><a href="#cb23-997" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se evalúa el valor de la función objetivo para cada individuo de la población</span>
<span id="cb23-998"><a href="#cb23-998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-999"><a href="#cb23-999" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Generación de nuevos individuos:**</span>
<span id="cb23-1000"><a href="#cb23-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1001"><a href="#cb23-1001" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>**Mutación:** Se crea un vector mutante sumando a un individuo objetivo una diferencia escalada entre otros dos individuos de la población.</span>
<span id="cb23-1002"><a href="#cb23-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1005"><a href="#cb23-1005" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-1006"><a href="#cb23-1006" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mutation(<span class="va">self</span>, population):</span>
<span id="cb23-1007"><a href="#cb23-1007" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-1008"><a href="#cb23-1008" aria-hidden="true" tabindex="-1"></a><span class="co">    Aplica la estrategia de mutación DE/rand/1</span></span>
<span id="cb23-1009"><a href="#cb23-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1010"><a href="#cb23-1010" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb23-1011"><a href="#cb23-1011" aria-hidden="true" tabindex="-1"></a><span class="co">    - population: Población actual</span></span>
<span id="cb23-1012"><a href="#cb23-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1013"><a href="#cb23-1013" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb23-1014"><a href="#cb23-1014" aria-hidden="true" tabindex="-1"></a><span class="co">    - Población mutada</span></span>
<span id="cb23-1015"><a href="#cb23-1015" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-1016"><a href="#cb23-1016" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crea una matriz para almacenar la población mutada</span></span>
<span id="cb23-1017"><a href="#cb23-1017" aria-hidden="true" tabindex="-1"></a>    mutation_pop <span class="op">=</span> np.zeros_like(population)</span>
<span id="cb23-1018"><a href="#cb23-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1019"><a href="#cb23-1019" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.population_size):</span>
<span id="cb23-1020"><a href="#cb23-1020" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Selecciona tres individuos aleatorios diferentes</span></span>
<span id="cb23-1021"><a href="#cb23-1021" aria-hidden="true" tabindex="-1"></a>        candidates <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="va">self</span>.population_size))</span>
<span id="cb23-1022"><a href="#cb23-1022" aria-hidden="true" tabindex="-1"></a>        candidates.remove(i)</span>
<span id="cb23-1023"><a href="#cb23-1023" aria-hidden="true" tabindex="-1"></a>        r1, r2, r3 <span class="op">=</span> np.random.choice(candidates, <span class="dv">3</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-1024"><a href="#cb23-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1025"><a href="#cb23-1025" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera un nuevo vector mediante mutación</span></span>
<span id="cb23-1026"><a href="#cb23-1026" aria-hidden="true" tabindex="-1"></a>        mutation_pop[i] <span class="op">=</span> population[r1] <span class="op">+</span> <span class="va">self</span>.F <span class="op">*</span> (population[r2] <span class="op">-</span> </span>
<span id="cb23-1027"><a href="#cb23-1027" aria-hidden="true" tabindex="-1"></a>                                                               population[r3])</span>
<span id="cb23-1028"><a href="#cb23-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1029"><a href="#cb23-1029" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Asegura que los valores estén dentro de los límites</span></span>
<span id="cb23-1030"><a href="#cb23-1030" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.dimension):</span>
<span id="cb23-1031"><a href="#cb23-1031" aria-hidden="true" tabindex="-1"></a>            mutation_pop[i, j] <span class="op">=</span> np.clip(</span>
<span id="cb23-1032"><a href="#cb23-1032" aria-hidden="true" tabindex="-1"></a>                mutation_pop[i, j],</span>
<span id="cb23-1033"><a href="#cb23-1033" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.bounds[j][<span class="dv">0</span>],</span>
<span id="cb23-1034"><a href="#cb23-1034" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.bounds[j][<span class="dv">1</span>]</span>
<span id="cb23-1035"><a href="#cb23-1035" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb23-1036"><a href="#cb23-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1037"><a href="#cb23-1037" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mutation_pop</span>
<span id="cb23-1038"><a href="#cb23-1038" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-1039"><a href="#cb23-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1040"><a href="#cb23-1040" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Cruce:** Se crea un vector de prueba combinando el vector mutante y el individuo objetivo mediante un operador de cruce.</span>
<span id="cb23-1041"><a href="#cb23-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1044"><a href="#cb23-1044" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-1045"><a href="#cb23-1045" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> crossover(<span class="va">self</span>, population, mutation_pop):</span>
<span id="cb23-1046"><a href="#cb23-1046" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-1047"><a href="#cb23-1047" aria-hidden="true" tabindex="-1"></a><span class="co">    Aplica el cruce binomial (crossover)</span></span>
<span id="cb23-1048"><a href="#cb23-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1049"><a href="#cb23-1049" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb23-1050"><a href="#cb23-1050" aria-hidden="true" tabindex="-1"></a><span class="co">    - population: Población actual</span></span>
<span id="cb23-1051"><a href="#cb23-1051" aria-hidden="true" tabindex="-1"></a><span class="co">    - mutation_pop: Población mutada</span></span>
<span id="cb23-1052"><a href="#cb23-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1053"><a href="#cb23-1053" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb23-1054"><a href="#cb23-1054" aria-hidden="true" tabindex="-1"></a><span class="co">    - Población de prueba tras el cruce</span></span>
<span id="cb23-1055"><a href="#cb23-1055" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-1056"><a href="#cb23-1056" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Crea una matriz para almacenar la población de prueba</span></span>
<span id="cb23-1057"><a href="#cb23-1057" aria-hidden="true" tabindex="-1"></a>    trial_pop <span class="op">=</span> np.zeros_like(population)</span>
<span id="cb23-1058"><a href="#cb23-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1059"><a href="#cb23-1059" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.population_size):</span>
<span id="cb23-1060"><a href="#cb23-1060" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera puntos de cruce basados en CR</span></span>
<span id="cb23-1061"><a href="#cb23-1061" aria-hidden="true" tabindex="-1"></a>        cross_points <span class="op">=</span> np.random.rand(<span class="va">self</span>.dimension) <span class="op">&lt;=</span> <span class="va">self</span>.CR</span>
<span id="cb23-1062"><a href="#cb23-1062" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Asegura al menos un punto de cruce</span></span>
<span id="cb23-1063"><a href="#cb23-1063" aria-hidden="true" tabindex="-1"></a>        cross_points[np.random.randint(<span class="dv">0</span>, <span class="va">self</span>.dimension)] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-1064"><a href="#cb23-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1065"><a href="#cb23-1065" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Genera vector de prueba</span></span>
<span id="cb23-1066"><a href="#cb23-1066" aria-hidden="true" tabindex="-1"></a>        trial_pop[i] <span class="op">=</span> np.where(cross_points, mutation_pop[i], population[i])</span>
<span id="cb23-1067"><a href="#cb23-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1068"><a href="#cb23-1068" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> trial_pop</span>
<span id="cb23-1069"><a href="#cb23-1069" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-1070"><a href="#cb23-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1071"><a href="#cb23-1071" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Selección:** Se compara el valor de la función objetivo del vector de prueba con el del individuo objetivo. El mejor de los dos se selecciona para la siguiente generación.</span>
<span id="cb23-1072"><a href="#cb23-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1075"><a href="#cb23-1075" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-1076"><a href="#cb23-1076" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> selection(<span class="va">self</span>, population, trial_pop):</span>
<span id="cb23-1077"><a href="#cb23-1077" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb23-1078"><a href="#cb23-1078" aria-hidden="true" tabindex="-1"></a><span class="co">    Selección de los mejores individuos</span></span>
<span id="cb23-1079"><a href="#cb23-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1080"><a href="#cb23-1080" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb23-1081"><a href="#cb23-1081" aria-hidden="true" tabindex="-1"></a><span class="co">    - population: Población actual</span></span>
<span id="cb23-1082"><a href="#cb23-1082" aria-hidden="true" tabindex="-1"></a><span class="co">    - trial_pop: Población de prueba</span></span>
<span id="cb23-1083"><a href="#cb23-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1084"><a href="#cb23-1084" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb23-1085"><a href="#cb23-1085" aria-hidden="true" tabindex="-1"></a><span class="co">    - Nueva población y sus valores de aptitud</span></span>
<span id="cb23-1086"><a href="#cb23-1086" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb23-1087"><a href="#cb23-1087" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcula la aptitud de la población actual y de prueba</span></span>
<span id="cb23-1088"><a href="#cb23-1088" aria-hidden="true" tabindex="-1"></a>    pop_fitness <span class="op">=</span> np.array([<span class="va">self</span>.func(ind) <span class="cf">for</span> ind <span class="kw">in</span> population])</span>
<span id="cb23-1089"><a href="#cb23-1089" aria-hidden="true" tabindex="-1"></a>    trial_fitness <span class="op">=</span> np.array([<span class="va">self</span>.func(ind) <span class="cf">for</span> ind <span class="kw">in</span> trial_pop])</span>
<span id="cb23-1090"><a href="#cb23-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1091"><a href="#cb23-1091" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Identifica qué individuos de prueba son mejores</span></span>
<span id="cb23-1092"><a href="#cb23-1092" aria-hidden="true" tabindex="-1"></a>    better_indices <span class="op">=</span> trial_fitness <span class="op">&lt;</span> pop_fitness</span>
<span id="cb23-1093"><a href="#cb23-1093" aria-hidden="true" tabindex="-1"></a>    population[better_indices] <span class="op">=</span> trial_pop[better_indices]</span>
<span id="cb23-1094"><a href="#cb23-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1095"><a href="#cb23-1095" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> population, np.minimum(pop_fitness, trial_fitness)</span>
<span id="cb23-1096"><a href="#cb23-1096" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-1097"><a href="#cb23-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1098"><a href="#cb23-1098" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Criterio de parada**:</span>
<span id="cb23-1099"><a href="#cb23-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1100"><a href="#cb23-1100" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Se repiten los pasos 3 y 4 hasta que se cumpla un criterio de parada (número máximo de generaciones, mejora mínima en la función objetivo, etc.), de acuerdo con @martinez2019evolucion.</span>
<span id="cb23-1101"><a href="#cb23-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1102"><a href="#cb23-1102" aria-hidden="true" tabindex="-1"></a>::: panel-tabset</span>
<span id="cb23-1103"><a href="#cb23-1103" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rosenbrock</span></span>
<span id="cb23-1104"><a href="#cb23-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1105"><a href="#cb23-1105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1106"><a href="#cb23-1106" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = \sum_{i=1}^{d-1} \left<span class="co">[</span><span class="ot"> 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \right</span><span class="co">]</span> \tag{1}</span>
<span id="cb23-1107"><a href="#cb23-1107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1108"><a href="#cb23-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1109"><a href="#cb23-1109" aria-hidden="true" tabindex="-1"></a>**Figura 25.**</span>
<span id="cb23-1110"><a href="#cb23-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1111"><a href="#cb23-1111" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización diferencial sobre la función de Rosenbrock.* <span class="al">![Aplicación de optimización diferencial sobre la función de Rosenbrock](images/Rosenbrock_diferential_evolution_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-1112"><a href="#cb23-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1113"><a href="#cb23-1113" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Rastrigin</span></span>
<span id="cb23-1114"><a href="#cb23-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1115"><a href="#cb23-1115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1116"><a href="#cb23-1116" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 10d + \sum_{i=1}^{d} \left<span class="co">[</span><span class="ot"> x_i^2 - 10 \cos(2\pi x_i) \right</span><span class="co">]</span> \tag{3}</span>
<span id="cb23-1117"><a href="#cb23-1117" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1118"><a href="#cb23-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1119"><a href="#cb23-1119" aria-hidden="true" tabindex="-1"></a>**Figura 26.**</span>
<span id="cb23-1120"><a href="#cb23-1120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1121"><a href="#cb23-1121" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización diferencial sobre la función de Rastrigin.* <span class="al">![Aplicación de optimización diferencial sobre la función de Rastrigin](images/Rastrigin_diferential_evolution_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-1122"><a href="#cb23-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1123"><a href="#cb23-1123" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Schwefel</span></span>
<span id="cb23-1124"><a href="#cb23-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1125"><a href="#cb23-1125" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-1126"><a href="#cb23-1126" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 418.9829d - \sum_{i=1}^{d} x_i \sin(\sqrt{|x_i|}) \tag{4}</span>
<span id="cb23-1127"><a href="#cb23-1127" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1128"><a href="#cb23-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1129"><a href="#cb23-1129" aria-hidden="true" tabindex="-1"></a>**Figura 27.**</span>
<span id="cb23-1130"><a href="#cb23-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1131"><a href="#cb23-1131" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización diferencial sobre la función de Schwefel.* <span class="al">![Aplicación de optimización diferencial sobre la función de Schwefel](images/Schwefel_diferential_evolution_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-1132"><a href="#cb23-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1133"><a href="#cb23-1133" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de Griewank</span></span>
<span id="cb23-1134"><a href="#cb23-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1135"><a href="#cb23-1135" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-1136"><a href="#cb23-1136" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}) = 1 + \frac{1}{4000} \sum_{i=1}^{d} x_i^2 - \prod_{i=1}^{d} \cos\left(\frac{x_i}{\sqrt{i}}\right) \tag{5}</span>
<span id="cb23-1137"><a href="#cb23-1137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1138"><a href="#cb23-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1139"><a href="#cb23-1139" aria-hidden="true" tabindex="-1"></a>**Figura 28.**</span>
<span id="cb23-1140"><a href="#cb23-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1141"><a href="#cb23-1141" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización diferencial sobre la función de Griewank.* <span class="al">![Aplicación de optimización diferencial sobre la función de Griewank](images/Griewank_diferential_evolution_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-1142"><a href="#cb23-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1143"><a href="#cb23-1143" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función Goldstein-Price</span></span>
<span id="cb23-1144"><a href="#cb23-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1145"><a href="#cb23-1145" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-1146"><a href="#cb23-1146" aria-hidden="true" tabindex="-1"></a>\begin{align} f(x_1, x_2) = &amp; \left<span class="co">[</span><span class="ot">1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\right</span><span class="co">]</span> <span class="sc">\\</span>          &amp; \left<span class="co">[</span><span class="ot">30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\right</span><span class="co">]</span> \end{align} \tag{6}</span>
<span id="cb23-1147"><a href="#cb23-1147" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1148"><a href="#cb23-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1149"><a href="#cb23-1149" aria-hidden="true" tabindex="-1"></a>**Figura 29.**</span>
<span id="cb23-1150"><a href="#cb23-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1151"><a href="#cb23-1151" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización diferencial sobre la función de Goldstein-Price.* <span class="al">![Aplicación de optimización diferencial sobre la función de Goldstein-Price](images/Goldstein_Price_diferential_evolution_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-1152"><a href="#cb23-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1153"><a href="#cb23-1153" aria-hidden="true" tabindex="-1"></a><span class="fu">### Función de las seis jorobas de camello</span></span>
<span id="cb23-1154"><a href="#cb23-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1155"><a href="#cb23-1155" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb23-1156"><a href="#cb23-1156" aria-hidden="true" tabindex="-1"></a>f(x_1, x_2) = \left(4 - 2.1x_1^2 + \frac{x_1^4}{3}\right)x_1^2 + x_1x_2 + \left(-4 + 4x_2^2\right)x_2^2 \tag{7}</span>
<span id="cb23-1157"><a href="#cb23-1157" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb23-1158"><a href="#cb23-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1159"><a href="#cb23-1159" aria-hidden="true" tabindex="-1"></a>**Figura 30.**</span>
<span id="cb23-1160"><a href="#cb23-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1161"><a href="#cb23-1161" aria-hidden="true" tabindex="-1"></a>*Aplicación de optimización diferencial sobre la función de las seis jorobas del camello.* <span class="al">![Aplicación de optimización diferencial sobre la función de las seis jorobas del camello](images/Camel_Six_Humps_diferential_evolution_animation.gif)</span> Elaboración propia.</span>
<span id="cb23-1162"><a href="#cb23-1162" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb23-1163"><a href="#cb23-1163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1164"><a href="#cb23-1164" aria-hidden="true" tabindex="-1"></a><span class="fu"># Resultados</span></span>
<span id="cb23-1165"><a href="#cb23-1165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1166"><a href="#cb23-1166" aria-hidden="true" tabindex="-1"></a>Como se puede observar, en la mayoría de los casos de optimización para una única corrida los puntos óptimos conergen a mínimos locales, lo que indica que los resultados óptimos pueden estar fuertemente influenciados por los valores iniciales de $x$ o las condiciones de inicio de los algoritmos. Por esta razón, para evaluar el rendimiento y el comportamiento de los algoritmos en un entorno más general, se realizarán múltiples ejecuciones. En cada corrida, los algoritmos partirán de valores iniciales distintos generados aleatoriamente. Con esto se verá cuánto tardan los algoritmos en mejorar la evaluación de la función objetivo y cuáles pueden ser algunos comentarios particulares a realizar. Los resultados se presentarán para los casos de 2 y 3 dimensiones de las funciones.</span>
<span id="cb23-1167"><a href="#cb23-1167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1168"><a href="#cb23-1168" aria-hidden="true" tabindex="-1"></a>(Tabla o gráfica de resutlados)</span>
<span id="cb23-1169"><a href="#cb23-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1170"><a href="#cb23-1170" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusiones y comentarios</span></span>
<span id="cb23-1171"><a href="#cb23-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1172"><a href="#cb23-1172" aria-hidden="true" tabindex="-1"></a><span class="fu"># Discusión</span></span>
<span id="cb23-1173"><a href="#cb23-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1174"><a href="#cb23-1174" aria-hidden="true" tabindex="-1"></a>Reflexione sobre los siguientes puntos:</span>
<span id="cb23-1175"><a href="#cb23-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1176"><a href="#cb23-1176" aria-hidden="true" tabindex="-1"></a>¿Qué aportaron los métodos de **descenso por gradiente** y qué aportaron los **métodos heurísticos**? Para responder a esta pregunta, considere:</span>
<span id="cb23-1177"><a href="#cb23-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1178"><a href="#cb23-1178" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>El **valor final** de la función objetivo.</span>
<span id="cb23-1179"><a href="#cb23-1179" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>El **número de evaluaciones** de la función objetivo.</span>
<span id="cb23-1180"><a href="#cb23-1180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1181"><a href="#cb23-1181" aria-hidden="true" tabindex="-1"></a>Es posible que se requiera realizar **varias corridas** de los algoritmos para obtener conclusiones significativas.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>