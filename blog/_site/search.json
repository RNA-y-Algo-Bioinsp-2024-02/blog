[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portafolio trabajos",
    "section": "",
    "text": "Algoritmo de colonia de hormigas para el problema del vendedor viajero\n\n\n\n\n\n\noptimización\n\n\nmétodos heurísticos\n\n\npython\n\n\n\n\n\n\n\n\n\nNov 15, 2024\n\n\nJulián Castaño Pineda, Luis Andrés Altamar Romero, Catalina Restrepo Salgado, Tomás Rodríguez Taborda\n\n\n\n\n\n\n\n\n\n\n\n\nMétodos de optimización heurística\n\n\n\n\n\n\noptimización\n\n\nmétodos heurísticos\n\n\npython\n\n\n\n\n\n\n\n\n\nNov 15, 2024\n\n\nJulián Castaño Pineda, Luis Andrés Altamar Romero, Catalina Restrepo Salgado, Tomás Rodríguez Taborda\n\n\n\n\n\n\n\n\n\n\n\n\n!Bienvenido a nuestro blog!\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Métodos de optimización heurística",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport io\nfrom PIL import Image\nEl objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.\nAl final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "!Bienvenido a nuestro blog!",
    "section": "",
    "text": "Este blog ha sido diseñado como parte de un curso dedicado a la inteligencia artificial y los modelos bioinspirados, con el propósito de servir como un repositorio de trabajos, reflexiones y aprendizajes desarrollados a lo largo del programa. Más allá del curso, nuestro objetivo es que este espacio evolucione hacia un portafolio que abarque múltiples temáticas en inteligencia artificial, analítica avanzada y aprendizaje automático.\n\n\n\n\nTrabajos del curso: Proyectos que exploran desde el funcionamiento básico de redes neuronales hasta implementaciones más avanzadas de algoritmos bioinspirados, como los basados en evolución genética o el comportamiento de colonias de hormigas.\nArtículos educativos: Explicaciones claras y prácticas sobre conceptos clave de inteligencia artificial y sus aplicaciones.\nRecursos reproducibles: Todo lo que publico está diseñado para ser reutilizable y comprensible, buscando contribuir al aprendizaje de otros.\n\n\n\n\n\n\n\n\n\n\nLa idea de este blog no solo es mostrar lo aprendido, sino también convertirlo en un material accesible y de calidad para otros. Crear contenido reproducible y útil puede ser un puente hacia el aprendizaje compartido, la inspiración y la mejora continua.\nAdemás, quieremos que este espacio sea un ejemplo de cómo construir un portafolio profesional que combine el rigor técnico con un diseño atractivo. Esto puede ser útil tanto para la comunidad académica como para el ámbito profesional.\n\n\n\n\n\nLee los proyectos: Cada entrada está organizada para que puedas entender tanto la teoría como las implementaciones prácticas.\nDescarga y reproduce: Los ejemplos están diseñados para ser replicados, con código y explicaciones detalladas.\nConstruye sobre esto: Usa las ideas presentadas como punto de partida para tus propios proyectos."
  },
  {
    "objectID": "posts/post-with-code/index.html#considere-las-siguientes-funciones-de-prueba",
    "href": "posts/post-with-code/index.html#considere-las-siguientes-funciones-de-prueba",
    "title": "Primer trabajo: Optimización heurística",
    "section": "",
    "text": "Función de Rosenbrock \\[ f(x, y) = (a - x)^2 + b(y - x^2)^2 \\]\nFunción de Rastrigin \\[ f(\\mathbf{x}) = An + \\sum_{i=1}^{n} \\left[ x_i^2 - A \\cos(2 \\pi x_i) \\right] \\]\nFunción de Schwefel \\[ f(\\mathbf{x}) = 418.9829n - \\sum_{i=1}^{n} x_i \\sin(\\sqrt{|x_i|}) \\]\nFunción de Griewank \\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{n} x_i^2 - \\prod_{i=1}^{n} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\nFunción Goldstein-Price \\[ f(x, y) = \\left[1 + (x + y + 1)^2 (19 - 14x + 3x^2 - 14y + 6xy + 3y^2)\\right] \\left[30 + (2x - 3y)^2 (18 - 32x + 12x^2 + 48y - 36xy + 27y^2)\\right] \\]\nFunción de las seis jorobas de camello \\[ f(x, y) = \\left(4 - 2.1x^2 + \\frac{x^4}{3}\\right)x^2 + xy + \\left(-4 + 4y^2\\right)y^2 \\]\n\n\n\n\nEscoja dos funciones de prueba.\nOptimización con método de descenso por gradiente:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando un método de descenso por gradiente con condición inicial aleatoria.\n\nOptimización con métodos heurísticos:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando:\n\nAlgoritmos evolutivos.\nOptimización de partículas.\nEvolución diferencial.\n\n\nRepresentación visual:\n\nCree un GIF animado o un video que muestre el proceso de optimización usando:\n\nDescenso por gradiente.\nMétodos heurísticos.\n\n\n\n\n\n\nReflexione sobre los siguientes puntos: - ¿Qué aportaron los métodos de descenso por gradiente y qué aportaron los métodos heurísticos? - Para responder a esta pregunta, considere: - El valor final de la función objetivo. - El número de evaluaciones de la función objetivo. - Es posible que se requiera realizar varias corridas de los algoritmos para obtener conclusiones significativas."
  },
  {
    "objectID": "posts/post-with-code/index.html#problema-del-viajero",
    "href": "posts/post-with-code/index.html#problema-del-viajero",
    "title": "Métodos de optimización heurística",
    "section": "5.1 Problema del Viajero:",
    "text": "5.1 Problema del Viajero:\nUn vendedor debe realizar un recorrido por todas las capitales de los 32 estados de los Estados Unidos Mexicanos.\n\n5.1.1 Tareas:\n\nOptimización con métodos metaheurísticos:\n\nUtilice colonias de hormigas para encontrar el orden óptimo del recorrido.\nUtilice algoritmos genéticos para encontrar el orden óptimo del recorrido.\n\nCosto del recorrido:\n\nEl costo de desplazamiento entre ciudades se calcula como la suma de:\n\nEl valor de la hora del vendedor (este es un parámetro que debe estudiarse).\nEl costo de los peajes.\nEl costo del combustible.\n\nCada equipo debe definir el vehículo que utilizará el vendedor para realizar el recorrido y, con base en esta elección, calcular el costo del combustible.\n\n\n\n\n5.1.2 Representación Visual:\n\nCree un GIF animado o un video que muestre cómo se comporta la mejor solución encontrada, usando un gráfico del recorrido en el mapa de México.\n\n\n\n\n5.1.3 Discusión:\nReflexione sobre: - Los resultados obtenidos con las colonias de hormigas y los algoritmos genéticos. - Comparación de costos y tiempo de ejecución."
  },
  {
    "objectID": "posts/post-with-code/index.html#funciones-a-optimizar",
    "href": "posts/post-with-code/index.html#funciones-a-optimizar",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Funciones a optimizar",
    "text": "Funciones a optimizar\nSe seleccionaron seis funciones comúnmente empleadas para evaluar métodos de optimización, debido a sus características particulares. Estas funciones presentan desafíos como la existencia de un mínimo global acompañado de múltiples mínimos locales, así como valles que pueden dificultar la convergencia de los algoritmos. A continuación, se describen dichas funciones, incluyendo su forma funcional generalizada para \\(d\\) dimensiones, su representación gráfica en 2 dimensiones, el valor del mínimo global, una breve descripción de cada función y el rango de evaluación sugerido por diversos autores. Las gráficas fueron generadas a partir de la funcion plot_function() que se muestra en la pestaña de Code sugerida.\n\n\nCode\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None, elev=30, azim=45 ):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(np.array([X1,X2]))\n\n    fig = plt.figure(figsize=(8, 4))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    ax1.view_init(elev=elev, azim=azim)\n\n    if x1_point is not None and x2_point is not None:\n        z_point = f(np.array([x1_point, x2_point])[:, None, None])[0, 0]\n\n        ax1.plot([x1_point], [x2_point], [z_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n        ax1.legend()\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, levels = 10)\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.plot([x1_point], [x2_point], color='r', marker='o', markersize=5, linewidth=0, label=\"Mínimo global\", zorder=5)\n        ax2.legend()\n\n    plt.show()\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\nCode\n# Función de Rosenbrock\ndef rosenbrock(x, a=1, b=100):\n    \"\"\"\n    Calcula el valor de la función de Rosenbrock.\n    x: vector de entrada (numpy array)\n    a, b: parámetros de la función\n    \"\"\"\n    return (sum(b * (x[1:] - x[:-1]**2)**2 + (x[:-1] - a)**2))\n\nplot_function(rosenbrock, x1_range=(-2.048, 2.048), x2_range=(-2.048, 2.048), title=\"Función Rosenbrock\", x1_point=1, x2_point=1)\n\n\n\n\n\n\n\n\n\nEn 2 dimensiones se puede definir como \\[ f(x_1, x_2) = (a - x_1)^2 + b(x_2 - x_1^2)^2 \\]\nLa Función de Rosenbrock, también conocida como función del valle o del plátano, es ampliamente utilizada para evaluar algoritmos de optimización basados en gradientes. Esta función es unimodal y presenta su mínimo global en un valle parabólico estrecho, lo que facilita su localización. Sin embargo, segun Simon Fraser University (n.d.) citando a Picheny, Wagner, and Ginsbourger (2012) convergencia hacia este mínimo puede ser desafiante debido a la naturaleza del valle.\nLa función se evalúa generalmente en el hipercubo \\(x_i \\in [-5, 10]\\) y tiene un mínimo global en \\(f(1,...,1) = 0\\)\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\nCode\n# Función de Rastrigin\ndef rastrigin(x):\n    \"\"\"\n    Calcula el valor de la función de Rastrigin.\n    x: vector de entrada (numpy array)\n    \"\"\"\n    d = len(x)\n    return 10 * d + sum(x**2 - 10 * np.cos(2 * np.pi * x))\nplot_function(rastrigin, x1_range=(-5.12, 5.12), x2_range=(-5.12, 5.12), title=\"Función Rastrigin\", x1_point=0, x2_point=0)\n\n\n\n\n\n\n\n\n\nSegun Simon Fraser University (n.d.), la función de Rastrigin tiene varios mínimos locales. Es altamente multimodal, pero las ubicaciones de los mínimos se distribuyen regularmente. La función generalmente se evalúa en el hipercubo \\(x_i \\in [-5.12, 5.12]\\) y su mínimo local se encuentra en \\(f(0,...,0)=0\\).\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\nCode\n# Función de Schwefel\ndef schwefel(x):\n    \"\"\"\n    Calcula el valor de la función de Schwefel.\n    x: vector de entrada (numpy array)\n    \"\"\"\n    d = len(x)\n    return 418.9829 * d - sum(x * np.sin(np.sqrt(np.abs(x))))\nplot_function(schwefel, x1_range=(-500, 500), x2_range=(-500, 500), title=\"Función Schwefel\", x1_point=420.9687, x2_point=420.9687)\n\n\n\n\n\n\n\n\n\nSegun Simon Fraser University (n.d.) La función de Schwefel es compleja, con muchos mínimos locales. Normalmente se evalua en el hipercubo \\(x_i \\in [-500,500]\\). Su minimo global está en \\(f(420.9687,...,420.9687)=0\\)\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\nCode\n# Función de Griewank\ndef griewank(x):\n    \"\"\"\n    Calcula el valor de la función Griewank.\n    x: numpy array unidimensional (1D) o un array con forma (d, n1, n2) para evaluaciones vectorizadas.\n    \n    Retorna:\n    - Un valor escalar si `x` es 1D.\n    - Una matriz (n1, n2) si `x` tiene forma (d, n1, n2).\n    \"\"\"\n    x = np.asarray(x)\n\n    if x.ndim == 1:\n        # Caso 1D: calcular para un solo vector\n        d = len(x)\n        sum_term = np.sum(x**2) / 4000\n        product_term = np.prod(np.cos(x / np.sqrt(np.arange(1, d + 1))))\n        return 1 + sum_term - product_term\n\n    elif x.ndim == 3:\n        # Caso ND: calcular para una cuadrícula (vectorizado)\n        d = x.shape[0]\n        i_indices = np.arange(1, d + 1).reshape(-1, 1, 1)\n        sum_term = np.sum(x**2, axis=0) / 4000\n        product_term = np.prod(np.cos(x / np.sqrt(i_indices)), axis=0)\n        return 1 + sum_term - product_term\n\n    else:\n        raise ValueError(\"La entrada debe ser un array 1D o un array con forma (d, n1, n2).\")\nplot_function(griewank, x1_range=(-600, 600), x2_range=(-600, 600), title=\"Función Griewank\", x1_point=0, x2_point=0)\n\n\n\n\n\n\n\n\n\nSegun Simon Fraser University (n.d.) la función de Griewank tiene muchos mínimos locales generalizados, que se distribuyen de forma regular. Lo que hace compleja su optimización al minimo global. Normalmente se evalua en el hipercubo \\(x_i \\in [-600,600]\\). Su minimo global está en \\(f(0,...,0)=0\\)\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\nCode\n# Función Goldstein-Price\ndef goldstein_price(x):\n    \"\"\"\n    Calcula el valor de la función Goldstein-Price.\n    x1, x2: coordenadas en 2D\n    \"\"\"\n    x1=x[0]\n    x2=x[1]\n    term1 = (1 + (x1 + x2 + 1)**2 * (19 - 14 * x1 + 3 * x1**2 - 14 * x2 + 6 * x1 * x2 + 3 * x2**2))\n    term2 = (30 + (2 * x1 - 3 * x2)**2 * (18 - 32 * x1 + 12 * x1**2 + 48 * x2 - 36 * x1 * x2 + 27 * x2**2))\n    return term1 * term2\nplot_function(goldstein_price, x1_range=(-2, 2), x2_range=(-2, 2), title=\"Función Goldstein price\", x1_point=0, x2_point=-1)\n\n\n\n\n\n\n\n\n\nLa función Goldstein-Price es una función en 2 dimensiones y tiene varios mínimos locales. Segun Molga and Smutnicki (2005), la función generalmente se evalúa en el cuadrado \\(x_1 \\in [-2, 2]\\) y \\(x_1 \\in [-2, 2]\\) . Su mínimo global es \\(f(0,-1) = 3\\)\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\nCode\n# Función de las seis jorobas de camello\ndef camel_six_humps(x):\n    \"\"\"\n    Calcula el valor de la función de las seis jorobas de camello.\n    x1, x2: coordenadas en 2D\n    \"\"\"\n    x1 = x[0]\n    x2 = x[1]\n    term1 = (4 - 2.1 * x1**2 + x1**4 / 3) * x1**2\n    term2 = x1 * x2\n    term3 = (-4 + 4 * x2**2) * x2**2\n    return term1 + term2 + term3\nplot_function(camel_six_humps, x1_range=(-2, 2), x2_range=(-1, 1), title=\"Función 6 jorobas de camello\", x1_point=0.0898, x2_point=-0.7126, elev=30, azim=75 )\n\n\n\n\n\n\n\n\n\nLa función de las seis jorobas de camello es una función en 2 dimensiones.Segun Molga and Smutnicki (2005) la función tiene seis mínimos locales, dos de los cuales son globales y recomienda evaluar la función en el rectángulo \\(x_1 \\in [-3, 3], x_2 \\in [-2, 2]\\), donde los mínimos globales son \\(f(0.0898,-0.7126) = -1.0316\\) y \\(f(-0.0898, 0.7126) = -1.0316\\)"
  },
  {
    "objectID": "posts/post-with-code/index.html#proceso-de-optimización",
    "href": "posts/post-with-code/index.html#proceso-de-optimización",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Proceso de optimización",
    "text": "Proceso de optimización\n\nOptimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nSegun (Bishop 2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla:\n\\[ x_{t+1} = x_t - \\eta \\nabla f(x_t) \\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable: \\[\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. (Bishop 2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como:\n\\[ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\]\n\\[ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\n\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/post-with-code/funciones.html",
    "href": "posts/post-with-code/funciones.html",
    "title": "",
    "section": "",
    "text": "CodeShow All CodeHide All Code\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n\nMatplotlib is building the font cache; this may take a moment.\n\n\n\n\nCode\nimport numpy as np\n\n# Función de Rosenbrock\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\n# Función de Schwefel\ndef schwefel(x1, x2):\n    return 418.9829 * 2 - (x1 * np.sin(np.sqrt(np.abs(x1))) + x2 * np.sin(np.sqrt(np.abs(x2))))\n\n# Función de Griewank\ndef griewank(x1, x2):\n    return 1 + (x1**2 + x2**2) / 4000 - (np.cos(x1 / np.sqrt(1)) * np.cos(x2 / np.sqrt(2)))\n\n# Función Goldstein-Price\ndef goldstein_price(x1, x2):\n    term1 = 1 + (x1 + x2 + 1)**2 * (19 - 14*x1 + 3*x1**2 - 14*x2 + 6*x1*x2 + 3*x2**2)\n    term2 = 30 + (2*x1 - 3*x2)**2 * (18 - 32*x1 + 12*x1**2 + 48*x2 - 36*x1*x2 + 27*x2**2)\n    return term1 * term2\n\n# Función de las seis jorobas de camello\ndef six_hump_camel(x1, x2):\n    return (4 - 2.1*x1**2 + (x1**4) / 3) * x1**2 + x1 * x2 + (-4 + 4*x2**2) * x2**2\n\n\n\n\nCode\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\"):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z)\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    plt.show()\n\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    ax1.plot_surface(X1, X2, Z)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        ax1.scatter(x1_point, x2_point, z_point+1, color='red', s=50)\n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, cmap='viridis')\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.scatter(x1_point, x2_point, color='red', s=50)\n\n    plt.show()\n\n# Ejemplo de uso con la función de Rosenbrock\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\nplot_function(rosenbrock, x1_range=(-2, 2), x2_range=(-1, 3), title=\"Rosenbrock Function\", x1_point=-1, x2_point=1)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n\n\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    \n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        ax1.scatter(x1_point, x2_point, z_point, color='red', s=50, depthshade=False)  # Ajuste pequeño\n    ax1.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n   \n\n    # Contour plot\n    ax2 = fig.add_subplot(122)\n    contour = ax2.contour(X1, X2, Z, cmap='viridis')\n    ax2.set_title(f'Contour Plot of {title}')\n    ax2.set_xlabel('X1')\n    ax2.set_ylabel('X2')\n    fig.colorbar(contour, ax=ax2)\n\n    if x1_point is not None and x2_point is not None:\n        ax2.scatter(x1_point, x2_point, color='red', s=50)\n\n    plt.show()\n\n# Ejemplo de uso con la función de Rosenbrock\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\nplot_function(rosenbrock, x1_range=(-2, 2), x2_range=(-1, 3), title=\"Rosenbrock Function\", x1_point=-1, x2_point=1)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef plot_function(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    x1 = np.linspace(x1_range[0], x1_range[1], 400)\n    x2 = np.linspace(x2_range[0], x2_range[1], 400)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n\n    fig = plt.figure(figsize=(14, 6))\n\n    # 3D plot\n    ax1 = fig.add_subplot(121, projection='3d')\n    # Primero dibujamos la superficie\n    surface = ax1.plot_surface(X1, X2, Z, cmap='viridis', alpha=0.7)\n    \n    # Luego dibujamos el punto\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        ax1.scatter(x1_point, x2_point, z_point, color='red', s=100, depthshade=False, linewidth=2, edgecolor='black')\n    \n    ax1.set_title(f'3D Plot of {title}')\n    ax1.set_xlabel('X1')\n    ax1.set_ylabel('X2')\n    ax1.set_zlabel('Z')\n\n\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndef plot_function_3d(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n    # Create the mesh grid\n    x1 = np.linspace(x1_range[0], x1_range[1], 100)\n    x2 = np.linspace(x2_range[0], x2_range[1], 100)\n    X1, X2 = np.meshgrid(x1, x2)\n    Z = f(X1, X2)\n    \n    # Create subplots\n    fig = make_subplots(\n        rows=1, cols=2,\n        specs=[[{'type': 'surface'}, {'type': 'contour'}]],\n        subplot_titles=('3D Surface Plot', 'Contour Plot')\n    )\n    \n    # Add surface plot\n    fig.add_trace(\n        go.Surface(x=X1, y=X2, z=Z, colorscale='viridis', opacity=0.8),\n        row=1, col=1\n    )\n    \n    # Add point if specified\n    if x1_point is not None and x2_point is not None:\n        z_point = f(x1_point, x2_point)\n        fig.add_trace(\n            go.Scatter3d(\n                x=[x1_point],\n                y=[x2_point],\n                z=[z_point],\n                mode='markers',\n                marker=dict(size=8, color='red'),\n                name='Point'\n            ),\n            row=1, col=1\n        )\n    \n    # Add contour plot\n    fig.add_trace(\n        go.Contour(\n            x=x1,\n            y=x2,\n            z=Z,\n            colorscale='viridis'\n        ),\n        row=1, col=2\n    )\n    \n    # Update layout\n    fig.update_layout(\n        title=title,\n        width=1200,\n        height=500,\n        scene=dict(\n            xaxis_title='X1',\n            yaxis_title='X2',\n            zaxis_title='Z'\n        )\n    )\n    \n    fig.show()\n\n# Test the function\ndef rosenbrock(x1, x2, a=1, b=100):\n    return (a - x1)**2 + b * (x2 - x1**2)**2\n\nplot_function_3d(rosenbrock, (-2, 2), (-1, 3), \"Rosenbrock Function\", x1_point=-1, x2_point=1)\n\nplot_function(rosenbrock, x1_range=(-5, 5), x2_range=(-5, 15), title=\"Rosenbrock Function\",x1_point=-1, x2_point=1)\n\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[64], line 2\n      1 import numpy as np\n----&gt; 2 import plotly.graph_objects as go\n      3 from plotly.subplots import make_subplots\n      5 def plot_function_3d(f, x1_range, x2_range, title=\"Function Plot\", x1_point=None, x2_point=None):\n      6     # Create the mesh grid\n\nModuleNotFoundError: No module named 'plotly'"
  },
  {
    "objectID": "posts/post-with-code/index.html#resultados",
    "href": "posts/post-with-code/index.html#resultados",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Resultados",
    "text": "Resultados"
  },
  {
    "objectID": "posts/post-with-code/index.html#conclusiones-y-comentarios",
    "href": "posts/post-with-code/index.html#conclusiones-y-comentarios",
    "title": "Primer trabajo: Optimización heurística",
    "section": "Conclusiones y comentarios",
    "text": "Conclusiones y comentarios\n\nTareas:\n\nEscoja dos funciones de prueba.\nOptimización con método de descenso por gradiente:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando un método de descenso por gradiente con condición inicial aleatoria.\n\nOptimización con métodos heurísticos:\n\nOptimice las funciones seleccionadas en dos y tres dimensiones usando:\n\nAlgoritmos evolutivos.\nOptimización de partículas.\nEvolución diferencial.\n\n\nRepresentación visual:\n\nCree un GIF animado o un video que muestre el proceso de optimización usando:\n\nDescenso por gradiente.\nMétodos heurísticos.\n\n\n\n\n\nDiscusión:\nReflexione sobre los siguientes puntos: - ¿Qué aportaron los métodos de descenso por gradiente y qué aportaron los métodos heurísticos? - Para responder a esta pregunta, considere: - El valor final de la función objetivo. - El número de evaluaciones de la función objetivo. - Es posible que se requiera realizar varias corridas de los algoritmos para obtener conclusiones significativas."
  },
  {
    "objectID": "posts/post-with-code/index.html#agoritmo-genético",
    "href": "posts/post-with-code/index.html#agoritmo-genético",
    "title": "Métodos de optimización heurística",
    "section": "2.2 Agoritmo genético",
    "text": "2.2 Agoritmo genético\nUn algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la selección natural y la evolución biológica, propuesto inicialmente por (Holland 1975). Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n\n2.2.1 Concepto General\nEl algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n\nSelección: Elegir individuos con mayor fitness.1\nCruce: Combinar soluciones para generar descendencia.\nMutación: Introducir variación genética.\n\nMatemáticamente, en un problema de minimización, el objetivo es encontrar:\n\\[ x^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) \\]\ndonde:\n\n\\(x\\) representa un individuo en el espacio de búsqueda.\n\\(f(x)\\) es la función objetivo que evalúa la calidad de \\(x\\).\n\nCada solución candidata se representa como un individuo, que puede ser un vector real o un cromosoma binario:\n\\[x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n\\]\nLa función objetivo mide qué tan buena es una solución:\n\\[\\text{Fitness}(x) = f(x)\\]\nPara problemas de minimización, menor \\(f(x)\\) implica mejor fitness.\n\n\n\n2.2.2 Etapas\nInicialización de la Población\nSe genera una población inicial de \\(P\\) individuos de forma aleatoria dentro de un intervalo \\([a, b]\\) :\n\\[x_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\}\\] donde:\n\n\\(x_{ij}\\) es la \\(j-ésima\\) coordenada del \\(i-ésimo\\) individuo.\n\n\n\nCode\n# Inicializar población\ndef initialize_population(size, dim, bounds):\n    return np.random.uniform(bounds[0], bounds[1], (size, dim))\n\n\n\nEvaluación del Fitness\nCada individuo de la población es evaluado usando la función objetivo:\n\\(\\text{Fitness}_i = f(x_i)\\)\n\n\nCode\n# Evaluar fitness\ndef evaluate_fitness(population,fitness_function):\n    return np.array([fitness_function(ind) for ind in population])\n\n\n\nSelección\nSe seleccionan individuos para reproducirse basándose en su fitness. Un métodos comune es el método de torneo, donde primero se seleccionan \\(k\\) individuos al azar y luego se elige al mejor de ellos(mejor fitness):\n\\[\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k\\]\n\n\nCode\n# Selección por torneo\ndef tournament_selection(population, fitness, k=3):\n    selected = []\n    for _ in range(len(population)):\n        candidates = np.random.choice(range(len(population)), k, replace=False)\n        winner = candidates[np.argmin(fitness[candidates])]\n        selected.append(population[winner])\n    return np.array(selected)\n\n\n\nCruce (Recombinación)\nDos individuos (padres) se combinan para generar descendencia. Un método común es punto de corte único, donde: 1. Se Elegie un punto de cruce aleatorio \\(k\\). 2. Se genera la descendencia mezclando las características de los padres.\n\\[\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:])\\]\n\\[\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:])\\]\nLa probabilidad de realizar un cruce está determinada por \\(p_c\\) (tasa de cruce).\n\n\nCode\n# Cruce\ndef crossover(parent1, parent2, crossover_rate):\n    if np.random.rand() &lt; crossover_rate:\n        point = np.random.randint(1, len(parent1))\n        child = np.concatenate([parent1[:point], parent2[point:]])\n        return child\n    return parent1 if np.random.rand() &lt; 0.5 else parent2\n\n\n\nMutación\nSe introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad \\(p_m\\):\n\\[x_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta)\\]\ndonde:\n\n\\(\\Delta\\) es una perturbación aleatoria.\n\\(x_{ij}\\) se restringe a los límites del problema.\n\n\n\nCode\n# Mutación\ndef mutate(individual, bounds, mutation_rate, delta):\n    for i in range(len(individual)):\n        if np.random.rand() &lt; mutation_rate:\n            individual[i] += np.random.uniform(-delta, delta)\n            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n    return individual\n\n\n\nEvaluación y Sustitución\nLa nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n\n\nCode\n# Algoritmo completo\ndef genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n    population = initialize_population(population_size, dim, bounds)\n    best_individual = None\n    trajectory = []\n    populations = []\n\n    for generation in range(generations):\n        populations.append(population.copy())\n        fitness = evaluate_fitness(population, fitness_function)\n        \n        if best_individual is None or np.min(fitness) &lt; fitness_function(best_individual):\n            best_individual = population[np.argmin(fitness)]\n        \n        # Guardar la mejor solución de esta generación\n        trajectory.append((*best_individual, fitness_function(best_individual)))\n        \n        # Selección\n        selected_population = tournament_selection(population, fitness)\n        \n        # Cruce y mutación\n        new_population = []\n        for i in range(0, len(selected_population), 2):\n            if i + 1 &lt; len(selected_population):\n                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n                new_population.extend([child1, child2])\n            else:\n                new_population.append(selected_population[i])\n        \n        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n    \n    # Convertir la trayectoria a DataFrame\n    \n    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n    df = pd.DataFrame(trajectory, columns=columns)\n    return best_individual, fitness_function(best_individual), df, populations\n\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\nLos algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: Exploración, que consiste en descubrir nuevas regiones del espacio de búsqueda, y Explotación, enfocada en refinar y mejorar las soluciones existentes.\nPara las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación \\(\\delta\\) se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n\n\n2.2.3 Observaciones\nVentajas:\n\nNo requiere derivadas ni condiciones específicas en $$$f(x)$ .\nEs efectivo en espacios de búsqueda multimodales o no convexos.\nAdaptable a diversos problemas.\n\nDesventajas:\n\nPuede ser computacionalmente costoso.\nNo garantiza convergencia al óptimo global.\nRequiere ajuste cuidadoso de parámetros."
  },
  {
    "objectID": "posts/post-with-code/index.html#footnotes",
    "href": "posts/post-with-code/index.html#footnotes",
    "title": "Métodos de optimización heurística",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl fitness representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.↩︎"
  },
  {
    "objectID": "posts/post-with-code/index.html#optimización-por-descenso-del-gradiente",
    "href": "posts/post-with-code/index.html#optimización-por-descenso-del-gradiente",
    "title": "Métodos de optimización heurística",
    "section": "2.1 Optimización por descenso del gradiente",
    "text": "2.1 Optimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nSegun (Bishop 2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla:\n\\[ x_{t+1} = x_t - \\eta \\nabla f(x_t) \\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable: \\[\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. (Bishop 2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como:\n\\[ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\]\n\\[ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\n\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/post-with-code/index.html#optimización-de-partículas",
    "href": "posts/post-with-code/index.html#optimización-de-partículas",
    "title": "Métodos de optimización heurística",
    "section": "2.3 Optimización de partículas",
    "text": "2.3 Optimización de partículas\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]"
  },
  {
    "objectID": "posts/post-with-code/index.html#optimización-diferencial",
    "href": "posts/post-with-code/index.html#optimización-diferencial",
    "title": "Métodos de optimización heurística",
    "section": "2.4 Optimización diferencial",
    "text": "2.4 Optimización diferencial"
  },
  {
    "objectID": "posts/post-with-code/index.html#solución-de-las-tareas-propuestas",
    "href": "posts/post-with-code/index.html#solución-de-las-tareas-propuestas",
    "title": "Métodos de optimización heurística",
    "section": "5.2 Solución de las tareas propuestas",
    "text": "5.2 Solución de las tareas propuestas\n\n5.2.1 Extracción de datos\nPara empezar a solucionar el problema, es necesario obtener información acerca del valor del salario del vendedor, el costo de los peajes y el cálculo correspondiente al costo total destinado a combustible; definiendo entonces el modelo de automóvil a considerar en el ejercicio, junto con su respectivo costo de gasolina. Durante el desarrollo de este proceso de extracción de información se tomaron como referencia las ciudades capitales de cada uno de los estados mexicanos y se observó el mapa de la división política de México en sus 32 estados, a fin de tener un mejor entendimiento de la región.\nFigura 1.\nMapa de México.  Nota. El mapa representa cada una de las ciudades capitales del país. Adaptado de Fondo plano de mapa de méxico [Ilustración], por Freepik, 2024, Freepik (https://www.freepik.es/vector-gratis/mapa-mexico). Licencia gratuita.\n\n5.2.1.1 Distancias y tiempo de conducción\nLa tabla de distancias y tiempo de conducción entre las ciudades fue obtenida a través del sitio web (mejoresrutas2024?), diseñado especialmente para el cálculo y planeación de viajes a lo largo de todo el país. Dicho recurso online permite obtener información como distancias, tiempo de conducción y otros valores asociados entre dos ciudades ingresando el nombre de cada una de ellas.\n\n\n5.2.1.2 Peajes\nPara obtener la información de los peajes, fue utilizado el mismo sitio web (mejoresrutas2024?), el cual también contiene datos relacionados con el costo actual de los peajes que se encuentran entre las ciudades donde se realiza la consulta.\nDebido al gran número de combinaciones posibles, se programó un bot en Python empleando la librería Beautiful Soup, lo que permitió automatizar la extracción de la información anteriormente mencionada. En el repositorio en GitHub es posible encontrar el archivo con el código para llevar a cabo esta tarea.\n\n\n\n5.2.2 Definición de gastos\nEn la siguiente sección se definen los gastos que deben ser consultados, entre los cuales se encuentran el salario del vendedor, el modelo de automóvil a utilizar y su correspondiente gasto de combustible.\n\n5.2.2.1 Salario del vendedor\nPara definir el salario del vendedor, se toma como referencia el salario minimo en México, que actualmente se encuentra en 248,93 pesos diarios según la (conasami2024?); por lo tanto, para una jornada de 8 horas, el salario mínimo por hora es de 31,12 aproximadamente. Dicho esto, se decide establecer un salario de 35 pesos mexicanos por hora para el vendedor del presente ejercicio.\n\n\n5.2.2.2 Modelo del carro y gasto en gasolina\nDe acuerdo con (elpais2024?), el modelo de automóvil más vendido actualmente en México es el Nissan Versa, por lo que se ha considerado conveniente seleccionarlo como medio de transporte a utilizar por parte del vendedor. Esto permitirá hacer una estimación más justa del costo total de realizar la ruta por los 32 estados mexicanos en el contexto de dicho país.\nAdicionalmente, es importante considerar que el rendimiento promedio de este modelo en carreteras es de 25 kilómetros por litro de acuerdo con información proporcionada por (nissanversarendimiento2023?) y que el tipo de gasolina que utiliza es la comúnmente denominada como “Gasolina Magna” en México la cual, al día 14 de noviembre, tiene un precio promedio de 23.96 pesos mexicanos por litro según (gasolinamx2024?).\n\n\n5.2.2.3 Transformaciones\nSe ha obtenido la información anterior con el objetivo de calcular el costo total de desplazamiento entre las ciudades capitales de México, sin embargo, se observa que no todos los datos se encuentran en las unidades requeridas (MXN): hay magnitudes en litros, horas, kilómetros, etc. Por lo tanto, se realizarán las siguientes transformaciones en todas las unidades para poder sumar dichos gastos en pesos mexicanos, a diferencia del caso de los peajes, pues estos ya se encuentran en la unidad monetaria deseada.\n\n5.2.2.3.1 Tiempo de viaje\nEl costo por el salario del vendedor es calculado la forma que se muestra en la Ecuación (1):\n\\[\n\\text{Costo\\_vendedor} = \\text{tiempo} \\times \\text{salario\\_del\\_vendedor} \\tag{1}\n\\]\n\n\n\n5.2.2.4 Gasolina para el viaje\nEl gasto total en gasolina se obtiene con la fórmula mostrada en la Ecuación (2):\n\\[\n\\text{Costo\\_gasolina} = \\left( \\frac{\\text{Distancia}}{\\text{Rendimiento (km/litro)}} \\right) \\times \\text{Precio\\_por\\_litro} \\tag{2}\n\\]\n\n5.2.2.4.1 Gasto total\nDespués de realizar las operaciones mostradas anteriormente, se tiene como resultado toda la información necesaria en las unidades requeridas para obtener un valor correspondiente al gasto total del viaje en pesos mexicanos, de acuerdo con lo definido en la Ecuación (3).\n\\[\n\\text{Gasto\\_recorrido} = \\text{Costo\\_gasolina} + \\text{Costo\\_vendedor} + \\text{Costo\\_Peajes} \\tag{3}\n\\]\n\n\n\n\n5.2.3 Ruta óptima\nA continuación, se procede con la utilización de los algoritmos propuestos para este caso: Colonia de Hormigas y Algoritmos Genéticos, con el fin de responder a la actividad planteada al principio del presente ejercicio, esto es, hallar la ruta óptima para el recorrido del vendedor a través de los 32 estados de México.\n\n5.2.3.1 Colonia de Hormigas\nConsiderando la información recolectada en (acowikipedia2024?) y (acobook2018?) y lo presentado en la primera sección del trabajo, puede decirse que los algoritmos de colonia de hormigas (Ant Colony Optimization, ACO) son una técnica de optimización basada en la inteligencia colectiva observada en las colonias de hormigas naturales. Fueron inspirados en el comportamiento de las hormigas en la naturaleza para resolver problemas complejos de optimización combinatoria, en esta segunda parte del trabajo profundizaremos más en sus hiperparámetros claves los cuales son:\n\nCantidad de hormigas: Cantidad de hormigas que participarán en cada iteración de la búsqueda de soluciones. Influye en la capacidad del algoritmo de explorar diferentes soluciones de manera simultánea. En este caso se utilizarán 32 hormigas, es decir, igual al número de estados en México.\nAlpha: Controla la influencia de la feromona en la probabilidad de que una hormiga elija ese camino. A medida que el valor aumenta, las hormigas son más propensas a seguir caminos con más feromona. Aquí se utilizará un valor de 1 para otorgar una influencia moderada de las feromonas depositadas.\nBeta: Controla la preferencia de las hormigas por caminos más “baratos” o prometedores, lo cual ayuda aumentar la exploración. Se va a considerar un valor de 2, puesto que se busca minimizar el costo del viaje\n\\(\\rho\\): Indica la tasa de evaporación de la feromona, lo cual evita que las soluciones previas influencien las iteraciones futuras. Se seleccionó una tasa de evaporación del 0.5, es decir, el 50% de las feromonas se evaporan en cada iteración.\n\\(Q\\): Cantidad de feromona depositada por una hormiga en su recorrido tras encontrar una solución. Se utilizará un valor de 100 para indicar la cantidad de feromonas en el camino.\n\nUna vez definidos los hiperparámetros, se puede continuar con la ejecución del algoritmo de colonia de hormigas, cuyo detalle se puede observar más a profundidad en el repositorio de GitHub. En la Figura 2 se puede observar cómo va variando el costo de realizar el viaje en cada una de las iteraciones que realizó dicho algoritmo.\nFigura 2.\nFunción costo del algoritmo Colonia de Hormigas.  Nota. La gráfica muestra la evolución del costo total del viaje a medida que se ejecutan las diferentes iteraciones del algoritmo, que para este caso fueron 500. Elaboración propia.\nDe acuerdo con la imagen anterior, es posible observar que el costo mínimo se alcanza relativamente rápido, antes de las 100 iteraciones. En este sentido, también es interesante notar que el cálculo de esta función de costo varía al considerar diferentes variaciones que puedan realizarse sobre el planteamiento inicial del problema, comportamiento que se verá más adelante.\nPosteriormente, en la Figura 3 puede verse la ruta óptima encontrada por el algoritmo de colonia de hormigas para que el vendedor pueda recorrer los 32 estados mexicanos.\nFigura 3.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas.  Nota. Puede observarse que esta visualización gráfica está dada por líneas rectas entre cada una de las ciudades y no muestra con fidelidad la forma en que se haría el recrorrido. Elaboración propia.\nCon el fin de que el camino óptimo pueda reflejar la realidad del viaje, en la Figura 4 se ilustra la utilización de la API gratuita Open Route Service para graficar el recorrido propuesto a lo largo de las carreteras en el mapa de México. La API key para acceder a este servicio es la siguiente:\n\n\nCode\napi_key = \"5b3ce3597851110001cf6248c140bc578aac4c2d95295dc798e53a22\"\n\n\nFigura 4.\nForma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas.  Nota. El gráfico muestra las carreteras que deberían seguirse para completar el recorrido propuesto, sin embargo, algunos aspectos siguen siendo siendo interesantes. Elaboración propia.\nComo se mencionó anteriormente, de esta forma se obtiene una ruta óptima más realista. No obstante, llama la atención que, en ciertas secciones, la ruta implica cruzar cuerpos de agua. Al investigar las razones de este comportamiento, se descubrió que para conectar algunos estados del país como Baja California Sur y Sinaloa, la opción de tomar un ferri es considerada la más conveniente según servicios de planificación de trayectos como (mejoresrutasferri2024?) y (bajaferries2024?).\nDado que la matriz de costos actual no considera el valor asociado al uso del ferri ni los gastos asociados al transporte del vehículo para continuar posteriormente el recorrido, se propone un análisis de los siguientes escenarios:\n\nIncluir el costo del ferri en la matriz de costos y evaluar la ruta resultante.\nRealizar el viaje completamente por tierra, excluyendo los estados que se alcanzan únicamente utilizando el ferri.\n\nPrimer escenario\nSe consultó el valor del tiquete de ferri para una persona adulta y el costo del transporte de un automóvil, encontrando que el más económico para un adulto es de 1,460 pesos mexicanos, mientras que el transporte del automóvil tiene un valor de 5,480 pesos mexicanos según (debate2023?).\nEstos costos fueron utilizados como parámetros para el algoritmo de colonia de hormigas, llegando a que, como se observa en la Figura 5, el algoritmo sigue alcanzando un mínimo de manera relativamente rápida.\nFigura 5.\nEvolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri.  Nota. Es interesante notar que, a pesar del incremento en el costo de moverse entre dos estados (debido al ferri), el algoritmo logró encontrar una ruta más barata que la hallada originalmente. Esto sugiere que en la primera solución encontrada el algoritmo podría haberse quedado atascado en un mínimo local debido a la falta de iteraciones. Elaboración propia.\nAdemás, también es posible observar que el tiempo y la distancia se redujeron en esta nueva solución, lo cual permite pensar que esta ruta no solo es más económica, sino también más eficiente, a pesar de que está considerando el costo adicional del ferri y el transporte del vehículo.\nLos resultados correspondientes a la visualización gráfica del camino óptimo encontrado para el vendedor en este escenario pueden observarse a continuación, en las Figuras 6 y 7.\nFigura 6.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri. . Nota. Las observaciones respecto a la forma en que se conectan los distintos puntos del recorrido permanecen iguales que en el caso considerado originalmente. Elaboración propia.\nFigura 7.\nCarreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas.  Nota. Esta imagen también fue generada por medio del uso de la API gratuita, así que sus resultados son reproducibles. Elaboración propia.\nSegundo escenario\nEn este segundo escenario, la ciudad de La Paz fue eliminada del recorrido, por lo que el viaje ahora solo incluye los 31 estados restantes. En consecuencia, también se redujo la cantidad de hormigas utilizadas en el algoritmo a un valor de 31, asignando una hormiga por estado para realizar la búsqueda.\nComo era de esperarse, el precio del recorrido se redujo en este caso. Sin embargo, al algoritmo le tomó muchas más iteraciones encontrar el costo mínimo, como se observa en la Figura 8.\nFigura 8.\nEvolución de la función costo para los 31 estados de México.  Nota. El hecho de que el planteamiento inicial de ciudades y estados a recorrer cambiara al no tener en cuenta el estado que solamente puede ser conectado vía marítima fue un factor determinante en la ejecución del algoritmo de hormigas, siendo mucho menos rápido que en el primer escenario (incluso que en el escenario original). Elaboración propia.\nA diferencia del caso anterior, la Figura 8 también muestra que la distancia y el tiempo aumentaron. Esto se debe a que, al no utilizar el ferri, el automóvil tuvo que realizar un recorrido más largo en ciertas partes para completar su ruta. Por lo tanto, aunque esta solución es más eficiente en términos de costo, no lo es en términos de tiempo y distancia recorrida.\nLa visualización gráfica de los resultados obtenidos para este caso pueden observarse en las Figuras 9 y 10, teniendo en cuenta las mismas consideraciones anteriormente mencionadas.\nFigura 9.\nRuta óptima encontrada mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Elaboración propia.\nFigura 10.\nOrden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Nota. Sumado a los inconvenientes observados en este escenario, al desconectar uno de los estados de México, puede observarse que una gran región del país queda excluida del recorrido del vendedor, lo que puede implicar significativas pérdidas económicas y oportunidades de establecer nuevos negocios.\n\n\n5.2.3.2 Algoritmo genético\nDe acuerdo con información proporcionada por (tesisga2009?) y encontrada en (gawikipedia2024?), y como se explico en la primera sección del trabajo, puede decirse que los algoritmos genéticos (Genetic Algorithms, GA) son una técnica de optimización inspirada en los principios de la selección natural y la evolución biológica. Los GA buscan soluciones óptimas mediante la creación, evaluación y modificación de una población de individuos, representando posibles soluciones a un problema dado. La evolución de la población se realiza mediante operadores genéticos como la mutación y en esta sección profundizaremos más en sus hiperparámetros clave, los cuales son:\n\nTamaño de la población: Define el número de individuos en cada generación. Un tamaño de población más grande permite una mejor exploración del espacio de soluciones, pero también aumenta el tiempo de cómputo. En este caso, se utilizará una población de 100 individuos, lo que proporciona un equilibrio adecuado entre diversidad y eficiencia computacional.\nNúmero de generaciones: Especifica cuántas veces se evolucionará la población mediante el proceso de selección, cruce y mutación; se consideran adecuadas un total de 200 generaciones para permitir al algoritmo explorar el espacio de búsqueda y converger hacia una solución óptima o cercana al óptimo.\nTasa de mutación: Representa la probabilidad de que un gen sea modificado aleatoriamente en un individuo. La mutación introduce variación genética, lo que ayuda a explorar nuevas áreas del espacio de búsqueda y a evitar estancamientos en óptimos locales. Se empleará una tasa de mutación de 0.1 (10%), lo que mantiene una buena cantidad de diversidad sin perturbar excesivamente a la población.\n\nDe la misma manera en que se realizó en la sección anterior, la presentación de resultados comienza con una obtención de resultados iniciales considerando los 32 estados de México y sin tener en cuenta el costo del ferri.\nComo se observa en la Figura 11, alcanzar el mínimo toma casi 175 generaciones, lo que indica que este algoritmo se demora más en llegar a un valor mínimo en comparación con el algoritmo de colonia de hormigas. Además, la solución que encuentra tiene un costo mayor y toma más tiempo y una mayor distancia completarla.\nFigura 11.\nEvolución de la función costo del algoritmo genético.  Nota. En la ejecución de este algoritmo, la solución óptima se encontró en una iteración muy cercana al límite máximo establecido, a diferencia del algoritmo de colonia de hormigas, que lo realizó muy rápidamente. Elaboración propia.\nAhora bien, en las Figuras 12 y 13 se tiene la visualización gráfica del recorrido propuesto por este algoritmo, siguiendo los mismos procedimientos de utilización de la API que se mencionaron de manera previa.\nFigura 12.\nRuta óptima encontrada mediante algoritmo genético.  Elaboración propia.\nFigura 13.\nRuta óptima con las carreteras encontrada mediante algoritmo genético.  Elaboración propia.\nNuevamente, se considera pertinente considerar los dos escenarios adicionales de análisis: un nuevo cálculo de costos teniendo en cuenta el tiquete de ferri y el transporte adicional para el automóvil y la exclusión La Paz, como territorio que solo puede conectarse a través de cuerpos de agua.\nPrimer escenario\nEs posible observar que al tomar en cuenta el costo del ferri, en este caso sí se aumenta el costo del camino óptimo y el número de iteraciones se reduce un poco, como puede verse en la Figura 14. Sin embargo, el tiempo que toma completar esta ruta es mucho más alto que en el caso anterior, lo que podría indicar que esta solución se quedó atrapada en un mínimo local.\nFigura 14.\nEvolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri.  Elaboración propia.\nPor otra parte, en las Figuras 15 y 16 se puede observar el recorrido propuesto por esta solución del algoritmo para que el vendedor se desplace por todo el país, viendo que los puntos de inicio y finalización son diferentes a los que había arrojado como resultado el algoritmo de colonia de hormigas.\nFigura 15.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri.  Nota. Sabiendo que la ruta marítima que seleccionaron ambos algoritmos es la misma, puede decirse que las diferencias entre sus resultados radican en otros aspectos inherentes a su propia definición, como pueden serlo los hiperparámetros y la forma en que realizan una búsqueda de la solución óptima. Elaboración propia.\nFigura 16.\nRuta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri.  Nota. La utilización de la API se dio exactamente igual que en los escenarios anteriores, de manera que estos resultados también son reproducibles.\nSegundo escenario\nEn este último escenario, el cual solamente considera 31 de los estados de México, es posible notar que el costo óptimo nuevamente bajó y, a diferencia del algoritmo de colonia de hormigas, el algoritmo genético sí encuentra una forma de reducir el tiempo y la distancia del recorrido, mostrando una mejoría en ese aspecto.\nDe acuerdo con la Figura 17, en este escenario el algoritmo genético necesitó más iteraciones para encontrar un mínimo, lo cual se ve compensado por el hecho de que mejoró el desempeño del algoritmo de colonia de hormigas en términos de las variables anteriormente mencionadas.\nFigura 17.\nEvolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México.  Elaboración propia.\nFinalmente, las Figuras 18 y 19 permiten observar el recorrido que debería realizar el vendedor de acuerdo con este escenario propuesto, en el que también queda aislada una amplia región del país debido a la decisión de no considerar recorridos que no fueran terrestres.\nFigura 18.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México.  Elaboración propia.\nFigura 19.\nRuta óptima de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México.  Nota. Al observar las carreteras que debería recorrer esta solución, puede observarse que el vendedor terminaría pasando por los mismos caminos varias veces, ya que deben darse varios recorridos de manera repetida por la necesidad de conectar algunos territorios de los 31 estados sin contemplar la opción del viaje en ferri. Elaboración propia.\n\n\n\n5.2.4 Verificación de la calidad de la solución\nEs importante evaluar qué tan buena es la solución alcanzada. Métodos exhaustivos como la fuerza bruta, que permiten comprobar cuál es la mejor solución entre todas las posibles, resultan computacionalmente inviables en este caso. Aprovechando que disponemos de un gran número de iteraciones y tres diferentes escenarios que nos permiten variar las condiciones del problema, podemos concluir que la solución obtenida es, al menos, razonablemente buena.\nAdemás, es relevante analizar el comportamiento de las funciones de costo. En todos los escenarios se observa que el costo se reduce significativamente al principio y luego comienza a fluctuar alrededor de una media estable. Esto indica que el algoritmo está convergiendo hacia esos valores. A partir de este comportamiento, seleccionamos la solución con el menor costo como la mejor alternativa.\nEn general, las funciones de costo tienden a estabilizarse dentro de un rango limitado de valores. Este patrón nos permite confiar en que las soluciones obtenidas se encuentran entre las mejores posibles, considerando las limitaciones inherentes a los métodos no determinísticos.\n\n\n5.2.5 Discusión de los resultados\nLos resultados obtenidos al aplicar el Algoritmo de Colonia de Hormigas y el Algoritmo Genético en tres situaciones diferentes permiten destacar las fortalezas y diferencias de cada uno. Por un lado, el Algoritmo de Colonia de Hormigas logra encontrar una solución más económica y en un menor número de iteraciones en comparación con el Algoritmo Genético. Por lo tanto, en esta evaluación específica, dicho algoritmo puede considerarse más eficiente para resolver el problema en esta situación particular.\nNo obstante, es importante señalar que la elección del algoritmo adecuado depende en gran medida de la naturaleza del problema. Incluso para un mismo problema, diferentes enfoques pueden llevar a variaciones significativas en los resultados, como se observó en este análisis. Aunque en este caso el Algoritmo de Colonia de Hormigas demostró ser más eficiente que el Algoritmo Genético, esta ventaja es altamente circunstancial y no necesariamente aplicable a todos los contextos. Esto refuerza la importancia de adaptar la metodología a las características específicas del problema a resolver."
  },
  {
    "objectID": "posts/welcome/index.html#qué-encontrarás-aquí",
    "href": "posts/welcome/index.html#qué-encontrarás-aquí",
    "title": "!Bienvenido a nuestro blog!",
    "section": "",
    "text": "Trabajos del curso: Proyectos que exploran desde el funcionamiento básico de redes neuronales hasta implementaciones más avanzadas de algoritmos bioinspirados, como los basados en evolución genética o el comportamiento de colonias de hormigas.\nArtículos educativos: Explicaciones claras y prácticas sobre conceptos clave de inteligencia artificial y sus aplicaciones.\nRecursos reproducibles: Todo lo que publico está diseñado para ser reutilizable y comprensible, buscando contribuir al aprendizaje de otros."
  },
  {
    "objectID": "posts/welcome/index.html#por-qué-este-blog",
    "href": "posts/welcome/index.html#por-qué-este-blog",
    "title": "!Bienvenido a nuestro blog!",
    "section": "",
    "text": "La idea de este blog no solo es mostrar lo aprendido, sino también convertirlo en un material accesible y de calidad para otros. Crear contenido reproducible y útil puede ser un puente hacia el aprendizaje compartido, la inspiración y la mejora continua.\nAdemás, quieremos que este espacio sea un ejemplo de cómo construir un portafolio profesional que combine el rigor técnico con un diseño atractivo. Esto puede ser útil tanto para la comunidad académica como para el ámbito profesional."
  },
  {
    "objectID": "posts/welcome/index.html#qué-puedes-hacer-ahora",
    "href": "posts/welcome/index.html#qué-puedes-hacer-ahora",
    "title": "Bienvenidos a nuestro blog",
    "section": "¿Qué puedes hacer ahora? 🎯",
    "text": "¿Qué puedes hacer ahora? 🎯\n\n📖 Explora los artículos: Hay algo para cada nivel, desde principiantes hasta profesionales.\n🗨️ Comenta y comparte: Tus ideas y retroalimentación son siempre bienvenidas. ¡Hagamos comunidad! 💬\n📬 Síguenos: Mantente al día con nuevo contenido. ¡Esto apenas empieza! 😉"
  },
  {
    "objectID": "posts/welcome/index.html#sobre-el-autor-tú",
    "href": "posts/welcome/index.html#sobre-el-autor-tú",
    "title": "Bienvenidos a nuestro blog",
    "section": "Sobre el autor… tú 😉",
    "text": "Sobre el autor… tú 😉\nEste blog es tan especial porque refleja no solo el conocimiento técnico, sino también el esfuerzo creativo de sus autores. Si estás aquí, ¡felicidades! Eres parte de una comunidad que se atreve a soñar en grande, explorar lo desconocido y aprender constantemente. 🌈\nGracias por unirte a este viaje. ¡Vamos a construir juntos algo extraordinario!"
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html",
    "href": "posts/optimación_combinatoria/index.html",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport io\nfrom PIL import Image"
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#optimización-por-descenso-del-gradiente",
    "href": "posts/optimación_combinatoria/index.html#optimización-por-descenso-del-gradiente",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "2.1 Optimización por descenso del gradiente",
    "text": "2.1 Optimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nSegun (Bishop 2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla:\n\\[ x_{t+1} = x_t - \\eta \\nabla f(x_t) \\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable: \\[\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. (Bishop 2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como:\n\\[ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\]\n\\[ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\n\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#agoritmo-genético",
    "href": "posts/optimación_combinatoria/index.html#agoritmo-genético",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "2.2 Agoritmo genético",
    "text": "2.2 Agoritmo genético\nUn algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la selección natural y la evolución biológica, propuesto inicialmente por (Holland 1975). Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n\n2.2.1 Concepto General\nEl algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n\nSelección: Elegir individuos con mayor fitness.1\nCruce: Combinar soluciones para generar descendencia.\nMutación: Introducir variación genética.\n\nMatemáticamente, en un problema de minimización, el objetivo es encontrar:\n\\[ x^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) \\]\ndonde:\n\n\\(x\\) representa un individuo en el espacio de búsqueda.\n\\(f(x)\\) es la función objetivo que evalúa la calidad de \\(x\\).\n\nCada solución candidata se representa como un individuo, que puede ser un vector real o un cromosoma binario:\n\\[x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n\\]\nLa función objetivo mide qué tan buena es una solución:\n\\[\\text{Fitness}(x) = f(x)\\]\nPara problemas de minimización, menor \\(f(x)\\) implica mejor fitness.\n\n\n\n2.2.2 Etapas\nInicialización de la Población\nSe genera una población inicial de \\(P\\) individuos de forma aleatoria dentro de un intervalo \\([a, b]\\) :\n\\[x_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\}\\] donde:\n\n\\(x_{ij}\\) es la \\(j-ésima\\) coordenada del \\(i-ésimo\\) individuo.\n\n\n\nCode\n# Inicializar población\ndef initialize_population(size, dim, bounds):\n    return np.random.uniform(bounds[0], bounds[1], (size, dim))\n\n\n\nEvaluación del Fitness\nCada individuo de la población es evaluado usando la función objetivo:\n\\(\\text{Fitness}_i = f(x_i)\\)\n\n\nCode\n# Evaluar fitness\ndef evaluate_fitness(population,fitness_function):\n    return np.array([fitness_function(ind) for ind in population])\n\n\n\nSelección\nSe seleccionan individuos para reproducirse basándose en su fitness. Un métodos comune es el método de torneo, donde primero se seleccionan \\(k\\) individuos al azar y luego se elige al mejor de ellos(mejor fitness):\n\\[\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k\\]\n\n\nCode\n# Selección por torneo\ndef tournament_selection(population, fitness, k=3):\n    selected = []\n    for _ in range(len(population)):\n        candidates = np.random.choice(range(len(population)), k, replace=False)\n        winner = candidates[np.argmin(fitness[candidates])]\n        selected.append(population[winner])\n    return np.array(selected)\n\n\n\nCruce (Recombinación)\nDos individuos (padres) se combinan para generar descendencia. Un método común es punto de corte único, donde: 1. Se Elegie un punto de cruce aleatorio \\(k\\). 2. Se genera la descendencia mezclando las características de los padres.\n\\[\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:])\\]\n\\[\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:])\\]\nLa probabilidad de realizar un cruce está determinada por \\(p_c\\) (tasa de cruce).\n\n\nCode\n# Cruce\ndef crossover(parent1, parent2, crossover_rate):\n    if np.random.rand() &lt; crossover_rate:\n        point = np.random.randint(1, len(parent1))\n        child = np.concatenate([parent1[:point], parent2[point:]])\n        return child\n    return parent1 if np.random.rand() &lt; 0.5 else parent2\n\n\n\nMutación\nSe introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad \\(p_m\\):\n\\[x_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta)\\]\ndonde:\n\n\\(\\Delta\\) es una perturbación aleatoria.\n\\(x_{ij}\\) se restringe a los límites del problema.\n\n\n\nCode\n# Mutación\ndef mutate(individual, bounds, mutation_rate, delta):\n    for i in range(len(individual)):\n        if np.random.rand() &lt; mutation_rate:\n            individual[i] += np.random.uniform(-delta, delta)\n            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n    return individual\n\n\n\nEvaluación y Sustitución\nLa nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n\n\nCode\n# Algoritmo completo\ndef genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n    population = initialize_population(population_size, dim, bounds)\n    best_individual = None\n    trajectory = []\n    populations = []\n\n    for generation in range(generations):\n        populations.append(population.copy())\n        fitness = evaluate_fitness(population, fitness_function)\n        \n        if best_individual is None or np.min(fitness) &lt; fitness_function(best_individual):\n            best_individual = population[np.argmin(fitness)]\n        \n        # Guardar la mejor solución de esta generación\n        trajectory.append((*best_individual, fitness_function(best_individual)))\n        \n        # Selección\n        selected_population = tournament_selection(population, fitness)\n        \n        # Cruce y mutación\n        new_population = []\n        for i in range(0, len(selected_population), 2):\n            if i + 1 &lt; len(selected_population):\n                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n                new_population.extend([child1, child2])\n            else:\n                new_population.append(selected_population[i])\n        \n        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n    \n    # Convertir la trayectoria a DataFrame\n    \n    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n    df = pd.DataFrame(trajectory, columns=columns)\n    return best_individual, fitness_function(best_individual), df, populations\n\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\nLos algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: Exploración, que consiste en descubrir nuevas regiones del espacio de búsqueda, y Explotación, enfocada en refinar y mejorar las soluciones existentes.\nPara las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación \\(\\delta\\) se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n\n\n2.2.3 Observaciones\nVentajas:\n\nNo requiere derivadas ni condiciones específicas en $$$f(x)$ .\nEs efectivo en espacios de búsqueda multimodales o no convexos.\nAdaptable a diversos problemas.\n\nDesventajas:\n\nPuede ser computacionalmente costoso.\nNo garantiza convergencia al óptimo global.\nRequiere ajuste cuidadoso de parámetros."
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#optimización-de-partículas",
    "href": "posts/optimación_combinatoria/index.html#optimización-de-partículas",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "2.3 Optimización de partículas",
    "text": "2.3 Optimización de partículas\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]"
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#optimización-diferencial",
    "href": "posts/optimación_combinatoria/index.html#optimización-diferencial",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "2.4 Optimización diferencial",
    "text": "2.4 Optimización diferencial"
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#problema-del-viajero",
    "href": "posts/optimación_combinatoria/index.html#problema-del-viajero",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "1.1 Problema del Viajero:",
    "text": "1.1 Problema del Viajero:\nUn vendedor debe realizar un recorrido por todas las capitales de los 32 estados de los Estados Unidos Mexicanos.\n\n1.1.1 Tareas:\n\nOptimización con métodos metaheurísticos:\n\nUtilice colonias de hormigas para encontrar el orden óptimo del recorrido.\nUtilice algoritmos genéticos para encontrar el orden óptimo del recorrido.\n\nCosto del recorrido:\n\nEl costo de desplazamiento entre ciudades se calcula como la suma de:\n\nEl valor de la hora del vendedor (este es un parámetro que debe estudiarse).\nEl costo de los peajes.\nEl costo del combustible.\n\nCada equipo debe definir el vehículo que utilizará el vendedor para realizar el recorrido y, con base en esta elección, calcular el costo del combustible.\n\n\n\n\n1.1.2 Representación Visual:\n\nCree un GIF animado o un video que muestre cómo se comporta la mejor solución encontrada, usando un gráfico del recorrido en el mapa de México.\n\n\n\n\n1.1.3 Discusión:\nReflexione sobre: - Los resultados obtenidos con las colonias de hormigas y los algoritmos genéticos. - Comparación de costos y tiempo de ejecución."
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#solución-de-las-tareas-propuestas",
    "href": "posts/optimación_combinatoria/index.html#solución-de-las-tareas-propuestas",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "1.2 Solución de las tareas propuestas",
    "text": "1.2 Solución de las tareas propuestas\n\n1.2.1 Extracción de datos\nPara empezar a solucionar el problema, es necesario obtener información acerca del valor del salario del vendedor, el costo de los peajes y el cálculo correspondiente al costo total destinado a combustible; definiendo entonces el modelo de automóvil a considerar en el ejercicio, junto con su respectivo costo de gasolina. Durante el desarrollo de este proceso de extracción de información se tomaron como referencia las ciudades capitales de cada uno de los estados mexicanos y se observó el mapa de la división política de México en sus 32 estados, a fin de tener un mejor entendimiento de la región.\nFigura 1.\nMapa de México.  Nota. El mapa representa cada una de las ciudades capitales del país. Adaptado de Fondo plano de mapa de méxico [Ilustración], por Freepik, 2024, Freepik (https://www.freepik.es/vector-gratis/mapa-mexico). Licencia gratuita.\n\n1.2.1.1 Distancias y tiempo de conducción\nLa tabla de distancias y tiempo de conducción entre las ciudades fue obtenida a través del sitio web (mejoresrutas2024?), diseñado especialmente para el cálculo y planeación de viajes a lo largo de todo el país. Dicho recurso online permite obtener información como distancias, tiempo de conducción y otros valores asociados entre dos ciudades ingresando el nombre de cada una de ellas.\n\n\n1.2.1.2 Peajes\nPara obtener la información de los peajes, fue utilizado el mismo sitio web (mejoresrutas2024?), el cual también contiene datos relacionados con el costo actual de los peajes que se encuentran entre las ciudades donde se realiza la consulta.\nDebido al gran número de combinaciones posibles, se programó un bot en Python empleando la librería Beautiful Soup, lo que permitió automatizar la extracción de la información anteriormente mencionada. En el repositorio en GitHub es posible encontrar el archivo con el código para llevar a cabo esta tarea.\n\n\n\n1.2.2 Definición de gastos\nEn la siguiente sección se definen los gastos que deben ser consultados, entre los cuales se encuentran el salario del vendedor, el modelo de automóvil a utilizar y su correspondiente gasto de combustible.\n\n1.2.2.1 Salario del vendedor\nPara definir el salario del vendedor, se toma como referencia el salario minimo en México, que actualmente se encuentra en 248,93 pesos diarios según la (conasami2024?); por lo tanto, para una jornada de 8 horas, el salario mínimo por hora es de 31,12 aproximadamente. Dicho esto, se decide establecer un salario de 35 pesos mexicanos por hora para el vendedor del presente ejercicio.\n\n\n1.2.2.2 Modelo del carro y gasto en gasolina\nDe acuerdo con (elpais2024?), el modelo de automóvil más vendido actualmente en México es el Nissan Versa, por lo que se ha considerado conveniente seleccionarlo como medio de transporte a utilizar por parte del vendedor. Esto permitirá hacer una estimación más justa del costo total de realizar la ruta por los 32 estados mexicanos en el contexto de dicho país.\nAdicionalmente, es importante considerar que el rendimiento promedio de este modelo en carreteras es de 25 kilómetros por litro de acuerdo con información proporcionada por (nissanversarendimiento2023?) y que el tipo de gasolina que utiliza es la comúnmente denominada como “Gasolina Magna” en México la cual, al día 14 de noviembre, tiene un precio promedio de 23.96 pesos mexicanos por litro según (gasolinamx2024?).\n\n\n1.2.2.3 Transformaciones\nSe ha obtenido la información anterior con el objetivo de calcular el costo total de desplazamiento entre las ciudades capitales de México, sin embargo, se observa que no todos los datos se encuentran en las unidades requeridas (MXN): hay magnitudes en litros, horas, kilómetros, etc. Por lo tanto, se realizarán las siguientes transformaciones en todas las unidades para poder sumar dichos gastos en pesos mexicanos, a diferencia del caso de los peajes, pues estos ya se encuentran en la unidad monetaria deseada.\n\n1.2.2.3.1 Tiempo de viaje\nEl costo por el salario del vendedor es calculado la forma que se muestra en la Ecuación (1):\n\\[\n\\text{Costo\\_vendedor} = \\text{tiempo} \\times \\text{salario\\_del\\_vendedor} \\tag{1}\n\\]\n\n\n\n1.2.2.4 Gasolina para el viaje\nEl gasto total en gasolina se obtiene con la fórmula mostrada en la Ecuación (2):\n\\[\n\\text{Costo\\_gasolina} = \\left( \\frac{\\text{Distancia}}{\\text{Rendimiento (km/litro)}} \\right) \\times \\text{Precio\\_por\\_litro} \\tag{2}\n\\]\n\n1.2.2.4.1 Gasto total\nDespués de realizar las operaciones mostradas anteriormente, se tiene como resultado toda la información necesaria en las unidades requeridas para obtener un valor correspondiente al gasto total del viaje en pesos mexicanos, de acuerdo con lo definido en la Ecuación (3).\n\\[\n\\text{Gasto\\_recorrido} = \\text{Costo\\_gasolina} + \\text{Costo\\_vendedor} + \\text{Costo\\_Peajes} \\tag{3}\n\\]\n\n\n\n\n1.2.3 Ruta óptima\nA continuación, se procede con la utilización de los algoritmos propuestos para este caso: Colonia de Hormigas y Algoritmos Genéticos, con el fin de responder a la actividad planteada al principio del presente ejercicio, esto es, hallar la ruta óptima para el recorrido del vendedor a través de los 32 estados de México.\n\n1.2.3.1 Colonia de Hormigas\nConsiderando la información recolectada en (acowikipedia2024?) y (acobook2018?) y lo presentado en la primera sección del trabajo, puede decirse que los algoritmos de colonia de hormigas (Ant Colony Optimization, ACO) son una técnica de optimización basada en la inteligencia colectiva observada en las colonias de hormigas naturales. Fueron inspirados en el comportamiento de las hormigas en la naturaleza para resolver problemas complejos de optimización combinatoria, en esta segunda parte del trabajo profundizaremos más en sus hiperparámetros claves los cuales son:\n\nCantidad de hormigas: Cantidad de hormigas que participarán en cada iteración de la búsqueda de soluciones. Influye en la capacidad del algoritmo de explorar diferentes soluciones de manera simultánea. En este caso se utilizarán 32 hormigas, es decir, igual al número de estados en México.\nAlpha: Controla la influencia de la feromona en la probabilidad de que una hormiga elija ese camino. A medida que el valor aumenta, las hormigas son más propensas a seguir caminos con más feromona. Aquí se utilizará un valor de 1 para otorgar una influencia moderada de las feromonas depositadas.\nBeta: Controla la preferencia de las hormigas por caminos más “baratos” o prometedores, lo cual ayuda aumentar la exploración. Se va a considerar un valor de 2, puesto que se busca minimizar el costo del viaje\n\\(\\rho\\): Indica la tasa de evaporación de la feromona, lo cual evita que las soluciones previas influencien las iteraciones futuras. Se seleccionó una tasa de evaporación del 0.5, es decir, el 50% de las feromonas se evaporan en cada iteración.\n\\(Q\\): Cantidad de feromona depositada por una hormiga en su recorrido tras encontrar una solución. Se utilizará un valor de 100 para indicar la cantidad de feromonas en el camino.\n\nUna vez definidos los hiperparámetros, se puede continuar con la ejecución del algoritmo de colonia de hormigas, cuyo detalle se puede observar más a profundidad en el repositorio de GitHub. En la Figura 2 se puede observar cómo va variando el costo de realizar el viaje en cada una de las iteraciones que realizó dicho algoritmo.\nFigura 2.\nFunción costo del algoritmo Colonia de Hormigas.  Nota. La gráfica muestra la evolución del costo total del viaje a medida que se ejecutan las diferentes iteraciones del algoritmo, que para este caso fueron 500. Elaboración propia.\nDe acuerdo con la imagen anterior, es posible observar que el costo mínimo se alcanza relativamente rápido, antes de las 100 iteraciones. En este sentido, también es interesante notar que el cálculo de esta función de costo varía al considerar diferentes variaciones que puedan realizarse sobre el planteamiento inicial del problema, comportamiento que se verá más adelante.\nPosteriormente, en la Figura 3 puede verse la ruta óptima encontrada por el algoritmo de colonia de hormigas para que el vendedor pueda recorrer los 32 estados mexicanos.\nFigura 3.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas.  Nota. Puede observarse que esta visualización gráfica está dada por líneas rectas entre cada una de las ciudades y no muestra con fidelidad la forma en que se haría el recrorrido. Elaboración propia.\nCon el fin de que el camino óptimo pueda reflejar la realidad del viaje, en la Figura 4 se ilustra la utilización de la API gratuita Open Route Service para graficar el recorrido propuesto a lo largo de las carreteras en el mapa de México. La API key para acceder a este servicio es la siguiente:\n\n\nCode\napi_key = \"5b3ce3597851110001cf6248c140bc578aac4c2d95295dc798e53a22\"\n\n\nFigura 4.\nForma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas.  Nota. El gráfico muestra las carreteras que deberían seguirse para completar el recorrido propuesto, sin embargo, algunos aspectos siguen siendo siendo interesantes. Elaboración propia.\nComo se mencionó anteriormente, de esta forma se obtiene una ruta óptima más realista. No obstante, llama la atención que, en ciertas secciones, la ruta implica cruzar cuerpos de agua. Al investigar las razones de este comportamiento, se descubrió que para conectar algunos estados del país como Baja California Sur y Sinaloa, la opción de tomar un ferri es considerada la más conveniente según servicios de planificación de trayectos como (mejoresrutasferri2024?) y (bajaferries2024?).\nDado que la matriz de costos actual no considera el valor asociado al uso del ferri ni los gastos asociados al transporte del vehículo para continuar posteriormente el recorrido, se propone un análisis de los siguientes escenarios:\n\nIncluir el costo del ferri en la matriz de costos y evaluar la ruta resultante.\nRealizar el viaje completamente por tierra, excluyendo los estados que se alcanzan únicamente utilizando el ferri.\n\nPrimer escenario\nSe consultó el valor del tiquete de ferri para una persona adulta y el costo del transporte de un automóvil, encontrando que el más económico para un adulto es de 1,460 pesos mexicanos, mientras que el transporte del automóvil tiene un valor de 5,480 pesos mexicanos según (debate2023?).\nEstos costos fueron utilizados como parámetros para el algoritmo de colonia de hormigas, llegando a que, como se observa en la Figura 5, el algoritmo sigue alcanzando un mínimo de manera relativamente rápida.\nFigura 5.\nEvolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri.  Nota. Es interesante notar que, a pesar del incremento en el costo de moverse entre dos estados (debido al ferri), el algoritmo logró encontrar una ruta más barata que la hallada originalmente. Esto sugiere que en la primera solución encontrada el algoritmo podría haberse quedado atascado en un mínimo local debido a la falta de iteraciones. Elaboración propia.\nAdemás, también es posible observar que el tiempo y la distancia se redujeron en esta nueva solución, lo cual permite pensar que esta ruta no solo es más económica, sino también más eficiente, a pesar de que está considerando el costo adicional del ferri y el transporte del vehículo.\nLos resultados correspondientes a la visualización gráfica del camino óptimo encontrado para el vendedor en este escenario pueden observarse a continuación, en las Figuras 6 y 7.\nFigura 6.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri. . Nota. Las observaciones respecto a la forma en que se conectan los distintos puntos del recorrido permanecen iguales que en el caso considerado originalmente. Elaboración propia.\nFigura 7.\nCarreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas.  Nota. Esta imagen también fue generada por medio del uso de la API gratuita, así que sus resultados son reproducibles. Elaboración propia.\nSegundo escenario\nEn este segundo escenario, la ciudad de La Paz fue eliminada del recorrido, por lo que el viaje ahora solo incluye los 31 estados restantes. En consecuencia, también se redujo la cantidad de hormigas utilizadas en el algoritmo a un valor de 31, asignando una hormiga por estado para realizar la búsqueda.\nComo era de esperarse, el precio del recorrido se redujo en este caso. Sin embargo, al algoritmo le tomó muchas más iteraciones encontrar el costo mínimo, como se observa en la Figura 8.\nFigura 8.\nEvolución de la función costo para los 31 estados de México.  Nota. El hecho de que el planteamiento inicial de ciudades y estados a recorrer cambiara al no tener en cuenta el estado que solamente puede ser conectado vía marítima fue un factor determinante en la ejecución del algoritmo de hormigas, siendo mucho menos rápido que en el primer escenario (incluso que en el escenario original). Elaboración propia.\nA diferencia del caso anterior, la Figura 8 también muestra que la distancia y el tiempo aumentaron. Esto se debe a que, al no utilizar el ferri, el automóvil tuvo que realizar un recorrido más largo en ciertas partes para completar su ruta. Por lo tanto, aunque esta solución es más eficiente en términos de costo, no lo es en términos de tiempo y distancia recorrida.\nLa visualización gráfica de los resultados obtenidos para este caso pueden observarse en las Figuras 9 y 10, teniendo en cuenta las mismas consideraciones anteriormente mencionadas.\nFigura 9.\nRuta óptima encontrada mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Elaboración propia.\nFigura 10.\nOrden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Nota. Sumado a los inconvenientes observados en este escenario, al desconectar uno de los estados de México, puede observarse que una gran región del país queda excluida del recorrido del vendedor, lo que puede implicar significativas pérdidas económicas y oportunidades de establecer nuevos negocios.\n\n\n1.2.3.2 Algoritmo genético\nDe acuerdo con información proporcionada por (tesisga2009?) y encontrada en (gawikipedia2024?), y como se explico en la primera sección del trabajo, puede decirse que los algoritmos genéticos (Genetic Algorithms, GA) son una técnica de optimización inspirada en los principios de la selección natural y la evolución biológica. Los GA buscan soluciones óptimas mediante la creación, evaluación y modificación de una población de individuos, representando posibles soluciones a un problema dado. La evolución de la población se realiza mediante operadores genéticos como la mutación y en esta sección profundizaremos más en sus hiperparámetros clave, los cuales son:\n\nTamaño de la población: Define el número de individuos en cada generación. Un tamaño de población más grande permite una mejor exploración del espacio de soluciones, pero también aumenta el tiempo de cómputo. En este caso, se utilizará una población de 100 individuos, lo que proporciona un equilibrio adecuado entre diversidad y eficiencia computacional.\nNúmero de generaciones: Especifica cuántas veces se evolucionará la población mediante el proceso de selección, cruce y mutación; se consideran adecuadas un total de 200 generaciones para permitir al algoritmo explorar el espacio de búsqueda y converger hacia una solución óptima o cercana al óptimo.\nTasa de mutación: Representa la probabilidad de que un gen sea modificado aleatoriamente en un individuo. La mutación introduce variación genética, lo que ayuda a explorar nuevas áreas del espacio de búsqueda y a evitar estancamientos en óptimos locales. Se empleará una tasa de mutación de 0.1 (10%), lo que mantiene una buena cantidad de diversidad sin perturbar excesivamente a la población.\n\nDe la misma manera en que se realizó en la sección anterior, la presentación de resultados comienza con una obtención de resultados iniciales considerando los 32 estados de México y sin tener en cuenta el costo del ferri.\nComo se observa en la Figura 11, alcanzar el mínimo toma casi 175 generaciones, lo que indica que este algoritmo se demora más en llegar a un valor mínimo en comparación con el algoritmo de colonia de hormigas. Además, la solución que encuentra tiene un costo mayor y toma más tiempo y una mayor distancia completarla.\nFigura 11.\nEvolución de la función costo del algoritmo genético.  Nota. En la ejecución de este algoritmo, la solución óptima se encontró en una iteración muy cercana al límite máximo establecido, a diferencia del algoritmo de colonia de hormigas, que lo realizó muy rápidamente. Elaboración propia.\nAhora bien, en las Figuras 12 y 13 se tiene la visualización gráfica del recorrido propuesto por este algoritmo, siguiendo los mismos procedimientos de utilización de la API que se mencionaron de manera previa.\nFigura 12.\nRuta óptima encontrada mediante algoritmo genético.  Elaboración propia.\nFigura 13.\nRuta óptima con las carreteras encontrada mediante algoritmo genético.  Elaboración propia.\nNuevamente, se considera pertinente considerar los dos escenarios adicionales de análisis: un nuevo cálculo de costos teniendo en cuenta el tiquete de ferri y el transporte adicional para el automóvil y la exclusión La Paz, como territorio que solo puede conectarse a través de cuerpos de agua.\nPrimer escenario\nEs posible observar que al tomar en cuenta el costo del ferri, en este caso sí se aumenta el costo del camino óptimo y el número de iteraciones se reduce un poco, como puede verse en la Figura 14. Sin embargo, el tiempo que toma completar esta ruta es mucho más alto que en el caso anterior, lo que podría indicar que esta solución se quedó atrapada en un mínimo local.\nFigura 14.\nEvolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri.  Elaboración propia.\nPor otra parte, en las Figuras 15 y 16 se puede observar el recorrido propuesto por esta solución del algoritmo para que el vendedor se desplace por todo el país, viendo que los puntos de inicio y finalización son diferentes a los que había arrojado como resultado el algoritmo de colonia de hormigas.\nFigura 15.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri.  Nota. Sabiendo que la ruta marítima que seleccionaron ambos algoritmos es la misma, puede decirse que las diferencias entre sus resultados radican en otros aspectos inherentes a su propia definición, como pueden serlo los hiperparámetros y la forma en que realizan una búsqueda de la solución óptima. Elaboración propia.\nFigura 16.\nRuta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri.  Nota. La utilización de la API se dio exactamente igual que en los escenarios anteriores, de manera que estos resultados también son reproducibles.\nSegundo escenario\nEn este último escenario, el cual solamente considera 31 de los estados de México, es posible notar que el costo óptimo nuevamente bajó y, a diferencia del algoritmo de colonia de hormigas, el algoritmo genético sí encuentra una forma de reducir el tiempo y la distancia del recorrido, mostrando una mejoría en ese aspecto.\nDe acuerdo con la Figura 17, en este escenario el algoritmo genético necesitó más iteraciones para encontrar un mínimo, lo cual se ve compensado por el hecho de que mejoró el desempeño del algoritmo de colonia de hormigas en términos de las variables anteriormente mencionadas.\nFigura 17.\nEvolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México.  Elaboración propia.\nFinalmente, las Figuras 18 y 19 permiten observar el recorrido que debería realizar el vendedor de acuerdo con este escenario propuesto, en el que también queda aislada una amplia región del país debido a la decisión de no considerar recorridos que no fueran terrestres.\nFigura 18.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México.  Elaboración propia.\nFigura 19.\nRuta óptima de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México.  Nota. Al observar las carreteras que debería recorrer esta solución, puede observarse que el vendedor terminaría pasando por los mismos caminos varias veces, ya que deben darse varios recorridos de manera repetida por la necesidad de conectar algunos territorios de los 31 estados sin contemplar la opción del viaje en ferri. Elaboración propia.\n\n\n\n1.2.4 Verificación de la calidad de la solución\nEs importante evaluar qué tan buena es la solución alcanzada. Métodos exhaustivos como la fuerza bruta, que permiten comprobar cuál es la mejor solución entre todas las posibles, resultan computacionalmente inviables en este caso. Aprovechando que disponemos de un gran número de iteraciones y tres diferentes escenarios que nos permiten variar las condiciones del problema, podemos concluir que la solución obtenida es, al menos, razonablemente buena.\nAdemás, es relevante analizar el comportamiento de las funciones de costo. En todos los escenarios se observa que el costo se reduce significativamente al principio y luego comienza a fluctuar alrededor de una media estable. Esto indica que el algoritmo está convergiendo hacia esos valores. A partir de este comportamiento, seleccionamos la solución con el menor costo como la mejor alternativa.\nEn general, las funciones de costo tienden a estabilizarse dentro de un rango limitado de valores. Este patrón nos permite confiar en que las soluciones obtenidas se encuentran entre las mejores posibles, considerando las limitaciones inherentes a los métodos no determinísticos.\n\n\n1.2.5 Discusión de los resultados\nLos resultados obtenidos al aplicar el Algoritmo de Colonia de Hormigas y el Algoritmo Genético en tres situaciones diferentes permiten destacar las fortalezas y diferencias de cada uno. Por un lado, el Algoritmo de Colonia de Hormigas logra encontrar una solución más económica y en un menor número de iteraciones en comparación con el Algoritmo Genético. Por lo tanto, en esta evaluación específica, dicho algoritmo puede considerarse más eficiente para resolver el problema en esta situación particular.\nNo obstante, es importante señalar que la elección del algoritmo adecuado depende en gran medida de la naturaleza del problema. Incluso para un mismo problema, diferentes enfoques pueden llevar a variaciones significativas en los resultados, como se observó en este análisis. Aunque en este caso el Algoritmo de Colonia de Hormigas demostró ser más eficiente que el Algoritmo Genético, esta ventaja es altamente circunstancial y no necesariamente aplicable a todos los contextos. Esto refuerza la importancia de adaptar la metodología a las características específicas del problema a resolver."
  },
  {
    "objectID": "posts/optimación_combinatoria/index.html#footnotes",
    "href": "posts/optimación_combinatoria/index.html#footnotes",
    "title": "Algoritmo de colonia de hormigas para el problema del vendedor viajero",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl fitness representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.↩︎"
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html",
    "href": "posts/optimizacion_heuristica/index.html",
    "title": "Métodos de optimización heurística",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport io\nfrom PIL import Image\nEl objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.\nAl final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#optimización-por-descenso-del-gradiente",
    "href": "posts/optimizacion_heuristica/index.html#optimización-por-descenso-del-gradiente",
    "title": "Métodos de optimización heurística",
    "section": "2.1 Optimización por descenso del gradiente",
    "text": "2.1 Optimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nSegun (Bishop 2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla:\n\\[ x_{t+1} = x_t - \\eta \\nabla f(x_t) \\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable: \\[\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix}\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. (Bishop 2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como:\n\\[ \\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\]\n\\[ \\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\n\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#agoritmo-genético",
    "href": "posts/optimizacion_heuristica/index.html#agoritmo-genético",
    "title": "Métodos de optimización heurística",
    "section": "2.2 Agoritmo genético",
    "text": "2.2 Agoritmo genético\nUn algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la selección natural y la evolución biológica, propuesto inicialmente por (Holland 1975). Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n\n2.2.1 Concepto General\nEl algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n\nSelección: Elegir individuos con mayor fitness.1\nCruce: Combinar soluciones para generar descendencia.\nMutación: Introducir variación genética.\n\nMatemáticamente, en un problema de minimización, el objetivo es encontrar:\n\\[ x^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) \\]\ndonde:\n\n\\(x\\) representa un individuo en el espacio de búsqueda.\n\\(f(x)\\) es la función objetivo que evalúa la calidad de \\(x\\).\n\nCada solución candidata se representa como un individuo, que puede ser un vector real o un cromosoma binario:\n\\[x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n\\]\nLa función objetivo mide qué tan buena es una solución:\n\\[\\text{Fitness}(x) = f(x)\\]\nPara problemas de minimización, menor \\(f(x)\\) implica mejor fitness.\n\n\n\n2.2.2 Etapas\nInicialización de la Población\nSe genera una población inicial de \\(P\\) individuos de forma aleatoria dentro de un intervalo \\([a, b]\\) :\n\\[x_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\}\\]\ndonde:\n\n\\(x_{ij}\\) es la \\(j-ésima\\) coordenada del \\(i-ésimo\\) individuo.\n\n\n\nCode\n# Inicializar población\ndef initialize_population(size, dim, bounds):\n    return np.random.uniform(bounds[0], bounds[1], (size, dim))\n\n\n\nEvaluación del Fitness\nCada individuo de la población es evaluado usando la función objetivo:\n\\(\\text{Fitness}_i = f(x_i)\\)\n\n\nCode\n# Evaluar fitness\ndef evaluate_fitness(population,fitness_function):\n    return np.array([fitness_function(ind) for ind in population])\n\n\n\nSelección\nSe seleccionan individuos para reproducirse basándose en su fitness. Un métodos comune es el método de torneo, donde primero se seleccionan \\(k\\) individuos al azar y luego se elige al mejor de ellos(mejor fitness):\n\\[\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k\\]\n\n\nCode\n# Selección por torneo\ndef tournament_selection(population, fitness, k=3):\n    selected = []\n    for _ in range(len(population)):\n        candidates = np.random.choice(range(len(population)), k, replace=False)\n        winner = candidates[np.argmin(fitness[candidates])]\n        selected.append(population[winner])\n    return np.array(selected)\n\n\n\nCruce (Recombinación)\nDos individuos (padres) se combinan para generar descendencia. Un método común es punto de corte único, donde: 1. Se Elegie un punto de cruce aleatorio \\(k\\). 2. Se genera la descendencia mezclando las características de los padres.\n\\[\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:])\\]\n\\[\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:])\\]\nLa probabilidad de realizar un cruce está determinada por \\(p_c\\) (tasa de cruce).\n\n\nCode\n# Cruce\ndef crossover(parent1, parent2, crossover_rate):\n    if np.random.rand() &lt; crossover_rate:\n        point = np.random.randint(1, len(parent1))\n        child = np.concatenate([parent1[:point], parent2[point:]])\n        return child\n    return parent1 if np.random.rand() &lt; 0.5 else parent2\n\n\n\nMutación\nSe introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad \\(p_m\\):\n\\[x_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta)\\]\ndonde:\n\n\\(\\Delta\\) es una perturbación aleatoria.\n\\(x_{ij}\\) se restringe a los límites del problema.\n\n\n\nCode\n# Mutación\ndef mutate(individual, bounds, mutation_rate, delta):\n    for i in range(len(individual)):\n        if np.random.rand() &lt; mutation_rate:\n            individual[i] += np.random.uniform(-delta, delta)\n            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n    return individual\n\n\n\nEvaluación y Sustitución\nLa nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n\n\nCode\n# Algoritmo completo\ndef genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n    population = initialize_population(population_size, dim, bounds)\n    best_individual = None\n    trajectory = []\n    populations = []\n\n    for generation in range(generations):\n        populations.append(population.copy())\n        fitness = evaluate_fitness(population, fitness_function)\n        \n        if best_individual is None or np.min(fitness) &lt; fitness_function(best_individual):\n            best_individual = population[np.argmin(fitness)]\n        \n        # Guardar la mejor solución de esta generación\n        trajectory.append((*best_individual, fitness_function(best_individual)))\n        \n        # Selección\n        selected_population = tournament_selection(population, fitness)\n        \n        # Cruce y mutación\n        new_population = []\n        for i in range(0, len(selected_population), 2):\n            if i + 1 &lt; len(selected_population):\n                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n                new_population.extend([child1, child2])\n            else:\n                new_population.append(selected_population[i])\n        \n        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n    \n    # Convertir la trayectoria a DataFrame\n    \n    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n    df = pd.DataFrame(trajectory, columns=columns)\n    return best_individual, fitness_function(best_individual), df, populations\n\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]\n\n\n\n\nLos algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: Exploración, que consiste en descubrir nuevas regiones del espacio de búsqueda, y Explotación, enfocada en refinar y mejorar las soluciones existentes.\nPara las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación \\(\\delta\\) se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n\n\n2.2.3 Observaciones\nVentajas:\n\nNo requiere derivadas ni condiciones específicas en $$$f(x)$ .\nEs efectivo en espacios de búsqueda multimodales o no convexos.\nAdaptable a diversos problemas.\n\nDesventajas:\n\nPuede ser computacionalmente costoso.\nNo garantiza convergencia al óptimo global.\nRequiere ajuste cuidadoso de parámetros."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#optimización-de-partículas",
    "href": "posts/optimizacion_heuristica/index.html#optimización-de-partículas",
    "title": "Métodos de optimización heurística",
    "section": "2.3 Optimización de partículas",
    "text": "2.3 Optimización de partículas\n\n2.3.1 Concepto Básico y Analogía\nLa Optimización por Enjambre de Partículas (PSO) es una técnica metaheurística inspirada en el comportamiento social de los animales, como los pájaros o los peces. En PSO, cada solución potencial al problema se representa como una partícula que se mueve en un espacio de búsqueda multidimensional. Cada partícula ajusta su posición y velocidad en cada iteración, basándose en su propia mejor posición encontrada (pBest) y la mejor posición encontrada por todo el enjambre (gBest). (Kennedy and Eberhart 1995)\nLos métodos PSO se atribuyen originalmente a los investigadores Kennedy, Eberhart​ y Shi. En un principio fueron concebidos para elaborar modelos de conductas sociales,​como el movimiento descrito por los organismos vivos en una bandada de aves o un banco de peces. Posteriormente el algoritmo se simplificó y se comprobó que era adecuado para problemas de optimización. (Kennedy 1997)\nFuncionamiento de PSOz\nEn el algoritmo PSO (Particle Swarm Optimization), cada partícula, que representa un individuo, posee una posición p⃗  ​ dentro del espacio de búsqueda y una velocidad v⃗ que determina su desplazamiento. Estas partículas, al igual que objetos en un entorno físico, cuentan con una inercia w, la cual conserva su movimiento en la dirección previamente seguida.\n\n\nCode\nself.positions = np.random.uniform(\n    self.bounds[:, 0],\n    self.bounds[:, 1],\n    size=(n_particles, dimensions)\n)\n\nself.velocities = np.zeros((n_particles, dimensions))\n\n# Evaluar posiciones iniciales\nself.scores = np.array([self.objective_function(p) for p in self.positions])\n\n\nAdemás, su aceleración, que representa un cambio en la velocidad, está influenciada por dos factores principales:\n\nAtracción hacia su mejor posición personal: Cada partícula tiende a moverse hacia la mejor ubicación que ha identificado en su trayectoria histórica (pbest).\nAtracción hacia la mejor posición global: Las partículas también se dirigen hacia la mejor ubicación encontrada por el grupo completo en el espacio de búsqueda (pgbest).\n\n\n(Sancho Caparrini 2024)\n\n\nCode\nfor iteration in range(self.max_iter):\n    # Actualizar velocidades\n    r1, r2 = np.random.rand(2)\n    self.velocities = (self.w * self.velocities +\n                     self.c1 * r1 * (self.p_best - self.positions) +\n                     self.c2 * r2 * (self.g_best - self.positions))\n    \n    # Actualizar posiciones\n    self.positions += self.velocities\n    \n    # Mantener partículas dentro de los límites\n    self.positions = np.clip(\n        self.positions,\n        self.bounds[:, 0],\n        self.bounds[:, 1]\n    )\n    \n    # Evaluar nuevas posiciones\n    self.scores = np.array([self.objective_function(p) for p in self.positions])\n    \n    # Actualizar mejores posiciones personales\n    improved_mask = self.scores &lt; self.p_best_scores\n    self.p_best[improved_mask] = self.positions[improved_mask]\n    self.p_best_scores[improved_mask] = self.scores[improved_mask]\n    \n    # Actualizar mejor posición global\n    min_score_idx = np.argmin(self.p_best_scores)\n    if self.p_best_scores[min_score_idx] &lt; self.g_best_score:\n        self.g_best = self.p_best[min_score_idx].copy()\n        self.g_best_score = self.p_best_scores[min_score_idx]\n\n\nEl algoritmo se detiene cuando se alcanza un número máximo de iteraciones, o cuando la mejora en la función objetivo es menor a un umbral predefinido.\nAl implementar el algoritmo, se presentó un comportamiento oscilatorio donde las partículas convergían inicialmente pero luego se dispersaban de manera repentina. El análisis reveló cuatro posibles causas: velocidades excesivas de las partículas, coeficientes de aprendizaje mal ajustados, peso de inercia estático y ausencia de un mecanismo de estabilización.\nLa solución implementada aborda estos problemas mediante cuatro modificaciones: Se  limitó la velocidad máxima al 10% del espacio de búsqueda para evitar saltos excesivos, se optimizaron los coeficientes cognitivo y social a un valor de 2.0 para balancear exploración y explotación, se implementó un peso de inercia dinámico que decrece linealmente de 0.9 a 0.4 durante la optimización y se añadió un factor de constricción calculado a partir de los coeficientes de aprendizaje para garantizar convergencia matemática.\n\n\nCode\n# Control de Velocidad Máxima\nv_max = 0.1 * (bounds[:, 1] - bounds[:, 0])\nvelocities = np.clip(velocities, -v_max, v_max)\n\n# Peso de Inercia Dinámico\nw = w_max - (w_max - w_min) * (iteracion / max_iter)\n\n# Factor de Constricción\nphi = c1 + c2\nchi = 2 / abs(2 - phi - np.sqrt(phi * phi - 4 * phi))\n\n# Parámetros Optimizados\nc1 = c2 = 2.0\nw_max = 0.9\nw_min = 0.4\n\n\nEstas modificaciones resultaron en una mejora significativa en la estabilidad del algoritmo, con una transición más suave entre las fases de exploración y explotación, y una convergencia más consistente hacia el óptimo global.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align}\n\\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]"
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#optimización-diferencial",
    "href": "posts/optimizacion_heuristica/index.html#optimización-diferencial",
    "title": "Métodos de optimización heurística",
    "section": "2.4 Optimización diferencial",
    "text": "2.4 Optimización diferencial\nFuncionamiento Básico\nLa Evolución Diferencial (ED) es un algoritmo de optimización poblacional inspirado en los procesos evolutivos naturales. Al igual que otros algoritmos de esta categoría, la ED mantiene una población de soluciones candidatas, las cuales se recombinan y mutan para producir nuevos individuos los cuales serán elegidos de acuerdo al valor de su función de desempeño. Lo que caracteriza a la ED es el uso de vectores de prueba, los cuales compiten con los individuos de la población actual a fin de sobrevivir. (Price and Storn 1995)\nPasos clave:\n\nInicialización de la población:\n\nSe genera aleatoriamente una población inicial de individuos (soluciones potenciales).\nCada individuo es un vector que representa un punto en el espacio de búsqueda.\n\n\n\n\nCode\ndef initialize_population(self):\n    \"\"\"\n    Inicializa la población de manera aleatoria dentro de los límites especificados\n\n    Returns:\n    - Matriz numpy con población inicial\n    \"\"\"\n    # Crea una matriz de ceros con el tamaño de la población\n    population = np.zeros((self.population_size, self.dimension))\n\n    # Genera valores aleatorios para cada dimensión\n    for i in range(self.dimension):\n        population[:, i] = np.random.uniform(\n            self.bounds[i][0],  # Límite inferior\n            self.bounds[i][1],  # Límite superior\n            size=self.population_size  # Número de individuos\n        )\n    return population\n\n\n\nEvaluación de la población:\n\nSe evalúa el valor de la función objetivo para cada individuo de la población\n\nGeneración de nuevos individuos:\n\nMutación: Se crea un vector mutante sumando a un individuo objetivo una diferencia escalada entre otros dos individuos de la población.\n\n\n\n\nCode\ndef mutation(self, population):\n    \"\"\"\n    Aplica la estrategia de mutación DE/rand/1\n\n    Parameters:\n    - population: Población actual\n\n    Returns:\n    - Población mutada\n    \"\"\"\n    # Crea una matriz para almacenar la población mutada\n    mutation_pop = np.zeros_like(population)\n\n    for i in range(self.population_size):\n        # Selecciona tres individuos aleatorios diferentes\n        candidates = list(range(self.population_size))\n        candidates.remove(i)\n        r1, r2, r3 = np.random.choice(candidates, 3, replace=False)\n\n        # Genera un nuevo vector mediante mutación\n        mutation_pop[i] = population[r1] + self.F * (population[r2] - \n                                                               population[r3])\n\n        # Asegura que los valores estén dentro de los límites\n        for j in range(self.dimension):\n            mutation_pop[i, j] = np.clip(\n                mutation_pop[i, j],\n                self.bounds[j][0],\n                self.bounds[j][1]\n            )\n\n    return mutation_pop\n\n\n\nCruce: Se crea un vector de prueba combinando el vector mutante y el individuo objetivo mediante un operador de cruce.\n\n\n\nCode\ndef crossover(self, population, mutation_pop):\n    \"\"\"\n    Aplica el cruce binomial (crossover)\n\n    Parameters:\n    - population: Población actual\n    - mutation_pop: Población mutada\n\n    Returns:\n    - Población de prueba tras el cruce\n    \"\"\"\n    # Crea una matriz para almacenar la población de prueba\n    trial_pop = np.zeros_like(population)\n\n    for i in range(self.population_size):\n        # Genera puntos de cruce basados en CR\n        cross_points = np.random.rand(self.dimension) &lt;= self.CR\n        # Asegura al menos un punto de cruce\n        cross_points[np.random.randint(0, self.dimension)] = True\n\n        # Genera vector de prueba\n        trial_pop[i] = np.where(cross_points, mutation_pop[i], population[i])\n\n    return trial_pop\n\n\n\nSelección: Se compara el valor de la función objetivo del vector de prueba con el del individuo objetivo. El mejor de los dos se selecciona para la siguiente generación.\n\n\n\nCode\ndef selection(self, population, trial_pop):\n    \"\"\"\n    Selección de los mejores individuos\n\n    Parameters:\n    - population: Población actual\n    - trial_pop: Población de prueba\n\n    Returns:\n    - Nueva población y sus valores de aptitud\n    \"\"\"\n    # Calcula la aptitud de la población actual y de prueba\n    pop_fitness = np.array([self.func(ind) for ind in population])\n    trial_fitness = np.array([self.func(ind) for ind in trial_pop])\n\n    # Identifica qué individuos de prueba son mejores\n    better_indices = trial_fitness &lt; pop_fitness\n    population[better_indices] = trial_pop[better_indices]\n\n    return population, np.minimum(pop_fitness, trial_fitness)\n\n\n\nCriterio de parada:\n\nSe repiten los pasos 3 y 4 hasta que se cumpla un criterio de parada (número máximo de generaciones, mejora mínima en la función objetivo, etc.)\n(Martínez Zecua et al. 2019)\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[f(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right]\\]\n\n\n\n\\[f(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right]\\]\n\n\n\n\\[ f(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\]\n\n\n\n\\[ f(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\]\n\n\n\n\\[ \\begin{align} f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\          & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right] \\end{align} \\]\n\n\n\n\\[ f(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\]"
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#problema-del-viajero",
    "href": "posts/optimizacion_heuristica/index.html#problema-del-viajero",
    "title": "Métodos de optimización heurística",
    "section": "5.1 Problema del Viajero:",
    "text": "5.1 Problema del Viajero:\nUn vendedor debe realizar un recorrido por todas las capitales de los 32 estados de los Estados Unidos Mexicanos.\n\n5.1.1 Tareas:\n\nOptimización con métodos metaheurísticos:\n\nUtilice colonias de hormigas para encontrar el orden óptimo del recorrido.\nUtilice algoritmos genéticos para encontrar el orden óptimo del recorrido.\n\nCosto del recorrido:\n\nEl costo de desplazamiento entre ciudades se calcula como la suma de:\n\nEl valor de la hora del vendedor (este es un parámetro que debe estudiarse).\nEl costo de los peajes.\nEl costo del combustible.\n\nCada equipo debe definir el vehículo que utilizará el vendedor para realizar el recorrido y, con base en esta elección, calcular el costo del combustible.\n\n\n\n\n5.1.2 Representación Visual:\n\nCree un GIF animado o un video que muestre cómo se comporta la mejor solución encontrada, usando un gráfico del recorrido en el mapa de México.\n\n\n\n\n5.1.3 Discusión:\nReflexione sobre: - Los resultados obtenidos con las colonias de hormigas y los algoritmos genéticos. - Comparación de costos y tiempo de ejecución."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#solución-de-las-tareas-propuestas",
    "href": "posts/optimizacion_heuristica/index.html#solución-de-las-tareas-propuestas",
    "title": "Métodos de optimización heurística",
    "section": "5.2 Solución de las tareas propuestas",
    "text": "5.2 Solución de las tareas propuestas\n\n5.2.1 Extracción de datos\nPara empezar a solucionar el problema, es necesario obtener información acerca del valor del salario del vendedor, el costo de los peajes y el cálculo correspondiente al costo total destinado a combustible; definiendo entonces el modelo de automóvil a considerar en el ejercicio, junto con su respectivo costo de gasolina. Durante el desarrollo de este proceso de extracción de información se tomaron como referencia las ciudades capitales de cada uno de los estados mexicanos y se observó el mapa de la división política de México en sus 32 estados, a fin de tener un mejor entendimiento de la región.\nFigura 1.\nMapa de México.  Nota. El mapa representa cada una de las ciudades capitales del país. Adaptado de Fondo plano de mapa de méxico [Ilustración], por Freepik, 2024, Freepik (https://www.freepik.es/vector-gratis/mapa-mexico). Licencia gratuita.\n\n5.2.1.1 Distancias y tiempo de conducción\nLa tabla de distancias y tiempo de conducción entre las ciudades fue obtenida a través del sitio web (mejoresrutas2024?), diseñado especialmente para el cálculo y planeación de viajes a lo largo de todo el país. Dicho recurso online permite obtener información como distancias, tiempo de conducción y otros valores asociados entre dos ciudades ingresando el nombre de cada una de ellas.\n\n\n5.2.1.2 Peajes\nPara obtener la información de los peajes, fue utilizado el mismo sitio web (mejoresrutas2024?), el cual también contiene datos relacionados con el costo actual de los peajes que se encuentran entre las ciudades donde se realiza la consulta.\nDebido al gran número de combinaciones posibles, se programó un bot en Python empleando la librería Beautiful Soup, lo que permitió automatizar la extracción de la información anteriormente mencionada. En el repositorio en GitHub es posible encontrar el archivo con el código para llevar a cabo esta tarea.\n\n\n\n5.2.2 Definición de gastos\nEn la siguiente sección se definen los gastos que deben ser consultados, entre los cuales se encuentran el salario del vendedor, el modelo de automóvil a utilizar y su correspondiente gasto de combustible.\n\n5.2.2.1 Salario del vendedor\nPara definir el salario del vendedor, se toma como referencia el salario minimo en México, que actualmente se encuentra en 248,93 pesos diarios según la (conasami2024?); por lo tanto, para una jornada de 8 horas, el salario mínimo por hora es de 31,12 aproximadamente. Dicho esto, se decide establecer un salario de 35 pesos mexicanos por hora para el vendedor del presente ejercicio.\n\n\n5.2.2.2 Modelo del carro y gasto en gasolina\nDe acuerdo con (elpais2024?), el modelo de automóvil más vendido actualmente en México es el Nissan Versa, por lo que se ha considerado conveniente seleccionarlo como medio de transporte a utilizar por parte del vendedor. Esto permitirá hacer una estimación más justa del costo total de realizar la ruta por los 32 estados mexicanos en el contexto de dicho país.\nAdicionalmente, es importante considerar que el rendimiento promedio de este modelo en carreteras es de 25 kilómetros por litro de acuerdo con información proporcionada por (nissanversarendimiento2023?) y que el tipo de gasolina que utiliza es la comúnmente denominada como “Gasolina Magna” en México la cual, al día 14 de noviembre, tiene un precio promedio de 23.96 pesos mexicanos por litro según (gasolinamx2024?).\n\n\n5.2.2.3 Transformaciones\nSe ha obtenido la información anterior con el objetivo de calcular el costo total de desplazamiento entre las ciudades capitales de México, sin embargo, se observa que no todos los datos se encuentran en las unidades requeridas (MXN): hay magnitudes en litros, horas, kilómetros, etc. Por lo tanto, se realizarán las siguientes transformaciones en todas las unidades para poder sumar dichos gastos en pesos mexicanos, a diferencia del caso de los peajes, pues estos ya se encuentran en la unidad monetaria deseada.\n\n5.2.2.3.1 Tiempo de viaje\nEl costo por el salario del vendedor es calculado la forma que se muestra en la Ecuación (1):\n\\[\n\\text{Costo\\_vendedor} = \\text{tiempo} \\times \\text{salario\\_del\\_vendedor} \\tag{1}\n\\]\n\n\n\n5.2.2.4 Gasolina para el viaje\nEl gasto total en gasolina se obtiene con la fórmula mostrada en la Ecuación (2):\n\\[\n\\text{Costo\\_gasolina} = \\left( \\frac{\\text{Distancia}}{\\text{Rendimiento (km/litro)}} \\right) \\times \\text{Precio\\_por\\_litro} \\tag{2}\n\\]\n\n5.2.2.4.1 Gasto total\nDespués de realizar las operaciones mostradas anteriormente, se tiene como resultado toda la información necesaria en las unidades requeridas para obtener un valor correspondiente al gasto total del viaje en pesos mexicanos, de acuerdo con lo definido en la Ecuación (3).\n\\[\n\\text{Gasto\\_recorrido} = \\text{Costo\\_gasolina} + \\text{Costo\\_vendedor} + \\text{Costo\\_Peajes} \\tag{3}\n\\]\n\n\n\n\n5.2.3 Ruta óptima\nA continuación, se procede con la utilización de los algoritmos propuestos para este caso: Colonia de Hormigas y Algoritmos Genéticos, con el fin de responder a la actividad planteada al principio del presente ejercicio, esto es, hallar la ruta óptima para el recorrido del vendedor a través de los 32 estados de México.\n\n5.2.3.1 Colonia de Hormigas\nConsiderando la información recolectada en (acowikipedia2024?) y (acobook2018?) y lo presentado en la primera sección del trabajo, puede decirse que los algoritmos de colonia de hormigas (Ant Colony Optimization, ACO) son una técnica de optimización basada en la inteligencia colectiva observada en las colonias de hormigas naturales. Fueron inspirados en el comportamiento de las hormigas en la naturaleza para resolver problemas complejos de optimización combinatoria, en esta segunda parte del trabajo profundizaremos más en sus hiperparámetros claves los cuales son:\n\nCantidad de hormigas: Cantidad de hormigas que participarán en cada iteración de la búsqueda de soluciones. Influye en la capacidad del algoritmo de explorar diferentes soluciones de manera simultánea. En este caso se utilizarán 32 hormigas, es decir, igual al número de estados en México.\nAlpha: Controla la influencia de la feromona en la probabilidad de que una hormiga elija ese camino. A medida que el valor aumenta, las hormigas son más propensas a seguir caminos con más feromona. Aquí se utilizará un valor de 1 para otorgar una influencia moderada de las feromonas depositadas.\nBeta: Controla la preferencia de las hormigas por caminos más “baratos” o prometedores, lo cual ayuda aumentar la exploración. Se va a considerar un valor de 2, puesto que se busca minimizar el costo del viaje\n\\(\\rho\\): Indica la tasa de evaporación de la feromona, lo cual evita que las soluciones previas influencien las iteraciones futuras. Se seleccionó una tasa de evaporación del 0.5, es decir, el 50% de las feromonas se evaporan en cada iteración.\n\\(Q\\): Cantidad de feromona depositada por una hormiga en su recorrido tras encontrar una solución. Se utilizará un valor de 100 para indicar la cantidad de feromonas en el camino.\n\nUna vez definidos los hiperparámetros, se puede continuar con la ejecución del algoritmo de colonia de hormigas, cuyo detalle se puede observar más a profundidad en el repositorio de GitHub. En la Figura 2 se puede observar cómo va variando el costo de realizar el viaje en cada una de las iteraciones que realizó dicho algoritmo.\nFigura 2.\nFunción costo del algoritmo Colonia de Hormigas.  Nota. La gráfica muestra la evolución del costo total del viaje a medida que se ejecutan las diferentes iteraciones del algoritmo, que para este caso fueron 500. Elaboración propia.\nDe acuerdo con la imagen anterior, es posible observar que el costo mínimo se alcanza relativamente rápido, antes de las 100 iteraciones. En este sentido, también es interesante notar que el cálculo de esta función de costo varía al considerar diferentes variaciones que puedan realizarse sobre el planteamiento inicial del problema, comportamiento que se verá más adelante.\nPosteriormente, en la Figura 3 puede verse la ruta óptima encontrada por el algoritmo de colonia de hormigas para que el vendedor pueda recorrer los 32 estados mexicanos.\nFigura 3.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas.  Nota. Puede observarse que esta visualización gráfica está dada por líneas rectas entre cada una de las ciudades y no muestra con fidelidad la forma en que se haría el recrorrido. Elaboración propia.\nCon el fin de que el camino óptimo pueda reflejar la realidad del viaje, en la Figura 4 se ilustra la utilización de la API gratuita Open Route Service para graficar el recorrido propuesto a lo largo de las carreteras en el mapa de México. La API key para acceder a este servicio es la siguiente:\n\n\nCode\napi_key = \"5b3ce3597851110001cf6248c140bc578aac4c2d95295dc798e53a22\"\n\n\nFigura 4.\nForma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas.  Nota. El gráfico muestra las carreteras que deberían seguirse para completar el recorrido propuesto, sin embargo, algunos aspectos siguen siendo siendo interesantes. Elaboración propia.\nComo se mencionó anteriormente, de esta forma se obtiene una ruta óptima más realista. No obstante, llama la atención que, en ciertas secciones, la ruta implica cruzar cuerpos de agua. Al investigar las razones de este comportamiento, se descubrió que para conectar algunos estados del país como Baja California Sur y Sinaloa, la opción de tomar un ferri es considerada la más conveniente según servicios de planificación de trayectos como (mejoresrutasferri2024?) y (bajaferries2024?).\nDado que la matriz de costos actual no considera el valor asociado al uso del ferri ni los gastos asociados al transporte del vehículo para continuar posteriormente el recorrido, se propone un análisis de los siguientes escenarios:\n\nIncluir el costo del ferri en la matriz de costos y evaluar la ruta resultante.\nRealizar el viaje completamente por tierra, excluyendo los estados que se alcanzan únicamente utilizando el ferri.\n\nPrimer escenario\nSe consultó el valor del tiquete de ferri para una persona adulta y el costo del transporte de un automóvil, encontrando que el más económico para un adulto es de 1,460 pesos mexicanos, mientras que el transporte del automóvil tiene un valor de 5,480 pesos mexicanos según (debate2023?).\nEstos costos fueron utilizados como parámetros para el algoritmo de colonia de hormigas, llegando a que, como se observa en la Figura 5, el algoritmo sigue alcanzando un mínimo de manera relativamente rápida.\nFigura 5.\nEvolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri.  Nota. Es interesante notar que, a pesar del incremento en el costo de moverse entre dos estados (debido al ferri), el algoritmo logró encontrar una ruta más barata que la hallada originalmente. Esto sugiere que en la primera solución encontrada el algoritmo podría haberse quedado atascado en un mínimo local debido a la falta de iteraciones. Elaboración propia.\nAdemás, también es posible observar que el tiempo y la distancia se redujeron en esta nueva solución, lo cual permite pensar que esta ruta no solo es más económica, sino también más eficiente, a pesar de que está considerando el costo adicional del ferri y el transporte del vehículo.\nLos resultados correspondientes a la visualización gráfica del camino óptimo encontrado para el vendedor en este escenario pueden observarse a continuación, en las Figuras 6 y 7.\nFigura 6.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri. . Nota. Las observaciones respecto a la forma en que se conectan los distintos puntos del recorrido permanecen iguales que en el caso considerado originalmente. Elaboración propia.\nFigura 7.\nCarreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas.  Nota. Esta imagen también fue generada por medio del uso de la API gratuita, así que sus resultados son reproducibles. Elaboración propia.\nSegundo escenario\nEn este segundo escenario, la ciudad de La Paz fue eliminada del recorrido, por lo que el viaje ahora solo incluye los 31 estados restantes. En consecuencia, también se redujo la cantidad de hormigas utilizadas en el algoritmo a un valor de 31, asignando una hormiga por estado para realizar la búsqueda.\nComo era de esperarse, el precio del recorrido se redujo en este caso. Sin embargo, al algoritmo le tomó muchas más iteraciones encontrar el costo mínimo, como se observa en la Figura 8.\nFigura 8.\nEvolución de la función costo para los 31 estados de México.  Nota. El hecho de que el planteamiento inicial de ciudades y estados a recorrer cambiara al no tener en cuenta el estado que solamente puede ser conectado vía marítima fue un factor determinante en la ejecución del algoritmo de hormigas, siendo mucho menos rápido que en el primer escenario (incluso que en el escenario original). Elaboración propia.\nA diferencia del caso anterior, la Figura 8 también muestra que la distancia y el tiempo aumentaron. Esto se debe a que, al no utilizar el ferri, el automóvil tuvo que realizar un recorrido más largo en ciertas partes para completar su ruta. Por lo tanto, aunque esta solución es más eficiente en términos de costo, no lo es en términos de tiempo y distancia recorrida.\nLa visualización gráfica de los resultados obtenidos para este caso pueden observarse en las Figuras 9 y 10, teniendo en cuenta las mismas consideraciones anteriormente mencionadas.\nFigura 9.\nRuta óptima encontrada mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Elaboración propia.\nFigura 10.\nOrden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Nota. Sumado a los inconvenientes observados en este escenario, al desconectar uno de los estados de México, puede observarse que una gran región del país queda excluida del recorrido del vendedor, lo que puede implicar significativas pérdidas económicas y oportunidades de establecer nuevos negocios.\n\n\n5.2.3.2 Algoritmo genético\nDe acuerdo con información proporcionada por (tesisga2009?) y encontrada en (gawikipedia2024?), y como se explico en la primera sección del trabajo, puede decirse que los algoritmos genéticos (Genetic Algorithms, GA) son una técnica de optimización inspirada en los principios de la selección natural y la evolución biológica. Los GA buscan soluciones óptimas mediante la creación, evaluación y modificación de una población de individuos, representando posibles soluciones a un problema dado. La evolución de la población se realiza mediante operadores genéticos como la mutación y en esta sección profundizaremos más en sus hiperparámetros clave, los cuales son:\n\nTamaño de la población: Define el número de individuos en cada generación. Un tamaño de población más grande permite una mejor exploración del espacio de soluciones, pero también aumenta el tiempo de cómputo. En este caso, se utilizará una población de 100 individuos, lo que proporciona un equilibrio adecuado entre diversidad y eficiencia computacional.\nNúmero de generaciones: Especifica cuántas veces se evolucionará la población mediante el proceso de selección, cruce y mutación; se consideran adecuadas un total de 200 generaciones para permitir al algoritmo explorar el espacio de búsqueda y converger hacia una solución óptima o cercana al óptimo.\nTasa de mutación: Representa la probabilidad de que un gen sea modificado aleatoriamente en un individuo. La mutación introduce variación genética, lo que ayuda a explorar nuevas áreas del espacio de búsqueda y a evitar estancamientos en óptimos locales. Se empleará una tasa de mutación de 0.1 (10%), lo que mantiene una buena cantidad de diversidad sin perturbar excesivamente a la población.\n\nDe la misma manera en que se realizó en la sección anterior, la presentación de resultados comienza con una obtención de resultados iniciales considerando los 32 estados de México y sin tener en cuenta el costo del ferri.\nComo se observa en la Figura 11, alcanzar el mínimo toma casi 175 generaciones, lo que indica que este algoritmo se demora más en llegar a un valor mínimo en comparación con el algoritmo de colonia de hormigas. Además, la solución que encuentra tiene un costo mayor y toma más tiempo y una mayor distancia completarla.\nFigura 11.\nEvolución de la función costo del algoritmo genético.  Nota. En la ejecución de este algoritmo, la solución óptima se encontró en una iteración muy cercana al límite máximo establecido, a diferencia del algoritmo de colonia de hormigas, que lo realizó muy rápidamente. Elaboración propia.\nAhora bien, en las Figuras 12 y 13 se tiene la visualización gráfica del recorrido propuesto por este algoritmo, siguiendo los mismos procedimientos de utilización de la API que se mencionaron de manera previa.\nFigura 12.\nRuta óptima encontrada mediante algoritmo genético.  Elaboración propia.\nFigura 13.\nRuta óptima con las carreteras encontrada mediante algoritmo genético.  Elaboración propia.\nNuevamente, se considera pertinente considerar los dos escenarios adicionales de análisis: un nuevo cálculo de costos teniendo en cuenta el tiquete de ferri y el transporte adicional para el automóvil y la exclusión La Paz, como territorio que solo puede conectarse a través de cuerpos de agua.\nPrimer escenario\nEs posible observar que al tomar en cuenta el costo del ferri, en este caso sí se aumenta el costo del camino óptimo y el número de iteraciones se reduce un poco, como puede verse en la Figura 14. Sin embargo, el tiempo que toma completar esta ruta es mucho más alto que en el caso anterior, lo que podría indicar que esta solución se quedó atrapada en un mínimo local.\nFigura 14.\nEvolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri.  Elaboración propia.\nPor otra parte, en las Figuras 15 y 16 se puede observar el recorrido propuesto por esta solución del algoritmo para que el vendedor se desplace por todo el país, viendo que los puntos de inicio y finalización son diferentes a los que había arrojado como resultado el algoritmo de colonia de hormigas.\nFigura 15.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri.  Nota. Sabiendo que la ruta marítima que seleccionaron ambos algoritmos es la misma, puede decirse que las diferencias entre sus resultados radican en otros aspectos inherentes a su propia definición, como pueden serlo los hiperparámetros y la forma en que realizan una búsqueda de la solución óptima. Elaboración propia.\nFigura 16.\nRuta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri.  Nota. La utilización de la API se dio exactamente igual que en los escenarios anteriores, de manera que estos resultados también son reproducibles.\nSegundo escenario\nEn este último escenario, el cual solamente considera 31 de los estados de México, es posible notar que el costo óptimo nuevamente bajó y, a diferencia del algoritmo de colonia de hormigas, el algoritmo genético sí encuentra una forma de reducir el tiempo y la distancia del recorrido, mostrando una mejoría en ese aspecto.\nDe acuerdo con la Figura 17, en este escenario el algoritmo genético necesitó más iteraciones para encontrar un mínimo, lo cual se ve compensado por el hecho de que mejoró el desempeño del algoritmo de colonia de hormigas en términos de las variables anteriormente mencionadas.\nFigura 17.\nEvolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México.  Elaboración propia.\nFinalmente, las Figuras 18 y 19 permiten observar el recorrido que debería realizar el vendedor de acuerdo con este escenario propuesto, en el que también queda aislada una amplia región del país debido a la decisión de no considerar recorridos que no fueran terrestres.\nFigura 18.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México.  Elaboración propia.\nFigura 19.\nRuta óptima de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México.  Nota. Al observar las carreteras que debería recorrer esta solución, puede observarse que el vendedor terminaría pasando por los mismos caminos varias veces, ya que deben darse varios recorridos de manera repetida por la necesidad de conectar algunos territorios de los 31 estados sin contemplar la opción del viaje en ferri. Elaboración propia.\n\n\n\n5.2.4 Verificación de la calidad de la solución\nEs importante evaluar qué tan buena es la solución alcanzada. Métodos exhaustivos como la fuerza bruta, que permiten comprobar cuál es la mejor solución entre todas las posibles, resultan computacionalmente inviables en este caso. Aprovechando que disponemos de un gran número de iteraciones y tres diferentes escenarios que nos permiten variar las condiciones del problema, podemos concluir que la solución obtenida es, al menos, razonablemente buena.\nAdemás, es relevante analizar el comportamiento de las funciones de costo. En todos los escenarios se observa que el costo se reduce significativamente al principio y luego comienza a fluctuar alrededor de una media estable. Esto indica que el algoritmo está convergiendo hacia esos valores. A partir de este comportamiento, seleccionamos la solución con el menor costo como la mejor alternativa.\nEn general, las funciones de costo tienden a estabilizarse dentro de un rango limitado de valores. Este patrón nos permite confiar en que las soluciones obtenidas se encuentran entre las mejores posibles, considerando las limitaciones inherentes a los métodos no determinísticos.\n\n\n5.2.5 Discusión de los resultados\nLos resultados obtenidos al aplicar el Algoritmo de Colonia de Hormigas y el Algoritmo Genético en tres situaciones diferentes permiten destacar las fortalezas y diferencias de cada uno. Por un lado, el Algoritmo de Colonia de Hormigas logra encontrar una solución más económica y en un menor número de iteraciones en comparación con el Algoritmo Genético. Por lo tanto, en esta evaluación específica, dicho algoritmo puede considerarse más eficiente para resolver el problema en esta situación particular.\nNo obstante, es importante señalar que la elección del algoritmo adecuado depende en gran medida de la naturaleza del problema. Incluso para un mismo problema, diferentes enfoques pueden llevar a variaciones significativas en los resultados, como se observó en este análisis. Aunque en este caso el Algoritmo de Colonia de Hormigas demostró ser más eficiente que el Algoritmo Genético, esta ventaja es altamente circunstancial y no necesariamente aplicable a todos los contextos. Esto refuerza la importancia de adaptar la metodología a las características específicas del problema a resolver."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#footnotes",
    "href": "posts/optimizacion_heuristica/index.html#footnotes",
    "title": "Métodos de optimización heurística",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl fitness representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.↩︎"
  },
  {
    "objectID": "posts/welcome/index.html#cómo-aprovechar-este-blog",
    "href": "posts/welcome/index.html#cómo-aprovechar-este-blog",
    "title": "!Bienvenido a nuestro blog!",
    "section": "",
    "text": "Lee los proyectos: Cada entrada está organizada para que puedas entender tanto la teoría como las implementaciones prácticas.\nDescarga y reproduce: Los ejemplos están diseñados para ser replicados, con código y explicaciones detalladas.\nConstruye sobre esto: Usa las ideas presentadas como punto de partida para tus propios proyectos."
  }
]