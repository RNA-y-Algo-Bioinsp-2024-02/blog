[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "¡Bienvenidos a nuestro blog!",
    "section": "",
    "text": "Este blog ha sido diseñado como parte de un curso dedicado a las Redes Neuronales y Algoritmos Bioinspirados, con el propósito de servir como un repositorio de trabajos, reflexiones y aprendizajes desarrollados a lo largo del programa. Más allá del curso, nuestro objetivo es que este espacio evolucione hacia un portafolio que abarque múltiples temáticas en inteligencia artificial, analítica avanzada y aprendizaje automático.\n\n\n\n\nTrabajos del curso: Proyectos que exploran desde el funcionamiento básico de redes neuronales hasta implementaciones más avanzadas de algoritmos bioinspirados, como los basados en evolución genética o el comportamiento de colonias de hormigas.\nArtículos educativos: Explicaciones claras y prácticas sobre conceptos clave de inteligencia artificial y sus aplicaciones.\nRecursos reproducibles: Todo lo que publico está diseñado para ser reutilizable y comprensible, buscando contribuir al aprendizaje de otros.\n\n\n\n\n\n\n\n\n\n\nLa idea de este blog no solo es mostrar lo aprendido, sino también convertirlo en un material accesible y de calidad para otros. Crear contenido reproducible y útil puede ser un puente hacia el aprendizaje compartido, la inspiración y la mejora continua.\nAdemás, quieremos que este espacio sea un ejemplo de cómo construir un portafolio profesional que combine el rigor técnico con un diseño atractivo. Esto puede ser útil tanto para la comunidad académica como para el ámbito profesional.\n\n\n\n\n\nLee los proyectos: Cada entrada está organizada para que puedas entender tanto la teoría como las implementaciones prácticas.\nDescarga y reproduce: Los ejemplos están diseñados para ser replicados, con código y explicaciones detalladas.\nConstruye sobre esto: Usa las ideas presentadas como punto de partida para tus propios proyectos."
  },
  {
    "objectID": "posts/welcome/index.html#qué-encontrarás-aquí",
    "href": "posts/welcome/index.html#qué-encontrarás-aquí",
    "title": "¡Bienvenidos a nuestro blog!",
    "section": "",
    "text": "Trabajos del curso: Proyectos que exploran desde el funcionamiento básico de redes neuronales hasta implementaciones más avanzadas de algoritmos bioinspirados, como los basados en evolución genética o el comportamiento de colonias de hormigas.\nArtículos educativos: Explicaciones claras y prácticas sobre conceptos clave de inteligencia artificial y sus aplicaciones.\nRecursos reproducibles: Todo lo que publico está diseñado para ser reutilizable y comprensible, buscando contribuir al aprendizaje de otros."
  },
  {
    "objectID": "posts/welcome/index.html#por-qué-este-blog",
    "href": "posts/welcome/index.html#por-qué-este-blog",
    "title": "¡Bienvenidos a nuestro blog!",
    "section": "",
    "text": "La idea de este blog no solo es mostrar lo aprendido, sino también convertirlo en un material accesible y de calidad para otros. Crear contenido reproducible y útil puede ser un puente hacia el aprendizaje compartido, la inspiración y la mejora continua.\nAdemás, quieremos que este espacio sea un ejemplo de cómo construir un portafolio profesional que combine el rigor técnico con un diseño atractivo. Esto puede ser útil tanto para la comunidad académica como para el ámbito profesional."
  },
  {
    "objectID": "posts/welcome/index.html#cómo-aprovechar-este-blog",
    "href": "posts/welcome/index.html#cómo-aprovechar-este-blog",
    "title": "¡Bienvenidos a nuestro blog!",
    "section": "",
    "text": "Lee los proyectos: Cada entrada está organizada para que puedas entender tanto la teoría como las implementaciones prácticas.\nDescarga y reproduce: Los ejemplos están diseñados para ser replicados, con código y explicaciones detalladas.\nConstruye sobre esto: Usa las ideas presentadas como punto de partida para tus propios proyectos."
  },
  {
    "objectID": "posts/optimizacion_combinatoria/index.html",
    "href": "posts/optimizacion_combinatoria/index.html",
    "title": "Optimización Combinatoria",
    "section": "",
    "text": "La optimización combinatoria es fundamental para resolver problemas complejos en rutas y logística. Este enfoque resulta especialmente útil en desafíos como el que se presenta a continuación, en el que un vendedor viajero busca la ruta más eficiente para recorrer los estados de México. Las técnicas empleadas para abordar este problema incluyen el algoritmo de colonia de hormigas, inspirado en el comportamiento de las hormigas en la naturaleza y los algoritmos genéticos, que simulan procesos evolutivos como la selección, cruce y mutación. Estas herramientas permitirán abordar el problema con la consideración de múltiples variables y restricciones, permitiendo además la optimización de recorridos en términos de tiempo y costo de manera.\n\n\nUn vendedor debe realizar un recorrido por todas las capitales de los 32 estados de los Estados Unidos Mexicanos.\n\n\n\nOptimización con métodos metaheurísticos:\n\nUtilice colonias de hormigas para encontrar el orden óptimo del recorrido.\nUtilice algoritmos genéticos para encontrar el orden óptimo del recorrido.\n\nCosto del recorrido:\n\nEl costo de desplazamiento entre ciudades se calcula como la suma de:\n\nEl valor de la hora del vendedor (este es un parámetro que debe estudiarse).\nEl costo de los peajes.\nEl costo del combustible.\n\nCada equipo debe definir el vehículo que utilizará el vendedor para realizar el recorrido y, con base en esta elección, calcular el costo del combustible.\n\n\n\n\n\n\nCree un GIF animado o un video que muestre cómo se comporta la mejor solución encontrada, usando un gráfico del recorrido en el mapa de México.\n\n\n\n\n\nReflexione sobre: - Los resultados obtenidos con las colonias de hormigas y los algoritmos genéticos. - Comparación de costos y tiempo de ejecución.\n\n\n\n\n\n\nPara empezar a solucionar el problema, es necesario obtener información acerca del valor del salario del vendedor, el costo de los peajes y el cálculo correspondiente al costo total destinado a combustible; definiendo entonces el modelo de automóvil a considerar en el ejercicio, junto con su respectivo costo de gasolina. Durante el desarrollo de este proceso de extracción de información se tomaron como referencia las ciudades capitales de cada uno de los estados mexicanos y se observó el mapa de la división política de México en sus 32 estados, a fin de tener un mejor entendimiento de la región.\nFigura 1.\nMapa de México.  Adaptado de Fondo plano de mapa de México [Ilustración], por Freepik, 2024 (https://www.freepik.es/vector-gratis/mapa-mexico). Licencia gratuita.\n\n\nLa tabla de distancias y tiempo de conducción entre las ciudades fue obtenida a través del sitio web Mejores Rutas (2024b), diseñado especialmente para el cálculo y planeación de viajes a lo largo de todo el país. Dicho recurso online permite obtener información como distancias, tiempo de conducción y otros valores asociados entre dos ciudades ingresando el nombre de cada una de ellas.\n\n\n\nPara obtener la información de los peajes, fue utilizado el mismo sitio web Mejores Rutas (2024b), el cual también contiene datos relacionados con el costo actual de los peajes que se encuentran entre las ciudades donde se realiza la consulta.\nDebido al gran número de combinaciones posibles, se programó un bot en Python empleando la librería Beautiful Soup, lo que permitió automatizar la extracción de la información anteriormente mencionada. En el repositorio de GitHub es posible encontrar el archivo con el código para llevar a cabo esta tarea.\n\n\n\n\nEn la siguiente sección se definen los gastos que deben ser consultados, entre los cuales se encuentran el salario del vendedor, el modelo de automóvil a utilizar y su correspondiente gasto de combustible.\n\n\nPara definir el salario del vendedor, se toma como referencia el salario minimo en México, que actualmente se encuentra en 248,93 pesos diarios según la Comisión Nacional de los Salarios Mínimos (CONASAMI) (2024); por lo tanto, para una jornada de 8 horas, el salario mínimo por hora es de 31,12 aproximadamente. Dicho esto, se decide establecer un salario de 35 pesos mexicanos por hora para el vendedor del presente ejercicio.\n\n\n\nDe acuerdo con El País (2024), el modelo de automóvil más vendido actualmente en México es el Nissan Versa, por lo que se ha considerado conveniente seleccionarlo como medio de transporte a utilizar por parte del vendedor. Esto permitirá hacer una estimación más justa del costo total de realizar la ruta por los 32 estados mexicanos en el contexto de dicho país.\nAdicionalmente, es importante considerar que el rendimiento promedio de este modelo en carreteras es de 25 kilómetros por litro de acuerdo con información proporcionada por Redacción De Cero a 100 (2023) y que el tipo de gasolina que utiliza es la comúnmente denominada como “Gasolina Magna” en México la cual, al día 14 de noviembre, tiene un precio promedio de 23.96 pesos mexicanos por litro según GasolinaMX.com (2024).\n\n\n\nSe ha obtenido la información anterior con el objetivo de calcular el costo total de desplazamiento entre las ciudades capitales de México, sin embargo, se observa que no todos los datos se encuentran en las unidades requeridas (MXN): hay magnitudes en litros, horas, kilómetros, etc. Por lo tanto, se realizarán las siguientes transformaciones en todas las unidades para poder sumar dichos gastos en pesos mexicanos, a diferencia del caso de los peajes, pues estos ya se encuentran en la unidad monetaria deseada.\n\n\nEl costo por el salario del vendedor es calculado la forma que se muestra en la Ecuación (1):\n\\[\n\\text{Costo\\_vendedor} = \\text{tiempo} \\times \\text{salario\\_del\\_vendedor} \\tag{1}\n\\]\n\n\n\n\nEl gasto total en gasolina se obtiene con la fórmula mostrada en la Ecuación (2):\n\\[\n\\text{Costo\\_gasolina} = \\left( \\frac{\\text{Distancia}}{\\text{Rendimiento (km/litro)}} \\right) \\times \\text{Precio\\_por\\_litro} \\tag{2}\n\\]\n\n\nDespués de realizar las operaciones mostradas anteriormente, se tiene como resultado toda la información necesaria en las unidades requeridas para obtener un valor correspondiente al gasto total del viaje en pesos mexicanos, de acuerdo con lo definido en la Ecuación (3).\n\\[\n\\text{Gasto\\_recorrido} = \\text{Costo\\_gasolina} + \\text{Costo\\_vendedor} + \\text{Costo\\_Peajes} \\tag{3}\n\\]\n\n\n\n\n\nA continuación, se procede con la utilización de los algoritmos propuestos para este caso: Colonia de Hormigas y Algoritmos Genéticos, con el fin de responder a la actividad planteada al principio del presente ejercicio, esto es, hallar la ruta óptima para el recorrido del vendedor a través de los 32 estados de México.\n\n\nConsiderando la información recolectada en Wikipedia (2024b) y Dorigo and Stützle (2018) y lo presentado en la primera sección del trabajo, puede decirse que los algoritmos de colonia de hormigas (Ant Colony Optimization, ACO) son una técnica de optimización basada en la inteligencia colectiva observada en las colonias de hormigas naturales. Fueron inspirados en el comportamiento de las hormigas en la naturaleza para resolver problemas complejos de optimización combinatoria, en esta segunda parte del trabajo profundizaremos más en sus hiperparámetros claves los cuales son:\n\nCantidad de hormigas: Cantidad de hormigas que participarán en cada iteración de la búsqueda de soluciones. Influye en la capacidad del algoritmo de explorar diferentes soluciones de manera simultánea. En este caso se utilizarán 32 hormigas, es decir, igual al número de estados en México.\nAlpha: Controla la influencia de la feromona en la probabilidad de que una hormiga elija ese camino. A medida que el valor aumenta, las hormigas son más propensas a seguir caminos con más feromona. Aquí se utilizará un valor de 1 para otorgar una influencia moderada de las feromonas depositadas.\nBeta: Controla la preferencia de las hormigas por caminos más “baratos” o prometedores, lo cual ayuda aumentar la exploración. Se va a considerar un valor de 2, puesto que se busca minimizar el costo del viaje\n\\(\\rho\\): Indica la tasa de evaporación de la feromona, lo cual evita que las soluciones previas influencien las iteraciones futuras. Se seleccionó una tasa de evaporación del 0.5, es decir, el 50% de las feromonas se evaporan en cada iteración.\n\\(Q\\): Cantidad de feromona depositada por una hormiga en su recorrido tras encontrar una solución. Se utilizará un valor de 100 para indicar la cantidad de feromonas en el camino.\n\nUna vez definidos los hiperparámetros, se puede continuar con la ejecución del algoritmo de colonia de hormigas, cuyo detalle se puede observar más a profundidad en el repositorio de GitHub. En la Figura 2 se puede observar cómo va variando el costo de realizar el viaje en cada una de las iteraciones que realizó dicho algoritmo.\nFigura 2.\nFunción costo del algoritmo Colonia de Hormigas.  Nota. La gráfica muestra la evolución del costo total del viaje a medida que se ejecutan las diferentes iteraciones del algoritmo, que para este caso fueron 500. Elaboración propia.\nDe acuerdo con la imagen anterior, es posible observar que el costo mínimo se alcanza relativamente rápido, antes de las 100 iteraciones. En este sentido, también es interesante notar que el cálculo de esta función de costo varía al considerar diferentes variaciones que puedan realizarse sobre el planteamiento inicial del problema, comportamiento que se verá más adelante.\nPosteriormente, en la Figura 3 puede verse la ruta óptima encontrada por el algoritmo de colonia de hormigas para que el vendedor pueda recorrer los 32 estados mexicanos.\nFigura 3.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas.  Nota. Puede observarse que esta visualización gráfica está dada por líneas rectas entre cada una de las ciudades y no muestra con fidelidad la forma en que se haría el recrorrido. Elaboración propia.\nCon el fin de que el camino óptimo pueda reflejar la realidad del viaje, en la Figura 4 se ilustra la utilización de la API gratuita Open Route Service para graficar el recorrido propuesto a lo largo de las carreteras en el mapa de México. La API key para acceder a este servicio es la siguiente:\n\n\nCode\napi_key = \"5b3ce3597851110001cf6248c140bc578aac4c2d95295dc798e53a22\"\n\n\nFigura 4.\nForma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas.  Nota. El gráfico muestra las carreteras que deberían seguirse para completar el recorrido propuesto, sin embargo, algunos aspectos siguen siendo siendo interesantes. Elaboración propia.\nComo se mencionó anteriormente, de esta forma se obtiene una ruta óptima más realista. No obstante, llama la atención que, en ciertas secciones, la ruta implica cruzar cuerpos de agua. Al investigar las razones de este comportamiento, se descubrió que para conectar algunos estados del país como Baja California Sur y Sinaloa, la opción de tomar un ferri es considerada la más conveniente según servicios de planificación de trayectos como Mejores Rutas (2024a) y Baja Ferries (2024).\nDado que la matriz de costos actual no considera el valor asociado al uso del ferri ni los gastos asociados al transporte del vehículo para continuar posteriormente el recorrido, se propone un análisis de los siguientes escenarios:\n\nIncluir el costo del ferri en la matriz de costos y evaluar la ruta resultante.\nRealizar el viaje completamente por tierra, excluyendo los estados que se alcanzan únicamente utilizando el ferri.\n\nPrimer escenario\nSe consultó el valor del tiquete de ferri para una persona adulta y el costo del transporte de un automóvil, encontrando que el más económico para un adulto es de 1,460 pesos mexicanos, mientras que el transporte del automóvil tiene un valor de 5,480 pesos mexicanos según Debate (2023).\nEstos costos fueron utilizados como parámetros para el algoritmo de colonia de hormigas, llegando a que, como se observa en la Figura 5, el algoritmo sigue alcanzando un mínimo de manera relativamente rápida.\nFigura 5.\nEvolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri.  Nota. Es interesante notar que, a pesar del incremento en el costo de moverse entre dos estados (debido al ferri), el algoritmo logró encontrar una ruta más barata que la hallada originalmente. Esto sugiere que en la primera solución encontrada el algoritmo podría haberse quedado atascado en un mínimo local debido a la falta de iteraciones. Elaboración propia.\nAdemás, también es posible observar que el tiempo y la distancia se redujeron en esta nueva solución, lo cual permite pensar que esta ruta no solo es más económica, sino también más eficiente, a pesar de que está considerando el costo adicional del ferri y el transporte del vehículo.\nLos resultados correspondientes a la visualización gráfica del camino óptimo encontrado para el vendedor en este escenario pueden observarse a continuación, en las Figuras 6 y 7.\nFigura 6.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri.  Nota. Las observaciones respecto a la forma en que se conectan los distintos puntos del recorrido permanecen iguales que en el caso considerado originalmente. Elaboración propia.\nFigura 7.\nCarreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas.  Nota. Esta imagen también fue generada por medio del uso de la API gratuita, así que sus resultados son reproducibles. Elaboración propia.\nSegundo escenario\nEn este segundo escenario, la ciudad de La Paz fue eliminada del recorrido, por lo que el viaje ahora solo incluye los 31 estados restantes. En consecuencia, también se redujo la cantidad de hormigas utilizadas en el algoritmo a un valor de 31, asignando una hormiga por estado para realizar la búsqueda.\nComo era de esperarse, el precio del recorrido se redujo en este caso. Sin embargo, al algoritmo le tomó muchas más iteraciones encontrar el costo mínimo, como se observa en la Figura 8.\nFigura 8.\nEvolución de la función costo para los 31 estados de México.  Nota. El hecho de que el planteamiento inicial de ciudades y estados a recorrer cambiara al no tener en cuenta el estado que solamente puede ser conectado vía marítima fue un factor determinante en la ejecución del algoritmo de hormigas, siendo mucho menos rápido que en el primer escenario (incluso que en el escenario original). Elaboración propia.\nA diferencia del caso anterior, la Figura 8 también muestra que la distancia y el tiempo aumentaron. Esto se debe a que, al no utilizar el ferri, el automóvil tuvo que realizar un recorrido más largo en ciertas partes para completar su ruta. Por lo tanto, aunque esta solución es más eficiente en términos de costo, no lo es en términos de tiempo y distancia recorrida.\nLa visualización gráfica de los resultados obtenidos para este caso pueden observarse en las Figuras 9 y 10, teniendo en cuenta las mismas consideraciones anteriormente mencionadas.\nFigura 9.\nRuta óptima encontrada mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Elaboración propia.\nFigura 10.\nOrden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Nota. Sumado a los inconvenientes observados en este escenario, al desconectar uno de los estados de México, puede observarse que una gran región del país queda excluida del recorrido del vendedor, lo que puede implicar significativas pérdidas económicas y oportunidades de establecer nuevos negocios.\n\n\n\nDe acuerdo con información proporcionada por José Ángel Fernández Prieto (2029) y encontrada en Wikipedia (2024a), y como se explico en la primera sección del trabajo, puede decirse que los algoritmos genéticos (Genetic Algorithms, GA) son una técnica de optimización inspirada en los principios de la selección natural y la evolución biológica. Los GA buscan soluciones óptimas mediante la creación, evaluación y modificación de una población de individuos, representando posibles soluciones a un problema dado. La evolución de la población se realiza mediante operadores genéticos como la mutación y en esta sección profundizaremos más en sus hiperparámetros clave, los cuales son:\n\nTamaño de la población: Define el número de individuos en cada generación. Un tamaño de población más grande permite una mejor exploración del espacio de soluciones, pero también aumenta el tiempo de cómputo. En este caso, se utilizará una población de 100 individuos, lo que proporciona un equilibrio adecuado entre diversidad y eficiencia computacional.\nNúmero de generaciones: Especifica cuántas veces se evolucionará la población mediante el proceso de selección, cruce y mutación; se consideran adecuadas un total de 200 generaciones para permitir al algoritmo explorar el espacio de búsqueda y converger hacia una solución óptima o cercana al óptimo.\nTasa de mutación: Representa la probabilidad de que un gen sea modificado aleatoriamente en un individuo. La mutación introduce variación genética, lo que ayuda a explorar nuevas áreas del espacio de búsqueda y a evitar estancamientos en óptimos locales. Se empleará una tasa de mutación de 0.1 (10%), lo que mantiene una buena cantidad de diversidad sin perturbar excesivamente a la población.\n\nDe la misma manera en que se realizó en la sección anterior, la presentación de resultados comienza con una obtención de resultados iniciales considerando los 32 estados de México y sin tener en cuenta el costo del ferri.\nComo se observa en la Figura 11, alcanzar el mínimo toma casi 175 generaciones, lo que indica que este algoritmo se demora más en llegar a un valor mínimo en comparación con el algoritmo de colonia de hormigas. Además, la solución que encuentra tiene un costo mayor y toma más tiempo y una mayor distancia completarla.\nFigura 11.\nEvolución de la función costo del algoritmo genético.  Nota. En la ejecución de este algoritmo, la solución óptima se encontró en una iteración muy cercana al límite máximo establecido, a diferencia del algoritmo de colonia de hormigas, que lo realizó muy rápidamente. Elaboración propia.\nAhora bien, en las Figuras 12 y 13 se tiene la visualización gráfica del recorrido propuesto por este algoritmo, siguiendo los mismos procedimientos de utilización de la API que se mencionaron de manera previa.\nFigura 12.\nRuta óptima encontrada mediante algoritmo genético.  Elaboración propia.\nFigura 13.\nRuta óptima con las carreteras encontrada mediante algoritmo genético.  Elaboración propia.\nNuevamente, se considera pertinente considerar los dos escenarios adicionales de análisis: un nuevo cálculo de costos teniendo en cuenta el tiquete de ferri y el transporte adicional para el automóvil y la exclusión La Paz, como territorio que solo puede conectarse a través de cuerpos de agua.\nPrimer escenario\nEs posible observar que al tomar en cuenta el costo del ferri, en este caso sí se aumenta el costo del camino óptimo y el número de iteraciones se reduce un poco, como puede verse en la Figura 14. Sin embargo, el tiempo que toma completar esta ruta es mucho más alto que en el caso anterior, lo que podría indicar que esta solución se quedó atrapada en un mínimo local.\nFigura 14.\nEvolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri.  Elaboración propia.\nPor otra parte, en las Figuras 15 y 16 se puede observar el recorrido propuesto por esta solución del algoritmo para que el vendedor se desplace por todo el país, viendo que los puntos de inicio y finalización son diferentes a los que había arrojado como resultado el algoritmo de colonia de hormigas.\nFigura 15.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri.  Nota. Sabiendo que la ruta marítima que seleccionaron ambos algoritmos es la misma, puede decirse que las diferencias entre sus resultados radican en otros aspectos inherentes a su propia definición, como pueden serlo los hiperparámetros y la forma en que realizan una búsqueda de la solución óptima. Elaboración propia.\nFigura 16.\nRuta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri.  Nota. La utilización de la API se dio exactamente igual que en los escenarios anteriores, de manera que estos resultados también son reproducibles.\nSegundo escenario\nEn este último escenario, el cual solamente considera 31 de los estados de México, es posible notar que el costo óptimo nuevamente bajó y, a diferencia del algoritmo de colonia de hormigas, el algoritmo genético sí encuentra una forma de reducir el tiempo y la distancia del recorrido, mostrando una mejoría en ese aspecto.\nDe acuerdo con la Figura 17, en este escenario el algoritmo genético necesitó más iteraciones para encontrar un mínimo, lo cual se ve compensado por el hecho de que mejoró el desempeño del algoritmo de colonia de hormigas en términos de las variables anteriormente mencionadas.\nFigura 17.\nEvolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México.  Elaboración propia.\nFinalmente, las Figuras 18 y 19 permiten observar el recorrido que debería realizar el vendedor de acuerdo con este escenario propuesto, en el que también queda aislada una amplia región del país debido a la decisión de no considerar recorridos que no fueran terrestres.\nFigura 18.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México.  Elaboración propia.\nFigura 19.\nRuta óptima de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México.  Nota. Al observar las carreteras que debería recorrer esta solución, puede observarse que el vendedor terminaría pasando por los mismos caminos varias veces, ya que deben darse varios recorridos de manera repetida por la necesidad de conectar algunos territorios de los 31 estados sin contemplar la opción del viaje en ferri. Elaboración propia.\n\n\n\n\nEs importante evaluar qué tan buena es la solución alcanzada. Métodos exhaustivos como la fuerza bruta, que permiten comprobar cuál es la mejor solución entre todas las posibles, resultan computacionalmente inviables en este caso. Aprovechando que disponemos de un gran número de iteraciones y tres diferentes escenarios que nos permiten variar las condiciones del problema, podemos concluir que la solución obtenida es, al menos, razonablemente buena.\nAdemás, es relevante analizar el comportamiento de las funciones de costo. En todos los escenarios se observa que el costo se reduce significativamente al principio y luego comienza a fluctuar alrededor de una media estable. Esto indica que el algoritmo está convergiendo hacia esos valores. A partir de este comportamiento, seleccionamos la solución con el menor costo como la mejor alternativa.\nEn general, las funciones de costo tienden a estabilizarse dentro de un rango limitado de valores. Este patrón nos permite confiar en que las soluciones obtenidas se encuentran entre las mejores posibles, considerando las limitaciones inherentes a los métodos no determinísticos.\n\n\n\nLos resultados obtenidos al aplicar el Algoritmo de Colonia de Hormigas y el Algoritmo Genético en tres situaciones diferentes permiten destacar las fortalezas y diferencias de cada uno. Por un lado, el Algoritmo de Colonia de Hormigas logra encontrar una solución más económica y en un menor número de iteraciones en comparación con el Algoritmo Genético. Por lo tanto, en esta evaluación específica, dicho algoritmo puede considerarse más eficiente para resolver el problema en esta situación particular.\nNo obstante, es importante señalar que la elección del algoritmo adecuado depende en gran medida de la naturaleza del problema. Incluso para un mismo problema, diferentes enfoques pueden llevar a variaciones significativas en los resultados, como se observó en este análisis. Aunque en este caso el Algoritmo de Colonia de Hormigas demostró ser más eficiente que el Algoritmo Genético, esta ventaja es altamente circunstancial y no necesariamente aplicable a todos los contextos. Esto refuerza la importancia de adaptar la metodología a las características específicas del problema a resolver.\nEn concordancia con lo anterior, es posible encontrar en las Figuras 20 y 21 una compilación de las soluciones encontradas con el algoritmo de colonia de hormigas y el algoritmo genético.\nFigura 20\nSoluciones obtenidas mediante el algoritmo de colonia de hormigas para la optimización de la ruta en las carreteras identificadas.  Nota. Esta animación muestra las variaciones en las rutas óptimas propuestas por el algoritmo de colonia de hormigas para los tres escenarios que fueron analizados durante el desarrollo del presente ejercicio. Elaboración propia.\nSoluciones obtenidas mediante el algoritmo genético para la optimización de la ruta en las carreteras identificadas.  Nota. Igualmente, en esta animación se muestran las diferentes rutas óptimas propuestas por el algoritmo genético para los tres escenarios que fueron analizados durante el desarrollo del presente ejercicio. Elaboración propia.\n\n\n\n\nLas contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo de los ejercicios correspondientes a Optimización Heurística y Optimización Combinatoria se muestran en el siguiente video."
  },
  {
    "objectID": "posts/optimizacion_combinatoria/index.html#problema-del-viajero",
    "href": "posts/optimizacion_combinatoria/index.html#problema-del-viajero",
    "title": "Optimización Combinatoria",
    "section": "",
    "text": "Un vendedor debe realizar un recorrido por todas las capitales de los 32 estados de los Estados Unidos Mexicanos.\n\n\n\nOptimización con métodos metaheurísticos:\n\nUtilice colonias de hormigas para encontrar el orden óptimo del recorrido.\nUtilice algoritmos genéticos para encontrar el orden óptimo del recorrido.\n\nCosto del recorrido:\n\nEl costo de desplazamiento entre ciudades se calcula como la suma de:\n\nEl valor de la hora del vendedor (este es un parámetro que debe estudiarse).\nEl costo de los peajes.\nEl costo del combustible.\n\nCada equipo debe definir el vehículo que utilizará el vendedor para realizar el recorrido y, con base en esta elección, calcular el costo del combustible.\n\n\n\n\n\n\nCree un GIF animado o un video que muestre cómo se comporta la mejor solución encontrada, usando un gráfico del recorrido en el mapa de México.\n\n\n\n\n\nReflexione sobre: - Los resultados obtenidos con las colonias de hormigas y los algoritmos genéticos. - Comparación de costos y tiempo de ejecución."
  },
  {
    "objectID": "posts/optimizacion_combinatoria/index.html#solución-de-las-tareas-propuestas",
    "href": "posts/optimizacion_combinatoria/index.html#solución-de-las-tareas-propuestas",
    "title": "Optimización Combinatoria",
    "section": "",
    "text": "Para empezar a solucionar el problema, es necesario obtener información acerca del valor del salario del vendedor, el costo de los peajes y el cálculo correspondiente al costo total destinado a combustible; definiendo entonces el modelo de automóvil a considerar en el ejercicio, junto con su respectivo costo de gasolina. Durante el desarrollo de este proceso de extracción de información se tomaron como referencia las ciudades capitales de cada uno de los estados mexicanos y se observó el mapa de la división política de México en sus 32 estados, a fin de tener un mejor entendimiento de la región.\nFigura 1.\nMapa de México.  Adaptado de Fondo plano de mapa de México [Ilustración], por Freepik, 2024 (https://www.freepik.es/vector-gratis/mapa-mexico). Licencia gratuita.\n\n\nLa tabla de distancias y tiempo de conducción entre las ciudades fue obtenida a través del sitio web Mejores Rutas (2024b), diseñado especialmente para el cálculo y planeación de viajes a lo largo de todo el país. Dicho recurso online permite obtener información como distancias, tiempo de conducción y otros valores asociados entre dos ciudades ingresando el nombre de cada una de ellas.\n\n\n\nPara obtener la información de los peajes, fue utilizado el mismo sitio web Mejores Rutas (2024b), el cual también contiene datos relacionados con el costo actual de los peajes que se encuentran entre las ciudades donde se realiza la consulta.\nDebido al gran número de combinaciones posibles, se programó un bot en Python empleando la librería Beautiful Soup, lo que permitió automatizar la extracción de la información anteriormente mencionada. En el repositorio de GitHub es posible encontrar el archivo con el código para llevar a cabo esta tarea.\n\n\n\n\nEn la siguiente sección se definen los gastos que deben ser consultados, entre los cuales se encuentran el salario del vendedor, el modelo de automóvil a utilizar y su correspondiente gasto de combustible.\n\n\nPara definir el salario del vendedor, se toma como referencia el salario minimo en México, que actualmente se encuentra en 248,93 pesos diarios según la Comisión Nacional de los Salarios Mínimos (CONASAMI) (2024); por lo tanto, para una jornada de 8 horas, el salario mínimo por hora es de 31,12 aproximadamente. Dicho esto, se decide establecer un salario de 35 pesos mexicanos por hora para el vendedor del presente ejercicio.\n\n\n\nDe acuerdo con El País (2024), el modelo de automóvil más vendido actualmente en México es el Nissan Versa, por lo que se ha considerado conveniente seleccionarlo como medio de transporte a utilizar por parte del vendedor. Esto permitirá hacer una estimación más justa del costo total de realizar la ruta por los 32 estados mexicanos en el contexto de dicho país.\nAdicionalmente, es importante considerar que el rendimiento promedio de este modelo en carreteras es de 25 kilómetros por litro de acuerdo con información proporcionada por Redacción De Cero a 100 (2023) y que el tipo de gasolina que utiliza es la comúnmente denominada como “Gasolina Magna” en México la cual, al día 14 de noviembre, tiene un precio promedio de 23.96 pesos mexicanos por litro según GasolinaMX.com (2024).\n\n\n\nSe ha obtenido la información anterior con el objetivo de calcular el costo total de desplazamiento entre las ciudades capitales de México, sin embargo, se observa que no todos los datos se encuentran en las unidades requeridas (MXN): hay magnitudes en litros, horas, kilómetros, etc. Por lo tanto, se realizarán las siguientes transformaciones en todas las unidades para poder sumar dichos gastos en pesos mexicanos, a diferencia del caso de los peajes, pues estos ya se encuentran en la unidad monetaria deseada.\n\n\nEl costo por el salario del vendedor es calculado la forma que se muestra en la Ecuación (1):\n\\[\n\\text{Costo\\_vendedor} = \\text{tiempo} \\times \\text{salario\\_del\\_vendedor} \\tag{1}\n\\]\n\n\n\n\nEl gasto total en gasolina se obtiene con la fórmula mostrada en la Ecuación (2):\n\\[\n\\text{Costo\\_gasolina} = \\left( \\frac{\\text{Distancia}}{\\text{Rendimiento (km/litro)}} \\right) \\times \\text{Precio\\_por\\_litro} \\tag{2}\n\\]\n\n\nDespués de realizar las operaciones mostradas anteriormente, se tiene como resultado toda la información necesaria en las unidades requeridas para obtener un valor correspondiente al gasto total del viaje en pesos mexicanos, de acuerdo con lo definido en la Ecuación (3).\n\\[\n\\text{Gasto\\_recorrido} = \\text{Costo\\_gasolina} + \\text{Costo\\_vendedor} + \\text{Costo\\_Peajes} \\tag{3}\n\\]\n\n\n\n\n\nA continuación, se procede con la utilización de los algoritmos propuestos para este caso: Colonia de Hormigas y Algoritmos Genéticos, con el fin de responder a la actividad planteada al principio del presente ejercicio, esto es, hallar la ruta óptima para el recorrido del vendedor a través de los 32 estados de México.\n\n\nConsiderando la información recolectada en Wikipedia (2024b) y Dorigo and Stützle (2018) y lo presentado en la primera sección del trabajo, puede decirse que los algoritmos de colonia de hormigas (Ant Colony Optimization, ACO) son una técnica de optimización basada en la inteligencia colectiva observada en las colonias de hormigas naturales. Fueron inspirados en el comportamiento de las hormigas en la naturaleza para resolver problemas complejos de optimización combinatoria, en esta segunda parte del trabajo profundizaremos más en sus hiperparámetros claves los cuales son:\n\nCantidad de hormigas: Cantidad de hormigas que participarán en cada iteración de la búsqueda de soluciones. Influye en la capacidad del algoritmo de explorar diferentes soluciones de manera simultánea. En este caso se utilizarán 32 hormigas, es decir, igual al número de estados en México.\nAlpha: Controla la influencia de la feromona en la probabilidad de que una hormiga elija ese camino. A medida que el valor aumenta, las hormigas son más propensas a seguir caminos con más feromona. Aquí se utilizará un valor de 1 para otorgar una influencia moderada de las feromonas depositadas.\nBeta: Controla la preferencia de las hormigas por caminos más “baratos” o prometedores, lo cual ayuda aumentar la exploración. Se va a considerar un valor de 2, puesto que se busca minimizar el costo del viaje\n\\(\\rho\\): Indica la tasa de evaporación de la feromona, lo cual evita que las soluciones previas influencien las iteraciones futuras. Se seleccionó una tasa de evaporación del 0.5, es decir, el 50% de las feromonas se evaporan en cada iteración.\n\\(Q\\): Cantidad de feromona depositada por una hormiga en su recorrido tras encontrar una solución. Se utilizará un valor de 100 para indicar la cantidad de feromonas en el camino.\n\nUna vez definidos los hiperparámetros, se puede continuar con la ejecución del algoritmo de colonia de hormigas, cuyo detalle se puede observar más a profundidad en el repositorio de GitHub. En la Figura 2 se puede observar cómo va variando el costo de realizar el viaje en cada una de las iteraciones que realizó dicho algoritmo.\nFigura 2.\nFunción costo del algoritmo Colonia de Hormigas.  Nota. La gráfica muestra la evolución del costo total del viaje a medida que se ejecutan las diferentes iteraciones del algoritmo, que para este caso fueron 500. Elaboración propia.\nDe acuerdo con la imagen anterior, es posible observar que el costo mínimo se alcanza relativamente rápido, antes de las 100 iteraciones. En este sentido, también es interesante notar que el cálculo de esta función de costo varía al considerar diferentes variaciones que puedan realizarse sobre el planteamiento inicial del problema, comportamiento que se verá más adelante.\nPosteriormente, en la Figura 3 puede verse la ruta óptima encontrada por el algoritmo de colonia de hormigas para que el vendedor pueda recorrer los 32 estados mexicanos.\nFigura 3.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas.  Nota. Puede observarse que esta visualización gráfica está dada por líneas rectas entre cada una de las ciudades y no muestra con fidelidad la forma en que se haría el recrorrido. Elaboración propia.\nCon el fin de que el camino óptimo pueda reflejar la realidad del viaje, en la Figura 4 se ilustra la utilización de la API gratuita Open Route Service para graficar el recorrido propuesto a lo largo de las carreteras en el mapa de México. La API key para acceder a este servicio es la siguiente:\n\n\nCode\napi_key = \"5b3ce3597851110001cf6248c140bc578aac4c2d95295dc798e53a22\"\n\n\nFigura 4.\nForma realista del camino óptimo encontrado mediante el uso del algoritmo de Colonia de Hormigas.  Nota. El gráfico muestra las carreteras que deberían seguirse para completar el recorrido propuesto, sin embargo, algunos aspectos siguen siendo siendo interesantes. Elaboración propia.\nComo se mencionó anteriormente, de esta forma se obtiene una ruta óptima más realista. No obstante, llama la atención que, en ciertas secciones, la ruta implica cruzar cuerpos de agua. Al investigar las razones de este comportamiento, se descubrió que para conectar algunos estados del país como Baja California Sur y Sinaloa, la opción de tomar un ferri es considerada la más conveniente según servicios de planificación de trayectos como Mejores Rutas (2024a) y Baja Ferries (2024).\nDado que la matriz de costos actual no considera el valor asociado al uso del ferri ni los gastos asociados al transporte del vehículo para continuar posteriormente el recorrido, se propone un análisis de los siguientes escenarios:\n\nIncluir el costo del ferri en la matriz de costos y evaluar la ruta resultante.\nRealizar el viaje completamente por tierra, excluyendo los estados que se alcanzan únicamente utilizando el ferri.\n\nPrimer escenario\nSe consultó el valor del tiquete de ferri para una persona adulta y el costo del transporte de un automóvil, encontrando que el más económico para un adulto es de 1,460 pesos mexicanos, mientras que el transporte del automóvil tiene un valor de 5,480 pesos mexicanos según Debate (2023).\nEstos costos fueron utilizados como parámetros para el algoritmo de colonia de hormigas, llegando a que, como se observa en la Figura 5, el algoritmo sigue alcanzando un mínimo de manera relativamente rápida.\nFigura 5.\nEvolución de la función costo del algoritmo de Colonia de Hormigas teniendo en cuenta al ferri.  Nota. Es interesante notar que, a pesar del incremento en el costo de moverse entre dos estados (debido al ferri), el algoritmo logró encontrar una ruta más barata que la hallada originalmente. Esto sugiere que en la primera solución encontrada el algoritmo podría haberse quedado atascado en un mínimo local debido a la falta de iteraciones. Elaboración propia.\nAdemás, también es posible observar que el tiempo y la distancia se redujeron en esta nueva solución, lo cual permite pensar que esta ruta no solo es más económica, sino también más eficiente, a pesar de que está considerando el costo adicional del ferri y el transporte del vehículo.\nLos resultados correspondientes a la visualización gráfica del camino óptimo encontrado para el vendedor en este escenario pueden observarse a continuación, en las Figuras 6 y 7.\nFigura 6.\nRuta óptima encontrada mediante el algoritmo de Colonia de Hormigas teniendo en cuenta el costo del ferri.  Nota. Las observaciones respecto a la forma en que se conectan los distintos puntos del recorrido permanecen iguales que en el caso considerado originalmente. Elaboración propia.\nFigura 7.\nCarreteras encontradas mediante el uso del algoritmo de Colonia de Hormigas.  Nota. Esta imagen también fue generada por medio del uso de la API gratuita, así que sus resultados son reproducibles. Elaboración propia.\nSegundo escenario\nEn este segundo escenario, la ciudad de La Paz fue eliminada del recorrido, por lo que el viaje ahora solo incluye los 31 estados restantes. En consecuencia, también se redujo la cantidad de hormigas utilizadas en el algoritmo a un valor de 31, asignando una hormiga por estado para realizar la búsqueda.\nComo era de esperarse, el precio del recorrido se redujo en este caso. Sin embargo, al algoritmo le tomó muchas más iteraciones encontrar el costo mínimo, como se observa en la Figura 8.\nFigura 8.\nEvolución de la función costo para los 31 estados de México.  Nota. El hecho de que el planteamiento inicial de ciudades y estados a recorrer cambiara al no tener en cuenta el estado que solamente puede ser conectado vía marítima fue un factor determinante en la ejecución del algoritmo de hormigas, siendo mucho menos rápido que en el primer escenario (incluso que en el escenario original). Elaboración propia.\nA diferencia del caso anterior, la Figura 8 también muestra que la distancia y el tiempo aumentaron. Esto se debe a que, al no utilizar el ferri, el automóvil tuvo que realizar un recorrido más largo en ciertas partes para completar su ruta. Por lo tanto, aunque esta solución es más eficiente en términos de costo, no lo es en términos de tiempo y distancia recorrida.\nLa visualización gráfica de los resultados obtenidos para este caso pueden observarse en las Figuras 9 y 10, teniendo en cuenta las mismas consideraciones anteriormente mencionadas.\nFigura 9.\nRuta óptima encontrada mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Elaboración propia.\nFigura 10.\nOrden de las carreteras encontrado mediante el uso del algoritmo de Colonia de Hormigas para 31 estados de México.  Nota. Sumado a los inconvenientes observados en este escenario, al desconectar uno de los estados de México, puede observarse que una gran región del país queda excluida del recorrido del vendedor, lo que puede implicar significativas pérdidas económicas y oportunidades de establecer nuevos negocios.\n\n\n\nDe acuerdo con información proporcionada por José Ángel Fernández Prieto (2029) y encontrada en Wikipedia (2024a), y como se explico en la primera sección del trabajo, puede decirse que los algoritmos genéticos (Genetic Algorithms, GA) son una técnica de optimización inspirada en los principios de la selección natural y la evolución biológica. Los GA buscan soluciones óptimas mediante la creación, evaluación y modificación de una población de individuos, representando posibles soluciones a un problema dado. La evolución de la población se realiza mediante operadores genéticos como la mutación y en esta sección profundizaremos más en sus hiperparámetros clave, los cuales son:\n\nTamaño de la población: Define el número de individuos en cada generación. Un tamaño de población más grande permite una mejor exploración del espacio de soluciones, pero también aumenta el tiempo de cómputo. En este caso, se utilizará una población de 100 individuos, lo que proporciona un equilibrio adecuado entre diversidad y eficiencia computacional.\nNúmero de generaciones: Especifica cuántas veces se evolucionará la población mediante el proceso de selección, cruce y mutación; se consideran adecuadas un total de 200 generaciones para permitir al algoritmo explorar el espacio de búsqueda y converger hacia una solución óptima o cercana al óptimo.\nTasa de mutación: Representa la probabilidad de que un gen sea modificado aleatoriamente en un individuo. La mutación introduce variación genética, lo que ayuda a explorar nuevas áreas del espacio de búsqueda y a evitar estancamientos en óptimos locales. Se empleará una tasa de mutación de 0.1 (10%), lo que mantiene una buena cantidad de diversidad sin perturbar excesivamente a la población.\n\nDe la misma manera en que se realizó en la sección anterior, la presentación de resultados comienza con una obtención de resultados iniciales considerando los 32 estados de México y sin tener en cuenta el costo del ferri.\nComo se observa en la Figura 11, alcanzar el mínimo toma casi 175 generaciones, lo que indica que este algoritmo se demora más en llegar a un valor mínimo en comparación con el algoritmo de colonia de hormigas. Además, la solución que encuentra tiene un costo mayor y toma más tiempo y una mayor distancia completarla.\nFigura 11.\nEvolución de la función costo del algoritmo genético.  Nota. En la ejecución de este algoritmo, la solución óptima se encontró en una iteración muy cercana al límite máximo establecido, a diferencia del algoritmo de colonia de hormigas, que lo realizó muy rápidamente. Elaboración propia.\nAhora bien, en las Figuras 12 y 13 se tiene la visualización gráfica del recorrido propuesto por este algoritmo, siguiendo los mismos procedimientos de utilización de la API que se mencionaron de manera previa.\nFigura 12.\nRuta óptima encontrada mediante algoritmo genético.  Elaboración propia.\nFigura 13.\nRuta óptima con las carreteras encontrada mediante algoritmo genético.  Elaboración propia.\nNuevamente, se considera pertinente considerar los dos escenarios adicionales de análisis: un nuevo cálculo de costos teniendo en cuenta el tiquete de ferri y el transporte adicional para el automóvil y la exclusión La Paz, como territorio que solo puede conectarse a través de cuerpos de agua.\nPrimer escenario\nEs posible observar que al tomar en cuenta el costo del ferri, en este caso sí se aumenta el costo del camino óptimo y el número de iteraciones se reduce un poco, como puede verse en la Figura 14. Sin embargo, el tiempo que toma completar esta ruta es mucho más alto que en el caso anterior, lo que podría indicar que esta solución se quedó atrapada en un mínimo local.\nFigura 14.\nEvolución de la función costo del algoritmo genético teniendo en cuenta el costo del ferri.  Elaboración propia.\nPor otra parte, en las Figuras 15 y 16 se puede observar el recorrido propuesto por esta solución del algoritmo para que el vendedor se desplace por todo el país, viendo que los puntos de inicio y finalización son diferentes a los que había arrojado como resultado el algoritmo de colonia de hormigas.\nFigura 15.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta el costo del ferri.  Nota. Sabiendo que la ruta marítima que seleccionaron ambos algoritmos es la misma, puede decirse que las diferencias entre sus resultados radican en otros aspectos inherentes a su propia definición, como pueden serlo los hiperparámetros y la forma en que realizan una búsqueda de la solución óptima. Elaboración propia.\nFigura 16.\nRuta óptima de carreteras encontrada mediante algoritmo genético teniendo en cuenta el costo del ferri.  Nota. La utilización de la API se dio exactamente igual que en los escenarios anteriores, de manera que estos resultados también son reproducibles.\nSegundo escenario\nEn este último escenario, el cual solamente considera 31 de los estados de México, es posible notar que el costo óptimo nuevamente bajó y, a diferencia del algoritmo de colonia de hormigas, el algoritmo genético sí encuentra una forma de reducir el tiempo y la distancia del recorrido, mostrando una mejoría en ese aspecto.\nDe acuerdo con la Figura 17, en este escenario el algoritmo genético necesitó más iteraciones para encontrar un mínimo, lo cual se ve compensado por el hecho de que mejoró el desempeño del algoritmo de colonia de hormigas en términos de las variables anteriormente mencionadas.\nFigura 17.\nEvolución de la función costo del algoritmo genético cuando se tienen en cuenta 31 estados de México.  Elaboración propia.\nFinalmente, las Figuras 18 y 19 permiten observar el recorrido que debería realizar el vendedor de acuerdo con este escenario propuesto, en el que también queda aislada una amplia región del país debido a la decisión de no considerar recorridos que no fueran terrestres.\nFigura 18.\nRuta óptima encontrada mediante algoritmos genéticos teniendo en cuenta solo 31 estados de México.  Elaboración propia.\nFigura 19.\nRuta óptima de carreteras encontrada mediante algoritmos genéticos teniendo en cuenta 31 de los estados de México.  Nota. Al observar las carreteras que debería recorrer esta solución, puede observarse que el vendedor terminaría pasando por los mismos caminos varias veces, ya que deben darse varios recorridos de manera repetida por la necesidad de conectar algunos territorios de los 31 estados sin contemplar la opción del viaje en ferri. Elaboración propia.\n\n\n\n\nEs importante evaluar qué tan buena es la solución alcanzada. Métodos exhaustivos como la fuerza bruta, que permiten comprobar cuál es la mejor solución entre todas las posibles, resultan computacionalmente inviables en este caso. Aprovechando que disponemos de un gran número de iteraciones y tres diferentes escenarios que nos permiten variar las condiciones del problema, podemos concluir que la solución obtenida es, al menos, razonablemente buena.\nAdemás, es relevante analizar el comportamiento de las funciones de costo. En todos los escenarios se observa que el costo se reduce significativamente al principio y luego comienza a fluctuar alrededor de una media estable. Esto indica que el algoritmo está convergiendo hacia esos valores. A partir de este comportamiento, seleccionamos la solución con el menor costo como la mejor alternativa.\nEn general, las funciones de costo tienden a estabilizarse dentro de un rango limitado de valores. Este patrón nos permite confiar en que las soluciones obtenidas se encuentran entre las mejores posibles, considerando las limitaciones inherentes a los métodos no determinísticos.\n\n\n\nLos resultados obtenidos al aplicar el Algoritmo de Colonia de Hormigas y el Algoritmo Genético en tres situaciones diferentes permiten destacar las fortalezas y diferencias de cada uno. Por un lado, el Algoritmo de Colonia de Hormigas logra encontrar una solución más económica y en un menor número de iteraciones en comparación con el Algoritmo Genético. Por lo tanto, en esta evaluación específica, dicho algoritmo puede considerarse más eficiente para resolver el problema en esta situación particular.\nNo obstante, es importante señalar que la elección del algoritmo adecuado depende en gran medida de la naturaleza del problema. Incluso para un mismo problema, diferentes enfoques pueden llevar a variaciones significativas en los resultados, como se observó en este análisis. Aunque en este caso el Algoritmo de Colonia de Hormigas demostró ser más eficiente que el Algoritmo Genético, esta ventaja es altamente circunstancial y no necesariamente aplicable a todos los contextos. Esto refuerza la importancia de adaptar la metodología a las características específicas del problema a resolver.\nEn concordancia con lo anterior, es posible encontrar en las Figuras 20 y 21 una compilación de las soluciones encontradas con el algoritmo de colonia de hormigas y el algoritmo genético.\nFigura 20\nSoluciones obtenidas mediante el algoritmo de colonia de hormigas para la optimización de la ruta en las carreteras identificadas.  Nota. Esta animación muestra las variaciones en las rutas óptimas propuestas por el algoritmo de colonia de hormigas para los tres escenarios que fueron analizados durante el desarrollo del presente ejercicio. Elaboración propia.\nSoluciones obtenidas mediante el algoritmo genético para la optimización de la ruta en las carreteras identificadas.  Nota. Igualmente, en esta animación se muestran las diferentes rutas óptimas propuestas por el algoritmo genético para los tres escenarios que fueron analizados durante el desarrollo del presente ejercicio. Elaboración propia."
  },
  {
    "objectID": "posts/optimizacion_combinatoria/index.html#contribuciones-individuales",
    "href": "posts/optimizacion_combinatoria/index.html#contribuciones-individuales",
    "title": "Optimización Combinatoria",
    "section": "",
    "text": "Las contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo de los ejercicios correspondientes a Optimización Heurística y Optimización Combinatoria se muestran en el siguiente video."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portafolio trabajos",
    "section": "",
    "text": "Modelos de riesgo de crédito con Redes Neuronales Artificiales\n\n\n\n\n\n\nredes neuronales artificiales\n\n\ndesarrollo web\n\n\npython\n\n\n\n\n\n\n\n\n\nJan 23, 2025\n\n\nJulián Castaño Pineda, Luis Andrés Altamar Romero, Catalina Restrepo Salgado, Tomás Rodríguez Taborda\n\n\n\n\n\n\n\n\n\n\n\n\nOptimización Combinatoria\n\n\n\n\n\n\noptimización\n\n\nmétodos combinatorios\n\n\npython\n\n\n\n\n\n\n\n\n\nNov 29, 2024\n\n\nJulián Castaño Pineda, Luis Andrés Altamar Romero, Catalina Restrepo Salgado, Tomás Rodríguez Taborda\n\n\n\n\n\n\n\n\n\n\n\n\nOptimización Heurística\n\n\n\n\n\n\noptimización\n\n\nmétodos heurísticos\n\n\npython\n\n\n\n\n\n\n\n\n\nNov 29, 2024\n\n\nJulián Castaño Pineda, Luis Andrés Altamar Romero, Catalina Restrepo Salgado, Tomás Rodríguez Taborda\n\n\n\n\n\n\n\n\n\n\n\n\n¡Bienvenidos a nuestro blog!\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca de",
    "section": "",
    "text": "Este blog ha sido diseñado como parte de un curso dedicado a las Redes Neuronales y Algoritmos Bioinspirados, con el propósito de servir como un repositorio de trabajos, reflexiones y aprendizajes desarrollados a lo largo del programa. Más allá del curso, nuestro objetivo es que este espacio evolucione hacia un portafolio que abarque múltiples temáticas en inteligencia artificial, analítica avanzada y aprendizaje automático."
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html",
    "href": "posts/modelos-riesgo-credito/index.html",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "",
    "text": "El riesgo de crédito, de acuerdo con información encontrada en el sitio web Financionario (n.d.) y, en concordancia con lo dicho por Tamplin (2023), se define como una medida empleada para dimensionar el riesgo (en términos de probabilidad) de que un prestatario incumpla con el pago de una obligación financiera o el reembolso del dinero correspondiente a un préstamo.\nEn este sentido, es posible notar que una correcta evaluación y gestión del riesgo de crédito es de vital importancia en las actividades relacionadas con el préstamo y la inversión, pues ayudan a que las entidades financieras puedan mantener su estabilidad, a la misma vez que se proyectan como instituciones de confianza ante las entidades estatales, sus socios y clientes. Adicionalmente, el riesgo de crédito suele tenerse en cuenta como un criterio a la hora de aprobar o definir las condiciones de un préstamo, solicitando garantías de respaldo al prestatario o ajustando la tasa de interés de acuerdo con estos resultados.\nSabiendo lo anterior, puede decirse que, tanto para las instituciones financieras como para quienes solicitan estos servicios, el riesgo de crédito es un factor de incertidumbre que influye en la toma de decisiones relacionada con la admisión de préstamos y otros productos financieros, entendiendo incertidumbre como “la falta de (…) certeza o de un conocimiento seguro respecto de una determinada situación”, según Gómez (2023).\n\n\n\nAdaptado de Ilustración del plan de ahorro de los empleados dibujada a mano[Ilustración], por Freepik, 2024 (https://www.freepik.es/vector-gratis/ilustracion-plan-ahorro-empleados-dibujada-mano_87161866.htm#fromView=search&page=1&position=11&uuid=e54defbf-b176-455c-82c3-276ae1b3c634&new_detail=true). Licencia gratuita.\n\n\n\n\nConsiderando entonces la importancia del estudio del riesgo de crédito y sus implicaciones en las decisiones que toman las instituciones financieran que invierten y otorgan préstamos, así como las consecuencias que estas decisiones acarrean sobre las personas que los solicitas, se decide abordar esta cuestión a partir desde el punto de vista de los conocimientos adquiridos en el curso. Esto, pues la evaluación del riesgo de crédito involucra tareas como las que se enuncian a continuación:\n\nManejo de grandes volúmenes de datos: las entidades financieras o estatales poseen un amplio registro de información sobre los clientes que acceden a estos servicios, tales como sus comportamientos de pago y datos demográficos.\nIdentificación de patrones no evidentes: la probabilidad de incumplimiento de un cliente con sus pagos no siempre tendrá una relación lineal con las características que se conocen acerca de su persona, por lo que pueden necesitarse técnicas de mayor complejidad para descubrir los patrones o relaciones que lo explican.\nToma de decisiones basadas en riesgo: correspondiente al objetivo final de la presente actividad, se es importante realizar una clasificación de los clientes según su nivel de riesgo de crédito, asignando un puntaje que permita evaluar cualitativa y cuantitativamente las solicitudes de préstamo.\n\nDicho esto, puede verse que la elaboración de una herramienta que permita una evaluación adecuada del riesgo de crédito sería altamente beneficiosa no solo para las entidades financieras, que contarían con un medio de conocer mejor a sus posibles clientes, sino también para estos últimos, pues tendrían la oportunidad de conocer con antelación las posibilidades de que su crédito sea aprobado así como las variables que influirían en esa decisión.\nPara tal fin se desarrollará una aplicación web que permitirá responder a la pregunta: ¿cuál es el puntaje de riesgo de crédito de un posible prestatario? a través de la utilización de un modelo de redes neuronales artificiales entrenado sobre un amplio conjunto de datos en este contexto. El dataset a emplear, titulado Credit Risk Analysis y proporcionado por G. (2021) será tratado con la siguiente metodología y posteriormente evaluado, como podrá verse más adelante.\nMetodología\n\nAnálisis descriptivo e hipótesis del conjunto de datos.\nPlanteamiento y evaluación de modelos.\nConclusiones y aprendizajes a partir del modelo.\nPlanteamiento de un caso de uso.\n\nA continuación se da inicio al desarrollo de la actividad, la cual será complementada con todos los recursos empleados y productos resultantes de dicho ejercicio.\n\n\n\n\n\n\n\n\nLa regresión logística es un algoritmo que a pesar de tener la palabra regresión en su nombre, esta pensado para la clasificación binaria, es posible además extender para problemas multiclase a través de la regresión logística multinomial. La salida que se obtiene de este algoritmo es un número entre 0 y 1 que representa la probabilidad de pertenecer a una clase, la suma de la probabilidad de todas las clases debe dar 1, y la clase con la mayor probabilidad es aquella donde la observación será clasificada.\nLas probabilidades son calculadas de la siguiente manera:\n\\[\nP(y = c \\mid X) = \\frac{e^{\\beta_{c0} + \\beta_{c1}X_1 + \\dots + \\beta_{cn}X_n}}{\\sum_{k=1}^{C} e^{\\beta_{k0} + \\beta_{k1}X_1 + \\dots + \\beta_{kn}X_n}}  \\tag{1}\n\\]\nLa expresión anterior es además posible de simplificar para introducir la función softmax la cual también será usada en la sección de redes neuronales, para ello escribimos la combinación lineal de las variables \\(X\\) de la siguiente manera:\n\\[\nz_c = \\beta_{c0} + \\beta_{c1}X_1 + \\dots + \\beta_{cn}X_n  \\tag{2}\n\\]\nCon lo cual la ecuación 1 queda de la siguiente manera:\n\\[\nP(y = c \\mid X)=\\frac{e^{z_c}}{\\sum_{k=1}^{C} e^{z_k}} \\tag{3}\n\\]\nLa clase a la que pertenecerá la observación según el modelo de regresión logística multinomial esta dado por:\n\\[\n\\hat{y} = \\arg\\max_c \\, P(y = c \\mid X) \\tag{4}\n\\]\nA diferencia de otros algoritmos de aprendizaje automático, no cuenta con la misma cantidad de hiperparámetros que algoritmos como Random Forest o Support Vector Machines. La librería de Scikit-Learn permite ajustar el método y la fuerza de la regularización.\nTipos de regularización\n\nL1 (Lasso): Penaliza la suma de los valores absolutos de los coeficientes:\n\\[\n\\|\\beta\\|_1 = \\sum_{i=1}^n |\\beta_i| \\tag{5}\n\\]\nEsto lleva algunos coeficientes a cero, permitiendo la selección de características.\nL2 (Ridge): Penaliza la suma de los cuadrados de los coeficientes:\n\\[\n\\|\\beta\\|_2^2 = \\sum_{i=1}^n \\beta_i^2 \\tag{6}\n\\]\nEsto evita que los coeficientes crezcan demasiado grandes, ayudando a reducir el sobreajuste.\n\nFuerza de la regularización\nControla la fuerza de la regularización de forma inversamente proporcional\n\\[\nC = \\frac{1}{\\lambda} \\tag{7}\n\\]\n\nUn valor grande de \\(C\\) implica menos regularización (modelo más flexible).\nUn valor pequeño de \\(C\\) implica más regularización (modelo más restringido).\n\nVentajas\nEl modelo de regresión logístico presenta las siguientes ventajas:\n\nInterpretabilidad: Los coeficientes \\(\\beta\\) permiten una interpretación clara del impacto de cada variable sobre la probabilidad de pertenecer a una clase en específico.\nFácil implementación: No requiere ajustes avanzados para su implementación.\nGrados de certeza: Debido a que proporciona las probabilidades de pertenecer a cada clase, permite evaluar el grado de certeza sobre la pertenencia del dato a cada una de ellas.\n\nDesventajas\n\nRelaciones no lineales: La regresión logística esta pensada para relaciones lineales, por lo que si se buscan modelar relaciones no lineales requiere la introducción de términos polinómicos.\n Independencia de alternativas irrelevantes: El modelo asume que la relación entre dos clases no cambia si se introduce una nueva clase, lo que no siempre es realista.\n\n\n\n\nLas redes neuronales artificiales son modelos computacionales agrupados dentro del machine learning, con los cuales se busca simular el comportamiento del cerebro humano, de acuerdo con UNIR Revista (2021) y IBM (2025). Su funcionamiento imita el procedimiento con el que trabajan en conjunto las neuronas biológicas para aprender de la información que reciben desde el exterior o por parte de otras neuronas.\nGracias a su comportamiento, basado en la utilización de datos de entrenamiento para mejorar paulatinamente la precisión de sus resultados, las redes neuronales permiten la realización de tareas que no se podían automatizar en otro tipo de modelos, lo que ha llevado al desarrollo de avances significativos en el área de la inteligencia artificial e impactando de forma directa a las personas e industrias.\nConsiderando lo dicho anteriormente, es posible ver que las redes neuronales artificiales son una gran alternativa a la hora de enfrentar tareas relacionadas con el aprendizaje a partir de un conjunto de datos, encontrando patrones que puedan explicar el comportamiento de estos últimos respecto de alguna variable objetivo, con la finalidad de tomar una decisión después del entendimiento de dicho fenómeno. En este sentido, será utilizada una red neuronal para mejorar el resultado obtenido con el modelo de baja complejidad en el presente ejercicio.\n\n\nEste teorema establece que:\n“Cualquier función continua definida en un conjunto compacto puede ser aproximada arbitrariamente bien por una red neuronal feedforward con una sola capa oculta y un número suficiente de neuronas, utilizando funciones de activación no lineales”\nLo anterior significa que las funciones de activación no lineales son esenciales para que las redes neuronales puedan aproximar funciones complejas. Si bien el teorema garantiza que una sola capa oculta con suficientes neuronas puede aproximar cualquier función continua en un conjunto compacto, en la práctica, aumentar el número de capas suele ser más eficiente para modelar problemas complejos.\n\n\n\nIlustración de los resultados obtenidos mediantes funciones no lineales comparadas con las funciones lineales.\n\n\n\n\n\nLas redes neuronales están compuestas por un conjunto de nodos, que vendrían siendo las neuronas artificiales, repartidos en capas que pertenecen a alguna de las siguientes tres categorías, con información obtenida de Cloudflare (2025) y ParoleDevs (n.d.):\n\nCapa de entrada: esta capa tiene conexión con el “mundo exterior” a la red neuronal artificial, recibiendo los datos iniciales que serán procesados por ella.\nCapa de salida: esta capa proporciona el resultado del procesamiento realizado por la red neuronal, comúnmente como una predicción o una clasificación (lo cual se ve internamente en términos de probabilidad).\nCapas ocultas: una o más capas que se encuentran entre las dos mencionadas anteriormente, realizando el procesamiento y extracción de características de los datos. Este análisis se realiza de menor a mayor profundidad, pues cada capa extrae los patrones más significativos de los datos que recibió como entrada y los envía a una capa superior para que sean vistos con más detalle.\n\nAhora bien, es conveniente conocer los elementos que componen a cada uno de los nodos que interactúan en las capas anteriormente mencionadas, pues de esta manera será posible comprender la importancia del correcto diseño de la arquitectura de una red neuronal artificial. De acuerdo con Burgos (n.d.), estos elementos son:\nEntrada: los datos que recibe la neurona artificial del exterior o de otras neuronas, se representa como un vector \\(x = (x_1, x_2, ..., x_n)\\).\nPesos sinápticos: representan los factores de importancia \\(w_{ij}\\) que se le asignan a las entradas que cada neurona recibió de su anterior compañera. Son valores numéricos que se modifican durante el entrenamiento del modelo y poseen una vital importancia en el desempeño de este mismo frente al conjunto de datos del que está aprendiendo.\nRegla de propagación: una operación que se aplica de forma primordial a los datos de entrada y los pesos para calcular el posible valor de la salida de la neurona artificial; generalmente es una suma ponderada pero también pueden ser otras clases de operaciones.\nFunción de activación capa de entrada: el valor obtenido con la regla de propagación se procesa con a través de esta función, a fin de obtener el verdadero resultado de salida de la neurona. Existe una gran variedad de funciones que se eligen de acuerdo con el objetivo de entrenamiento de la red neuronal artificial, entre las cuales se encuentran las siguientes:\n\nIdentidad.\n\nLa función de identidad es una función lineal que devuelve el mismo valor de entrada como salida: \\[ f(x) = x \\]\n\nEscalón.\n\nLa función de escalón devuelve un valor binario dependiendo de si la entrada supera un umbral ( ): \\[ f(x) =\n\\begin{cases}\n1 & \\text{si } x \\geq \\theta \\\\\n0 & \\text{si } x &lt; \\theta\n\\end{cases} \\]\n\nLineal a tramos.\n\nLa función lineal a tramos aplica una transformación lineal dentro de un rango específico: \\[ f(x) =\n\\begin{cases}\n0 & \\text{si } x \\leq 0 \\\\\nx & \\text{si } 0 &lt; x \\leq 1 \\\\\n1 & \\text{si } x &gt; 1\n\\end{cases} \\]\n\nSigmoide. La función sigmoide suaviza la salida en un rango entre 0 y 1: \\[ f(x) = \\frac{1}{1 + e^{-x}} \\]\nGaussiana. La función gaussiana calcula una salida basada en la forma de una campana, con una media () y desviación estándar (): \\[ f(x) = e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\nSinusoidal. La función sinusoidal genera una salida oscilatoria basada en una onda sinusoidal: \\[ f(x) = \\sin(x) \\]\n\nSalida: resultado \\(y_i\\) del procedimiento aplicado sobre los datos de entrada.\nFunción de activación capa de salida:\n\nSoftmax: Permite convertir un conjunto de valores en probabilidades que suman 1, su principal uso se encuentra en problemas de clasificación multiclase.\n\n\\[\n\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n\\]\n\nCross-entropy: Mide la diferencia entre las predicciones \\(\\hat{y_i}\\) y la real \\(y\\), para el caso de clasificación lo hace de la siguiente manera:\n\n\\[\n\\text{Cross-Entropy Loss} = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n\\]\n\nSparse Cross-Entropy Loss : Es una variante de Cross-Entropy que no requiere codificación one-hot, sino que trabaja directamente con índices de las clases verdaderas.\n\n\\[\n\\text{Sparse Cross-Entropy Loss} = - \\log(\\hat{y}_{c})\n\\]\n\nFocal loss: Es una extensión de Cross-Entropy que aplica un factor de penalización para enfocarse más en ejemplos mal clasificados. Es especialmente útil para casos de datasets desbalanceados.\n\n\\[\n\\text{Focal Loss} = - \\alpha_t (1 - p_t)^\\gamma \\log(p_t)\n\\]\nDonde: \\[\np_t = \\hat{y}_c\n\\]\n\n\n\nTeniendo en cuenta las particularidades de la arquitectura de las redes neuronales artificiales, a continuación se detallan algunos tipos diferentes de modelos, clasificados según su diseño, así como sus correspondientes aplicaciones en diferentes campos de la academia y la industria.\n\nRedes neuronales artificiales perceptrón: tienen la arquitectura más sencilla, compuesta por nodos con una única función de activación, suelen utilizarse para tareas de clasificación binaria.\nRedes neuronales artificiales multicapa: su arquitectura está conformada por capas de neuronas artificiales interconectadas y son utilizadas para tareas más complejas como toma de decisiones y clasificación multiclase.\nRedes neuronales artificiales convolucionales: estas redes están especialmente diseñadas para realizar tareas relacionadas con el reconocimiento de imágenes, pues utilizan filtros convolucionales para identificar patrones y características especiales en cada pixel.\nRedes neuronales artificiales recurrentes: suelen ser empleadas para tareas como reconocimiento de voz, traducción automática y generación de texto por su capacidad para procesar datos secuenciales, donde toda la información está relacionada entre sí y posee un contexto común para explicarse.\n\n\n\n\nAlgunas de las aplicaciones de las redes neuronales en la actualidad incluyen las siguientes:\n\nReconocimiento de imágenes: las redes neuronales pueden ser utilizadas para identificar personas y objetos en imágenes y videos.\nProcesamiento del lenguaje natural: las redes neuronales pueden utilizarse en tareas de comprensión del lenguaje como la traducción automática, la generación de texto y el reconocimiento de voz.\nToma de decisiones: las redes neuronales pueden ser herramientas de ayuda para la toma de decisiones en situaciones complejas tales como el análisis financiero, que es el caso del presente ejercicio y el diagnóstico médico, entre otras.\nSistemas de recomendación: las redes neuronales pueden ser empleadas para generar recomendaciones personalizadas con base en las preferencias del usuario en diferentes plataformas de streaming, comercio electrónico y redes sociales. Profe Digital (n.d.)\n\n\n\n\n\n\n\n\nDespués de haber jugado con el dataset en la sección anterior para los análisis descriptivos y exploratorios, pasamos a realizar el pre procesamiento de los datos necesario para que la arquitectura de la red neuronal sea capaz de recibirlos y además ayudar a mejorar su rendimiento. Iniciamos dividiendo el conjunto de datos en entrenamiento, validación y test para evitar cualquier tipo de data leakage durante el preprocesamiento.\n\n\nUtilizamos tres estrategias para la clasificación de las variables categóricas según su naturaleza\n\nOrdinal Encoder: Esta técnica se aplicó cuando las variables categóricas presentaban un orden natural. La codificación numérica asignada reflejaba este orden, asegurando que los valores fueran representativos de su jerarquía inherente.\nLabel Encoder: Se empleó en variables categóricas binarias. Este enfoque evitó imponer un orden ficticio entre los valores, lo que podría generar sesgos al interpretar una relación inexistente entre las categorías.\nOne Hot Encoding: Diseñada para variables categóricas sin un orden natural y con más de dos niveles. Cada categoría fue representada mediante un vector binario, donde un valor de 1 indica pertenencia a una categoría específica y e asigna 0 a las demás. Se prestó especial atención al número de niveles en cada variable. En casos con muchas categorías, esta técnica podría haber generado una matriz de alta dimensionalidad, aumentando los requerimientos computacionales y complicando el entrenamiento de la red neuronal. Para evitar estos problemas, se evaluó cuidadosamente la viabilidad de aplicar este método en cada caso.\n\n\n\n\nLa técnica de imputación de datos faltantes elegidas fue Iterative Imputer para las variables numéricas debido a que muestra mejores capacidades en manejar relaciones complejas que otros métodos de imputación como lo son la media o similares, gracias a que considera todo el dataset de manera conjunta en lugar de una sola columna. Para el caso de variables catgóricas se utilizo la imputación mediante mediana.\n\n\n\nUtilizamos StandardScaler debido a que normaliza las características centrando su media en 0 y escalando según la desviación estándar, lo cual es crucial en redes neuronales para garantizar estabilidad numérica y mejorar la eficiencia del entrenamiento.\nEsto previene problemas como:\n\nGradiente explosivo: Valores extremos en las entradas producen gradientes excesivamente grandes, causando desbordamientos numéricos y actualizaciones erráticas de pesos.\nGradiente desvaneciente: Gradientes extremadamente pequeños ralentizan la convergencia, dificultando el aprendizaje efectivo.\n\nLa fórmula utilizada por StandardScaler es:\n\\[\nX' = \\frac{X - \\mu}{\\sigma}\n\\]\ndonde:\n\n\\(X\\): Valor original.\n\\(u\\): Media de los datos.\n\\(sigma\\): Desviación estándar de los datos.\n\nEste método asegura que las características tengan una varianza de 1 y estén centradas en 0, permitiendo que funciones de activación como sigmoid y tanh operen eficientemente.\n\n\n\nEl análisis descriptivo mostró que la variable respuesta del dataset está altamente desbalanceada, lo cual representa un reto significativo al crear el modelo. Un modelo entrenado en estas condiciones puede tender a predecir únicamente la clase mayoritaria, generando métricas como el accuracy con valores engañosamente altos, pero sin reflejar una verdadera capacidad predictiva. Para abordar este problema, utilizaremos las siguientes técnicas:\n\nSobremuestreo y Submuestreo: Esta estrategia combina el aumento de las clases minoritarias mediante sobremuestreo y la reducción de las clases mayoritarias mediante submuestreo. El objetivo es equilibrar la cantidad de datos entre las clases, incentivando al modelo a aprender las características de todas las clases y mejorando sus métricas al minimizar la función de pérdida. Esto fue utilizado para el modelo con todas las clases.\n\n\n\n\nIlustración del funcionamiento de las técnicas de sobremuestreo y submuestreo. Tomado de (https://www.datasciencecentral.com/handling-imbalanced-data-sets-in-supervised-learning-using-family/)\n\n\n\nAgrupamiento de las clases: En esta estrategia agrupamos algunas de las clases con una menor cantidad de datos, esto debido a que como se verá más adelante son clases que tienen tan pocos datos que predecirlas es altamente complejo, y que pone en evidencia además las limitaciones de técnicas de sobremuestreo y submuestreo en la presencia de clases altamente desbalanceadas.\n\n\n\n\n\n\n\nDado el desbalance de la variable objetivo, utilizaremos métricas diseñadas para proporcionar una evaluación más equitativa del modelo:\n\nF1-Score Macro: A diferencia de métricas como el accuracy, que tienden a favorecer la clase mayoritaria en datasets desbalanceados, el F1-Score Macro asigna igual importancia a todas las clases, independientemente del número de muestras. Esto nos brinda una evaluación más realista del desempeño del modelo.\n\n\n\n\nPara abordar el desbalance de clases durante el entrenamiento, utilizaremos técnicas como:\n\nFocal Loss: Esta función de pérdida está diseñada específicamente para problemas de clasificación desbalanceados. Su objetivo es priorizar las clases minoritarias al reducir la importancia de las predicciones correctamente clasificadas para las clases mayoritarias. Esto ayuda al modelo a concentrarse más en aprender las características de las clases menos representadas.\nPesos de las Clases: En algunos casos, asignar pesos inversamente proporcionales al tamaño de cada clase en la función de pérdida puede ser una estrategia complementaria para equilibrar la importancia de las clases en el modelo.\n\n\n\n\n\nEarly Stopping: Permite reducir los tiempos de entrenamiento al monitorear una métrica, y dado un parámetro de paciencia que indica cuantas Epoch esperar, detiene el entrenamiento si la mejora después de cumplida la paciencia no es lo suficientemente significativa para justificar seguir entrenando.\nReduce Learning Rate on Plateu: Ayuda a mantener la capacidad de mejora durante el entrenamiento, los cálculos del gradiente, que dependen de la tasa de aprendizaje pueden no ser capaces de llegar al mínimo de la función de pérdida, por lo que este callback reduce la tasa de entrenamiento si para una cantidad de Epochs dada, no ha habida una mejoría en los resultados, esto permite tener un aprendizaje con capacidad de mejoría a través de las Epochs.\n\n\n\n\nLas capas definidas en el modelo fueron las siguiente:\n\n\n\nInput(shape=(X_train_bal.shape[1],)):\n\nDefine el tamaño de la entrada, igual al número de características en el dataset balanceado \\(X_{train\\_bal}\\).\n\nEs la capa inicial que recibe los datos de entrada para ser procesados por las siguientes capas.\n\n\n\n\n\n\n\nDense(128, activation=‘relu’, kernel_regularizer=l2(1e-4)):\n\nContiene 128 neuronas con activación ReLU, que introduce no linealidades y permite al modelo aprender patrones complejos.\n\nUtiliza un regularizador \\(L_2\\) con un valor de \\(1 \\times 10^{-4}\\) para prevenir el sobreajuste al penalizar pesos grandes.\n\n\nBatchNormalization():\n\nNormaliza la salida de la capa densa para estabilizar el entrenamiento y acelerar la convergencia.\n\n\nDropout(0.2):\n\nDesactiva aleatoriamente el 20% de las neuronas durante el entrenamiento para mejorar la generalización y reducir el riesgo de sobreajuste.\n\n\n\n\n\n\n\nDense(64, activation=‘relu’, kernel_regularizer=l2(1e-4)):\n\nReduce el número de neuronas a 64 para aprender características más específicas.\n\nConserva el mismo esquema de regularización \\(L_2\\) y activación ReLU.\n\n\nBatchNormalization():\n\nAsegura que las distribuciones de activaciones estén centradas durante el entrenamiento.\n\n\nDropout(0.2):\n\nMantiene el mismo porcentaje de desactivación que la capa anterior para seguir controlando el sobreajuste.\n\n\n\n\n\n\n\nDense(32, activation=‘relu’, kernel_regularizer=l2(1e-4)):\n\nReduce aún más el número de neuronas a 32, capturando características específicas de alto nivel.\n\nSigue utilizando activación ReLU y regularización \\(L_2\\).\n\n\nBatchNormalization():\n\nContinua normalizando las activaciones para estabilizar el aprendizaje.\n\n\nDropout(0.2):\n\nPermite que el modelo siga generalizando bien al reducir el riesgo de sobreajuste.\n\n\n\n\n\n\n\nDense(num_classes, activation=‘softmax’):\n\nContiene \\(num_{classes}\\) neuronas, donde cada neurona representa una clase de la variable objetivo.\n\nUsa la activación Softmax para calcular probabilidades de pertenencia para cada clase, asegurando que la suma de las probabilidades sea igual a 1.\n\n\n\n\n\n\n\n\nRegularización y Generalización:\n\nLa regularización \\(L_2\\) y Dropout en cada capa oculta ayudan a prevenir el sobreajuste, especialmente relevante dado el desbalance inicial del dataset.\n\nNormalización y Estabilidad:\n\nBatchNormalization estabiliza el aprendizaje al controlar las distribuciones de activaciones en cada capa, acelerando la convergencia.\n\nArquitectura Progresiva:\n\nLa reducción progresiva de neuronas en las capas ocultas (128 → 64 → 32) permite al modelo capturar primero características generales y luego refinarlas a características específicas.\n\nCapacidad para Multiclase:\n\nLa capa de salida con Softmax asegura que el modelo sea adecuado para problemas de clasificación multiclase, produciendo distribuciones de probabilidad por clase.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDebido a la naturaleza del proyecto, tareas como lo son la monitoría del modelo se dejan como futuras mejorías, nos centraremos específicamente en dos.\n\n\nSe utilizó el framework de FastAPI (Ramírez 2018) para convertir el modelo una API que pudiera realizar predicciones pasandole la información de cada usuario. En el GitHub se encuentra el archivo con el código necesario para lograr este resultado."
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html#delimitaciones-del-problema-y-metodología",
    "href": "posts/modelos-riesgo-credito/index.html#delimitaciones-del-problema-y-metodología",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "",
    "text": "Considerando entonces la importancia del estudio del riesgo de crédito y sus implicaciones en las decisiones que toman las instituciones financieran que invierten y otorgan préstamos, así como las consecuencias que estas decisiones acarrean sobre las personas que los solicitas, se decide abordar esta cuestión a partir desde el punto de vista de los conocimientos adquiridos en el curso. Esto, pues la evaluación del riesgo de crédito involucra tareas como las que se enuncian a continuación:\n\nManejo de grandes volúmenes de datos: las entidades financieras o estatales poseen un amplio registro de información sobre los clientes que acceden a estos servicios, tales como sus comportamientos de pago y datos demográficos.\nIdentificación de patrones no evidentes: la probabilidad de incumplimiento de un cliente con sus pagos no siempre tendrá una relación lineal con las características que se conocen acerca de su persona, por lo que pueden necesitarse técnicas de mayor complejidad para descubrir los patrones o relaciones que lo explican.\nToma de decisiones basadas en riesgo: correspondiente al objetivo final de la presente actividad, se es importante realizar una clasificación de los clientes según su nivel de riesgo de crédito, asignando un puntaje que permita evaluar cualitativa y cuantitativamente las solicitudes de préstamo.\n\nDicho esto, puede verse que la elaboración de una herramienta que permita una evaluación adecuada del riesgo de crédito sería altamente beneficiosa no solo para las entidades financieras, que contarían con un medio de conocer mejor a sus posibles clientes, sino también para estos últimos, pues tendrían la oportunidad de conocer con antelación las posibilidades de que su crédito sea aprobado así como las variables que influirían en esa decisión.\nPara tal fin se desarrollará una aplicación web que permitirá responder a la pregunta: ¿cuál es el puntaje de riesgo de crédito de un posible prestatario? a través de la utilización de un modelo de redes neuronales artificiales entrenado sobre un amplio conjunto de datos en este contexto. El dataset a emplear, titulado Credit Risk Analysis y proporcionado por G. (2021) será tratado con la siguiente metodología y posteriormente evaluado, como podrá verse más adelante.\nMetodología\n\nAnálisis descriptivo e hipótesis del conjunto de datos.\nPlanteamiento y evaluación de modelos.\nConclusiones y aprendizajes a partir del modelo.\nPlanteamiento de un caso de uso.\n\nA continuación se da inicio al desarrollo de la actividad, la cual será complementada con todos los recursos empleados y productos resultantes de dicho ejercicio."
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html#contribuciones-individuales",
    "href": "posts/modelos-riesgo-credito/index.html#contribuciones-individuales",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "3.1 Contribuciones individuales",
    "text": "3.1 Contribuciones individuales\nLas contribuciones realizadas por cada uno de los integrantes del equipo en el desarrollo de los ejercicios correspondientes a Modelos de riesgo de crédito con Redes Neuronales Artificiales se muestran en el siguiente video."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html",
    "href": "posts/optimizacion_heuristica/index.html",
    "title": "Optimización Heurística",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom IPython.display import display\nfrom IPython.display import Image as IPImage\nimport io\nfrom PIL import Image\nEl objetivo de esta sección es evaluar diversos métodos de optimización aplicados a varias funciones, con el fin de medir su rendimiento. En particular, se utilizarán las funciones de Rosenbrock, Schwefel, Griewank, Goldstein-Price y la función de las seis jorobas de camello. Estas funciones serán optimizadas mediante el método del gradiente descendente y tres algoritmos heurísticos: Algoritmos Evolutivos, Optimización por Enjambre de Partículas y Evolución Diferencial.\nAl final, se comentará sobre los aportes de los métodos de descenso por gradiente y los métodos heurísticos, considerando el valor final de la función objetivo y el número de evaluaciones de la función objetivo, en un entorno de simulación con varios parámetros y condiciones para garantizar conclusiones significativas."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#optimización-por-descenso-del-gradiente",
    "href": "posts/optimizacion_heuristica/index.html#optimización-por-descenso-del-gradiente",
    "title": "Optimización Heurística",
    "section": "2.1 Optimización por descenso del gradiente",
    "text": "2.1 Optimización por descenso del gradiente\nEl descenso del gradiente es un algoritmo de optimización iterativo que busca encontrar el mínimo local de una función diferenciable. La idea principal es moverse en la dirección opuesta al gradiente de la función en cada punto, ya que el gradiente apunta en la dirección de máximo crecimiento.\nDe acuerdo con Bishop (2006), para una función \\(f(x)\\), el algoritmo actualiza iterativamente el punto \\(x\\) usando la regla que se observa en la Ecuación 8.\n\\[\nx_{t+1} = x_t - \\eta \\nabla f(x_t) \\tag{8}\n\\]\ndonde:\n\n\\(x_t\\) es el punto actual\n\\(\\eta\\) es la tasa de aprendizaje\n\\(\\nabla f(x_t)\\) es el gradiente de la función en \\(x_t\\)\n\nEl gradiente \\(\\nabla f\\) es un vector que contiene las derivadas parciales respecto a cada variable, tal como se ilustra en la Ecuación 9:\n\\[\n\\nabla f(x_1, x_2) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\end{bmatrix} \\tag{9}\n\\]\nEl gradiente \\(\\nabla f\\) se puede aproximar numéricamente usando diferencias finitas. Bishop (2006) plantean que, se puede mejorar consideramblemente la presición del método usando diferencias centrales simétricas. En este caso, para una función \\(f(x_1, x_2)\\), las derivadas parciales se calculan como se muestra en las Ecuaciones 10 y 11.\n\\[\n\\frac{\\partial f}{\\partial x_1} \\approx \\frac{f(x_1 + h, x_2) - f(x_1 - h, x_2)}{2h} \\tag{10}\n\\]\n\\[\n\\frac{\\partial f}{\\partial x_2} \\approx \\frac{f(x_1, x_2 + h) - f(x_1, x_2 - h)}{2h} \\tag{11}\n\\]\ndonde \\(h\\) es un pequeño incremento (típicamente \\(10^{-7}\\) o \\(10^{-8}\\)).\n\n\nCode\ndef partial_derivative(x0, func, i, h, *args):\n  e = np.zeros(len(x0))\n  e[i] = 1\n  return (func(x0+h*e, *args) - func(x0-h*e, *args))/(2*h)\n\ndef numerical_gradient(x0, func, h, *args):\n  gradient = np.zeros(len(x0))\n  for i in range(len(x0)):\n    gradient[i] = partial_derivative(x0, func, i, h, *args)\n  return gradient\n\ndef gradient_descent_num_dev_mult(x0, eta, func, h, max_iter, *args):\n  \"\"\"\n  Perform gradient descent with numerical derivatives for a multi-dimensional function.\n\n  Parameters:\n      x0 (array-like): Initial guess for the variables.\n      eta (float): Learning rate.\n      func (callable): Function to minimize.\n      h (float): Step size for numerical gradient calculation.\n      max_iter (int): Maximum number of iterations.\n      *args: Additional arguments for the function.\n\n  Returns:\n      result_df (pd.DataFrame): DataFrame with columns ['x1', 'x2', 'f(x1,x2)']\n                                containing the trajectory of points.\n  \"\"\"\n  x_old = np.array(x0)\n  x_hist = []  # List to store the history of x and f(x)\n\n  for i in range(max_iter):\n      # Calculate the gradient numerically\n      gradient = numerical_gradient(x_old, func, h, *args)\n\n      # Update x based on gradient descent rule\n      x_new = x_old - eta * gradient\n\n      # Append current x and function value to history\n      x_hist.append([x_old[0], x_old[1], func(x_old, *args)])\n\n      # Update x_old\n      x_old = x_new\n\n  # Add the final position and function value\n  x_hist.append([x_new[0], x_new[1], func(x_new, *args)])\n\n  # Convert history to a pandas DataFrame\n  result_df = pd.DataFrame(x_hist, columns=['x1', 'x2', 'f(x1,x2)'])\n\n  return result_df\n\n\nA continuación, se presentan las animaciones que ilustran la aplicación del descenso del gradiente en las seis funciones evaluadas. Los parámetros iniciales, la tasa de aprendizaje y el número de iteraciones del algoritmo fueron seleccionados cuidadosamente para optimizar la visualización del funcionamiento del método.Estos parámetros se detallan en las tablas a continuación.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1.5\n-1.7\n0.001\n30\n\n\n\nFigura 7.\nAplicación del descenso del gradiente en la función de Rosenbrok.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-0.46\n0.46\n0.005\n30\n\n\n\nFigura 8.\nAplicación del descenso del gradiente en la función de Rastrigin.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n310\n310\n0.8\n30\n\n\n\nFigura 9.\nAplicación del descenso del gradiente en la función de Schwefel.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-500\n500\n70\n33\n\n\n\nFigura 10.\nAplicación del descenso del gradiente en la función de Griewank.  Elaboración propia.\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align} \\tag{6}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n0.5\n-1.5\n0.00005\n50\n\n\n\nFigura 11.\nAplicación del descenso del gradiente en la función de Goldstein-Price.  Elaboración propia.\n\n\n\\[\nf(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n\\]\n\n\n\n\\(x_{1_0}\\)\n\\(x_{2_0}\\)\n\\(\\eta\\)\n\\(n\\)\n\n\n\n\n-1\n-1\n0.015\n33\n\n\n\nFigura 12.\nAplicación del descenso del gradiente en la función de las seis jorobas del camello.  Elaboración propia.\n\n\n\nEl método del gradiente descendente puede imaginarse como una persona deslizándose por una colina representada por una función. El punto de inicio es el lugar desde donde comienza a deslizarse, y la tasa de aprendizaje actúa como la aceleración que controla la velocidad del deslizamiento en cada paso. Si esta aceleración es demasiado alta, puede ayudar a llegar más rápido al valle más bajo, pero también existe el riesgo de salir del camino o incluso terminar subiendo una colina debido a un impulso excesivo que sobrepasa el objetivo.\nPara garantizar que este método sea eficiente, es importante considerar lo siguiente:\n\nTasa de aprendizaje: Un valor demasiado grande puede causar divergencia, mientras que uno muy pequeño puede hacer que el proceso sea extremadamente lento.\nPunto inicial: La ubicación inicial afecta la trayectoria y la probabilidad de alcanzar el mínimo global.\nCriterio de parada: Es esencial definir cuándo detener el algoritmo, ya sea por alcanzar un número máximo de iteraciones o porque la mejora entre pasos sea insignificante (convergencia)."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#agoritmo-genético",
    "href": "posts/optimizacion_heuristica/index.html#agoritmo-genético",
    "title": "Optimización Heurística",
    "section": "2.2 Agoritmo genético",
    "text": "2.2 Agoritmo genético\nUn algoritmo genético (GA) es un método heurístico de optimización inspirado en los principios de la selección natural y la evolución biológica, propuesto inicialmente por Holland (1975). Este enfoque busca soluciones óptimas en un espacio de búsqueda utilizando una población de candidatos.\n\n2.2.1 Concepto General\nEl algoritmo genético simula el proceso evolutivo a través de las siguientes etapas:\n\nSelección: Elegir individuos con mayor fitness.1\nCruce: Combinar soluciones para generar descendencia.\nMutación: Introducir variación genética.\n\nMatemáticamente, en un problema de minimización, el objetivo es encontrar:\n\\[\nx^* = \\arg\\min_{x \\in \\mathbb{R}^n} f(x) \\tag{12}\n\\]\ndonde:\n\n\\(x\\) representa un individuo en el espacio de búsqueda.\n\\(f(x)\\) es la función objetivo que evalúa la calidad de \\(x\\).\n\nCada solución candidata se representa como un individuo, que puede ser un vector real o un cromosoma binario, tal como se ilustra en la Ecuación 13:\n\\[\nx = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n \\tag{13}\n\\]\nLa función objetivo, mostrada en la Ecuación 14, mide qué tan buena es una solución.\n\\[\n\\text{Fitness}(x) = f(x) \\tag{14}\n\\]\nPara problemas de minimización, menor \\(f(x)\\) implica mejor fitness.\n\n\n\n2.2.2 Etapas\nInicialización de la Población\nSe genera una población inicial de \\(P\\) individuos de forma aleatoria dentro de un intervalo \\([a, b]\\):\n\\[\nx_{ij} \\sim \\text{U}(a, b), \\quad \\forall i \\in \\{1, 2, \\ldots, P\\}, \\; j \\in \\{1, 2, \\ldots, n\\} \\tag{15}\n\\]\ndonde:\n\n\\(x_{ij}\\) es la \\(j-ésima\\) coordenada del \\(i-ésimo\\) individuo.\n\n\n\nCode\n# Inicializar población\ndef initialize_population(size, dim, bounds):\n    return np.random.uniform(bounds[0], bounds[1], (size, dim))\n\n\n\nEvaluación del Fitness\nCada individuo de la población es evaluado usando la función objetivo mostrada a continuación, en la Ecuación 16.\n\\[\n\\text{Fitness}_i = f(x_i) \\tag{16}\n\\]\n\n\nCode\n# Evaluar fitness\ndef evaluate_fitness(population,fitness_function):\n    return np.array([fitness_function(ind) for ind in population])\n\n\n\nSelección\nSe seleccionan individuos para reproducirse basándose en su fitness. Un métodos común es el método de torneo, observado en la Ecuación 17, donde primero se seleccionan \\(k\\) individuos al azar y luego se elige al mejor de ellos (quien tenga el mejor fitness):\n\\[\n\\text{Individuo seleccionado} = \\arg\\min_{j \\in S} \\text{Fitness}_j, \\; S \\subseteq \\{1, \\ldots, P\\}, \\; |S| = k \\tag{17}\n\\]\n\n\nCode\n# Selección por torneo\ndef tournament_selection(population, fitness, k=3):\n    selected = []\n    for _ in range(len(population)):\n        candidates = np.random.choice(range(len(population)), k, replace=False)\n        winner = candidates[np.argmin(fitness[candidates])]\n        selected.append(population[winner])\n    return np.array(selected)\n\n\n\nCruce (Recombinación)\nDos individuos (padres) se combinan para generar descendencia. Un método común es punto de corte único, donde primero se elige un punto de cruce aleatorio \\(k\\) y después se genera la descendencia mezclando las características de los padres, como se observa en las Ecuaciones 18 y 19.\n\\[\n\\text{Hijo 1} = (\\text{Padre}_1[:k], \\text{Padre}_2[k:]) \\tag{18}\n\\]\n\\[\n\\text{Hijo 2} = (\\text{Padre}_2[:k], \\text{Padre}_1[k:]) \\tag{19}\n\\]\nLa probabilidad de realizar un cruce está determinada por \\(p_c\\) (tasa de cruce).\n\n\nCode\n# Cruce\ndef crossover(parent1, parent2, crossover_rate):\n    if np.random.rand() &lt; crossover_rate:\n        point = np.random.randint(1, len(parent1))\n        child = np.concatenate([parent1[:point], parent2[point:]])\n        return child\n    return parent1 if np.random.rand() &lt; 0.5 else parent2\n\n\n\nMutación\nSe introduce una variación genética al modificar aleatoriamente uno o más genes(variables) en un individuo(punto del plano) con probabilidad \\(p_m\\):\n\\[\nx_{ij} = x_{ij} + \\Delta, \\quad \\Delta \\sim \\text{U}(-\\delta, \\delta) \\tag{20}\n\\]\ndonde:\n\n\\(\\Delta\\) es una perturbación aleatoria.\n\\(x_{ij}\\) se restringe a los límites del problema.\n\n\n\nCode\n# Mutación\ndef mutate(individual, bounds, mutation_rate, delta):\n    for i in range(len(individual)):\n        if np.random.rand() &lt; mutation_rate:\n            individual[i] += np.random.uniform(-delta, delta)\n            individual[i] = np.clip(individual[i], bounds[0], bounds[1])\n    return individual\n\n\n\nEvaluación y Sustitución\nLa nueva población es evaluada, y mediante el uso de elitismo, es posible conservar a los mejores individuos. El algoritmo continúa iterando con esta población actualizada, mejorando progresivamente la optimización de la función objetivo al incrementar el fitness general de la población.\n\n\nCode\n# Algoritmo completo\ndef genetic_algorithm(fitness_function, population_size, generations, mutation_rate, crossover_rate, dim, bounds, delta):\n    population = initialize_population(population_size, dim, bounds)\n    best_individual = None\n    trajectory = []\n    populations = []\n\n    for generation in range(generations):\n        populations.append(population.copy())\n        fitness = evaluate_fitness(population, fitness_function)\n        \n        if best_individual is None or np.min(fitness) &lt; fitness_function(best_individual):\n            best_individual = population[np.argmin(fitness)]\n        \n        # Guardar la mejor solución de esta generación\n        trajectory.append((*best_individual, fitness_function(best_individual)))\n        \n        # Selección\n        selected_population = tournament_selection(population, fitness)\n        \n        # Cruce y mutación\n        new_population = []\n        for i in range(0, len(selected_population), 2):\n            if i + 1 &lt; len(selected_population):\n                child1 = crossover(selected_population[i], selected_population[i+1], crossover_rate)\n                child2 = crossover(selected_population[i+1], selected_population[i], crossover_rate)\n                new_population.extend([child1, child2])\n            else:\n                new_population.append(selected_population[i])\n        \n        population = np.array([mutate(ind, bounds, mutation_rate, delta) for ind in new_population])\n    \n    # Convertir la trayectoria a DataFrame\n    \n    columns = [f'x{i+1}' for i in range(dim)] + ['f(x)']\n    df = pd.DataFrame(trajectory, columns=columns)\n    return best_individual, fitness_function(best_individual), df, populations\n\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n\\]\nFigura 13.\nAplicación del algoritmo genético sobre la función de Rosenbrok.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n\\]\nFigura 14.\nAplicación del algoritmo genético sobre la función de Rastrigin.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n\\]\nFigura 15.\nAplicación del algoritmo genético sobre la función de Schwefel.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n\\]\nFigura 16.\nAplicación del algoritmo genético sobre la función de Griewank.  Elaboración propia.\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align} \\tag{6}\n\\]\nFigura 17.\nAplicación del algoritmo genético sobre la función de Goldstein-Price.  Elaboración propia.\n\n\n\\[\nf(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n\\]\nFigura 18.\nAplicación del algoritmo genético sobre la función de las seis jorobas del camello.  Elaboración propia.\n\n\n\nLos algoritmos genéticos convergen hacia soluciones aproximadas, aunque no garantizan alcanzar el óptimo global. Sin embargo, suelen mostrar una rápida convergencia en pocas generaciones. Estos algoritmos buscan equilibrar dos objetivos clave: exploración, que consiste en descubrir nuevas regiones del espacio de búsqueda, y explotación, enfocada en refinar y mejorar las soluciones existentes.\nPara las simulaciones presentadas en los GIF, se utilizaron los siguientes parámetros: tamaño de población = 30, número de generaciones = 20, tasa de mutación = 0.5, y tasa de cruce = 0.5. El parámetro de mutación \\(\\delta\\) se ajusta según los límites de evaluación de las funciones objetivo, representando aproximadamente un 5% del rango de dichas funciones.\n\n\n2.2.3 Observaciones\nVentajas:\n\nNo requiere derivadas ni condiciones específicas en \\(f(x)\\) .\nEs efectivo en espacios de búsqueda multimodales o no convexos.\nAdaptable a diversos problemas.\n\nDesventajas:\n\nPuede ser computacionalmente costoso.\nNo garantiza convergencia al óptimo global.\nRequiere ajuste cuidadoso de parámetros."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#optimización-de-partículas",
    "href": "posts/optimizacion_heuristica/index.html#optimización-de-partículas",
    "title": "Optimización Heurística",
    "section": "2.3 Optimización de partículas",
    "text": "2.3 Optimización de partículas\n\n2.3.1 Concepto Básico y Analogía\nDe acuerdo con Kennedy and Eberhart (1995), puede decirse que la Optimización por Enjambre de Partículas (PSO) es una técnica metaheurística inspirada en el comportamiento social de los animales, como los pájaros o los peces. En PSO, cada solución potencial al problema se representa como una partícula que se mueve en un espacio de búsqueda multidimensional. Cada partícula ajusta su posición y velocidad en cada iteración, basándose en su propia mejor posición encontrada (pBest) y la mejor posición encontrada por todo el enjambre (gBest).\nLos métodos PSO se atribuyen originalmente a los investigadores Kennedy (1997). En un principio fueron concebidos para elaborar modelos de conductas sociales,​como el movimiento descrito por los organismos vivos en una bandada de aves o un banco de peces. Posteriormente el algoritmo se simplificó y se comprobó que era adecuado para problemas de optimización.\nFuncionamiento de PSOz\nEn el algoritmo PSO (Particle Swarm Optimization), cada partícula, que representa un individuo, posee una posición p⃗  ​ dentro del espacio de búsqueda y una velocidad v⃗ que determina su desplazamiento. Estas partículas, al igual que objetos en un entorno físico, cuentan con una inercia w, la cual conserva su movimiento en la dirección previamente seguida.\n\n\nCode\nself.positions = np.random.uniform(\n    self.bounds[:, 0],\n    self.bounds[:, 1],\n    size=(n_particles, dimensions)\n)\n\nself.velocities = np.zeros((n_particles, dimensions))\n\n# Evaluar posiciones iniciales\nself.scores = np.array([self.objective_function(p) for p in self.positions])\n\n\nAdemás, su aceleración, que representa un cambio en la velocidad, está influenciada por dos factores principales:\n\nAtracción hacia su mejor posición personal: Cada partícula tiende a moverse hacia la mejor ubicación que ha identificado en su trayectoria histórica (pbest).\nAtracción hacia la mejor posición global: Las partículas también se dirigen hacia la mejor ubicación encontrada por el grupo completo en el espacio de búsqueda (pgbest).\n\nIlustración del funcionamiento del algoritmo PSO. \nAdaptado de Sancho Caparrini (2024)\n\n\nCode\nfor iteration in range(self.max_iter):\n    # Actualizar velocidades\n    r1, r2 = np.random.rand(2)\n    self.velocities = (self.w * self.velocities +\n                     self.c1 * r1 * (self.p_best - self.positions) +\n                     self.c2 * r2 * (self.g_best - self.positions))\n    \n    # Actualizar posiciones\n    self.positions += self.velocities\n    \n    # Mantener partículas dentro de los límites\n    self.positions = np.clip(\n        self.positions,\n        self.bounds[:, 0],\n        self.bounds[:, 1]\n    )\n    \n    # Evaluar nuevas posiciones\n    self.scores = np.array([self.objective_function(p) for p in self.positions])\n    \n    # Actualizar mejores posiciones personales\n    improved_mask = self.scores &lt; self.p_best_scores\n    self.p_best[improved_mask] = self.positions[improved_mask]\n    self.p_best_scores[improved_mask] = self.scores[improved_mask]\n    \n    # Actualizar mejor posición global\n    min_score_idx = np.argmin(self.p_best_scores)\n    if self.p_best_scores[min_score_idx] &lt; self.g_best_score:\n        self.g_best = self.p_best[min_score_idx].copy()\n        self.g_best_score = self.p_best_scores[min_score_idx]\n\n\nEl algoritmo se detiene cuando se alcanza un número máximo de iteraciones, o cuando la mejora en la función objetivo es menor a un umbral predefinido.\nAl implementar el algoritmo, se presentó un comportamiento oscilatorio donde las partículas convergían inicialmente pero luego se dispersaban de manera repentina. El análisis reveló cuatro posibles causas: velocidades excesivas de las partículas, coeficientes de aprendizaje mal ajustados, peso de inercia estático y ausencia de un mecanismo de estabilización.\nLa solución implementada aborda estos problemas mediante cuatro modificaciones: Se  limitó la velocidad máxima al 10% del espacio de búsqueda para evitar saltos excesivos, se optimizaron los coeficientes cognitivo y social a un valor de 2.0 para balancear exploración y explotación, se implementó un peso de inercia dinámico que decrece linealmente de 0.9 a 0.4 durante la optimización y se añadió un factor de constricción calculado a partir de los coeficientes de aprendizaje para garantizar convergencia matemática.\n\n\nCode\n# Control de Velocidad Máxima\nv_max = 0.1 * (bounds[:, 1] - bounds[:, 0])\nvelocities = np.clip(velocities, -v_max, v_max)\n\n# Peso de Inercia Dinámico\nw = w_max - (w_max - w_min) * (iteracion / max_iter)\n\n# Factor de Constricción\nphi = c1 + c2\nchi = 2 / abs(2 - phi - np.sqrt(phi * phi - 4 * phi))\n\n# Parámetros Optimizados\nc1 = c2 = 2.0\nw_max = 0.9\nw_min = 0.4\n\n\nEstas modificaciones resultaron en una mejora significativa en la estabilidad del algoritmo, con una transición más suave entre las fases de exploración y explotación, y una convergencia más consistente hacia el óptimo global.\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n\\]\nFigura 19.\nAplicación de optimización de partículas sobre la función de Rosenbrock.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n\\]\nFigura 20.\nAplicación de optimización de partículas sobre la función de Rastrigin.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n\\]\nFigura 21.\nAplicación de optimización de partículas sobre la función de Schwefel.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n\\]\nFigura 22.\nAplicación de optimización de partículas sobre la función de Griewank.  Elaboración propia.\n\n\n\\[\n\\begin{align}\nf(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\\n         & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right]\n\\end{align} \\tag{6}\n\\]\nFigura 23.\nAplicación de optimización de partículas sobre la función de Goldstein-Price.  Elaboración propia.\n\n\n\\[\nf(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n\\]\nFigura 24.\nAplicación de optimización de partículas sobre la función de las seis jorobas del camello.  Elaboración propia."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#optimización-diferencial",
    "href": "posts/optimizacion_heuristica/index.html#optimización-diferencial",
    "title": "Optimización Heurística",
    "section": "2.4 Optimización diferencial",
    "text": "2.4 Optimización diferencial\nFuncionamiento Básico\nLa Evolución Diferencial (ED) es un algoritmo de optimización poblacional inspirado en los procesos evolutivos naturales. Al igual que otros algoritmos de esta categoría, la ED mantiene una población de soluciones candidatas, las cuales se recombinan y mutan para producir nuevos individuos los cuales serán elegidos de acuerdo al valor de su función de desempeño. Lo que caracteriza a la ED es el uso de vectores de prueba, los cuales compiten con los individuos de la población actual a fin de sobrevivir. (Price and Storn 1995)\nPasos clave:\n\nInicialización de la población:\n\nSe genera aleatoriamente una población inicial de individuos (soluciones potenciales).\nCada individuo es un vector que representa un punto en el espacio de búsqueda.\n\n\n\n\nCode\ndef initialize_population(self):\n    \"\"\"\n    Inicializa la población de manera aleatoria dentro de los límites especificados\n\n    Returns:\n    - Matriz numpy con población inicial\n    \"\"\"\n    # Crea una matriz de ceros con el tamaño de la población\n    population = np.zeros((self.population_size, self.dimension))\n\n    # Genera valores aleatorios para cada dimensión\n    for i in range(self.dimension):\n        population[:, i] = np.random.uniform(\n            self.bounds[i][0],  # Límite inferior\n            self.bounds[i][1],  # Límite superior\n            size=self.population_size  # Número de individuos\n        )\n    return population\n\n\n\nEvaluación de la población:\n\nSe evalúa el valor de la función objetivo para cada individuo de la población\n\nGeneración de nuevos individuos:\n\nMutación: Se crea un vector mutante sumando a un individuo objetivo una diferencia escalada entre otros dos individuos de la población.\n\n\n\n\nCode\ndef mutation(self, population):\n    \"\"\"\n    Aplica la estrategia de mutación DE/rand/1\n\n    Parameters:\n    - population: Población actual\n\n    Returns:\n    - Población mutada\n    \"\"\"\n    # Crea una matriz para almacenar la población mutada\n    mutation_pop = np.zeros_like(population)\n\n    for i in range(self.population_size):\n        # Selecciona tres individuos aleatorios diferentes\n        candidates = list(range(self.population_size))\n        candidates.remove(i)\n        r1, r2, r3 = np.random.choice(candidates, 3, replace=False)\n\n        # Genera un nuevo vector mediante mutación\n        mutation_pop[i] = population[r1] + self.F * (population[r2] - \n                                                               population[r3])\n\n        # Asegura que los valores estén dentro de los límites\n        for j in range(self.dimension):\n            mutation_pop[i, j] = np.clip(\n                mutation_pop[i, j],\n                self.bounds[j][0],\n                self.bounds[j][1]\n            )\n\n    return mutation_pop\n\n\n\nCruce: Se crea un vector de prueba combinando el vector mutante y el individuo objetivo mediante un operador de cruce.\n\n\n\nCode\ndef crossover(self, population, mutation_pop):\n    \"\"\"\n    Aplica el cruce binomial (crossover)\n\n    Parameters:\n    - population: Población actual\n    - mutation_pop: Población mutada\n\n    Returns:\n    - Población de prueba tras el cruce\n    \"\"\"\n    # Crea una matriz para almacenar la población de prueba\n    trial_pop = np.zeros_like(population)\n\n    for i in range(self.population_size):\n        # Genera puntos de cruce basados en CR\n        cross_points = np.random.rand(self.dimension) &lt;= self.CR\n        # Asegura al menos un punto de cruce\n        cross_points[np.random.randint(0, self.dimension)] = True\n\n        # Genera vector de prueba\n        trial_pop[i] = np.where(cross_points, mutation_pop[i], population[i])\n\n    return trial_pop\n\n\n\nSelección: Se compara el valor de la función objetivo del vector de prueba con el del individuo objetivo. El mejor de los dos se selecciona para la siguiente generación.\n\n\n\nCode\ndef selection(self, population, trial_pop):\n    \"\"\"\n    Selección de los mejores individuos\n\n    Parameters:\n    - population: Población actual\n    - trial_pop: Población de prueba\n\n    Returns:\n    - Nueva población y sus valores de aptitud\n    \"\"\"\n    # Calcula la aptitud de la población actual y de prueba\n    pop_fitness = np.array([self.func(ind) for ind in population])\n    trial_fitness = np.array([self.func(ind) for ind in trial_pop])\n\n    # Identifica qué individuos de prueba son mejores\n    better_indices = trial_fitness &lt; pop_fitness\n    population[better_indices] = trial_pop[better_indices]\n\n    return population, np.minimum(pop_fitness, trial_fitness)\n\n\n\nCriterio de parada:\n\nSe repiten los pasos 3 y 4 hasta que se cumpla un criterio de parada (número máximo de generaciones, mejora mínima en la función objetivo, etc.), de acuerdo con Martínez Zecua et al. (2019).\n\n\n\nFunción de RosenbrockFunción de RastriginFunción de SchwefelFunción de GriewankFunción Goldstein-PriceFunción de las seis jorobas de camello\n\n\n\\[\nf(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left[ 100(x_{i+1} - x_i^2)^2 + (x_i - 1)^2 \\right] \\tag{1}\n\\]\nFigura 25.\nAplicación de optimización diferencial sobre la función de Rosenbrock.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 10d + \\sum_{i=1}^{d} \\left[ x_i^2 - 10 \\cos(2\\pi x_i) \\right] \\tag{3}\n\\]\nFigura 26.\nAplicación de optimización diferencial sobre la función de Rastrigin.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 418.9829d - \\sum_{i=1}^{d} x_i \\sin(\\sqrt{|x_i|}) \\tag{4}\n\\]\nFigura 27.\nAplicación de optimización diferencial sobre la función de Schwefel.  Elaboración propia.\n\n\n\\[\nf(\\mathbf{x}) = 1 + \\frac{1}{4000} \\sum_{i=1}^{d} x_i^2 - \\prod_{i=1}^{d} \\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right) \\tag{5}\n\\]\nFigura 28.\nAplicación de optimización diferencial sobre la función de Griewank.  Elaboración propia.\n\n\n\\[\n\\begin{align} f(x_1, x_2) = & \\left[1 + (x_1 + x_2 + 1)^2 (19 - 14x_1 + 3x_1^2 - 14x_2 + 6x_1x_2 + 3x_2^2)\\right] \\\\          & \\left[30 + (2x_1 - 3x_2)^2 (18 - 32x_1 + 12x_1^2 + 48x_2 - 36x_1x_2 + 27x_2^2)\\right] \\end{align} \\tag{6}\n\\]\nFigura 29.\nAplicación de optimización diferencial sobre la función de Goldstein-Price.  Elaboración propia.\n\n\n\\[\nf(x_1, x_2) = \\left(4 - 2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2 \\tag{7}\n\\]\nFigura 30.\nAplicación de optimización diferencial sobre la función de las seis jorobas del camello.  Elaboración propia."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#análisis-de-mejor-fitness-para-los-diferentes-métodos",
    "href": "posts/optimizacion_heuristica/index.html#análisis-de-mejor-fitness-para-los-diferentes-métodos",
    "title": "Optimización Heurística",
    "section": "3.1 Análisis de mejor fitness para los diferentes métodos",
    "text": "3.1 Análisis de mejor fitness para los diferentes métodos\nPara cada función se realizó un gráfico de comparación de mejor fitness para cada corrida en cada uno de los métodos utilizados, originando el conjunto de resultados que se pueden observar en la Figura 31, como se muestra a continuación.\nFigura 31.\nRendimiento de las funciones, en función de las corridas y los métodos de optimización.  Nota. Es posible hacer una comparación tanto a nivel de corridas como al respecto de los métodos empleados anteriormente, con lo cual se llega a las conclusiones enunciadas más adelante. Elaboración propia.\nFinalmente, en la Figura 32 se pueden observar los resultados generales obtenidos en cuanto a los tiempos de ejecución de cada uno de los algoritmos utilizados.\nFigura 32.\nTiempo promedio de ejecución de cada método de optimización ejecutado.  Elaboración propia."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#eficiencia-computacional-tiempo-de-ejecución",
    "href": "posts/optimizacion_heuristica/index.html#eficiencia-computacional-tiempo-de-ejecución",
    "title": "Optimización Heurística",
    "section": "4.1 Eficiencia computacional (tiempo de ejecución)",
    "text": "4.1 Eficiencia computacional (tiempo de ejecución)\n\nGradiente Descendente: Es consistentemente el método más rápido, pues obtuvo tiempos de ejecución de entre 0.003 a 0.008 segundos, siendo extremadamente rápido en comparación con los demás pero potencialmente menos preciso.\nEnjambre de Partículas: Tiene tiempos de ejecución moderados, de 0.07 a 0.27 segundos, con una sobrecarga computacional ligeramente mayor que Gradiente Descendente y presenta buen equilibrio entre velocidad y exploración.\nEvolución Diferencial: Tiene un rendimiento más lento con tiempos de ejecución de entre 0.8 y 1.9 segundos y consume significativamente más tiempo, lo que sugiere la utilización de operaciones de mutación y cruce más complejas.\nAlgoritmo Genético: Posee un rendimiento similar a Enjambre de Partículas con tiempos de ejecución de entre 0.07 y 0.14 segundos, es más eficiente que Evolución Diferencial, lo que sugiere la necesidad de requisitos computacionales moderados."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#rendimiento-de-optimización",
    "href": "posts/optimizacion_heuristica/index.html#rendimiento-de-optimización",
    "title": "Optimización Heurística",
    "section": "4.2 Rendimiento de Optimización",
    "text": "4.2 Rendimiento de Optimización\nEn el análisis del rendimiento de optimización, se observaron variaciones significativas entre los diferentes algoritmos según la función de prueba. En funciones como Rosenbrock y Rastrigin, el Enjambre de Partículas y la Evolución Diferencial mostraron un rendimiento superior, logrando valores de error casi cero, mientras que el Algoritmo Genético tuvo resultados moderados y el Gradiente Descendente mostró mayor dificultad. En contraste, para funciones como Goldstein-Price y Camellos de Seis Jorobas, casi todos los métodos convergieron de manera similar cerca del óptimo conocido, sugiriendo que la efectividad de cada algoritmo depende crucialmente de la estructura y complejidad de la función objetivo."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#conclusión",
    "href": "posts/optimizacion_heuristica/index.html#conclusión",
    "title": "Optimización Heurística",
    "section": "4.3 Conclusión",
    "text": "4.3 Conclusión\nEl rendimiento de los algoritmos de optimización es altamente dependiente del contexto. Mientras que Enjambre de Partículas y Evolución Diferencial mostraron un rendimiento robusto en la mayoría de las funciones, la mejor elección depende de los desafíos específicos de optimización."
  },
  {
    "objectID": "posts/optimizacion_heuristica/index.html#footnotes",
    "href": "posts/optimizacion_heuristica/index.html#footnotes",
    "title": "Optimización Heurística",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl fitness representa la aptitud o adecuación de una solución a un problema específico. En nuestro caso, representa la evaluación del individuo en la funcion objetivo.↩︎"
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html#planteamiento-y-evaluación-de-modelos",
    "href": "posts/modelos-riesgo-credito/index.html#planteamiento-y-evaluación-de-modelos",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "",
    "text": "La regresión logística es un algoritmo que a pesar de tener la palabra regresión en su nombre, esta pensado para la clasificación binaria, es posible además extender para problemas multiclase a través de la regresión logística multinomial. La salida que se obtiene de este algoritmo es un número entre 0 y 1 que representa la probabilidad de pertenecer a una clase, la suma de la probabilidad de todas las clases debe dar 1, y la clase con la mayor probabilidad es aquella donde la observación será clasificada.\nLas probabilidades son calculadas de la siguiente manera:\n\\[\nP(y = c \\mid X) = \\frac{e^{\\beta_{c0} + \\beta_{c1}X_1 + \\dots + \\beta_{cn}X_n}}{\\sum_{k=1}^{C} e^{\\beta_{k0} + \\beta_{k1}X_1 + \\dots + \\beta_{kn}X_n}}  \\tag{1}\n\\]\nLa expresión anterior es además posible de simplificar para introducir la función softmax la cual también será usada en la sección de redes neuronales, para ello escribimos la combinación lineal de las variables \\(X\\) de la siguiente manera:\n\\[\nz_c = \\beta_{c0} + \\beta_{c1}X_1 + \\dots + \\beta_{cn}X_n  \\tag{2}\n\\]\nCon lo cual la ecuación 1 queda de la siguiente manera:\n\\[\nP(y = c \\mid X)=\\frac{e^{z_c}}{\\sum_{k=1}^{C} e^{z_k}} \\tag{3}\n\\]\nLa clase a la que pertenecerá la observación según el modelo de regresión logística multinomial esta dado por:\n\\[\n\\hat{y} = \\arg\\max_c \\, P(y = c \\mid X) \\tag{4}\n\\]\nA diferencia de otros algoritmos de aprendizaje automático, no cuenta con la misma cantidad de hiperparámetros que algoritmos como Random Forest o Support Vector Machines. La librería de Scikit-Learn permite ajustar el método y la fuerza de la regularización.\nTipos de regularización\n\nL1 (Lasso): Penaliza la suma de los valores absolutos de los coeficientes:\n\\[\n\\|\\beta\\|_1 = \\sum_{i=1}^n |\\beta_i| \\tag{5}\n\\]\nEsto lleva algunos coeficientes a cero, permitiendo la selección de características.\nL2 (Ridge): Penaliza la suma de los cuadrados de los coeficientes:\n\\[\n\\|\\beta\\|_2^2 = \\sum_{i=1}^n \\beta_i^2 \\tag{6}\n\\]\nEsto evita que los coeficientes crezcan demasiado grandes, ayudando a reducir el sobreajuste.\n\nFuerza de la regularización\nControla la fuerza de la regularización de forma inversamente proporcional\n\\[\nC = \\frac{1}{\\lambda} \\tag{7}\n\\]\n\nUn valor grande de \\(C\\) implica menos regularización (modelo más flexible).\nUn valor pequeño de \\(C\\) implica más regularización (modelo más restringido).\n\nVentajas\nEl modelo de regresión logístico presenta las siguientes ventajas:\n\nInterpretabilidad: Los coeficientes \\(\\beta\\) permiten una interpretación clara del impacto de cada variable sobre la probabilidad de pertenecer a una clase en específico.\nFácil implementación: No requiere ajustes avanzados para su implementación.\nGrados de certeza: Debido a que proporciona las probabilidades de pertenecer a cada clase, permite evaluar el grado de certeza sobre la pertenencia del dato a cada una de ellas.\n\nDesventajas\n\nRelaciones no lineales: La regresión logística esta pensada para relaciones lineales, por lo que si se buscan modelar relaciones no lineales requiere la introducción de términos polinómicos.\n Independencia de alternativas irrelevantes: El modelo asume que la relación entre dos clases no cambia si se introduce una nueva clase, lo que no siempre es realista.\n\n\n\n\nLas redes neuronales artificiales son modelos computacionales agrupados dentro del machine learning, con los cuales se busca simular el comportamiento del cerebro humano, de acuerdo con UNIR Revista (2021) y IBM (2025). Su funcionamiento imita el procedimiento con el que trabajan en conjunto las neuronas biológicas para aprender de la información que reciben desde el exterior o por parte de otras neuronas.\nGracias a su comportamiento, basado en la utilización de datos de entrenamiento para mejorar paulatinamente la precisión de sus resultados, las redes neuronales permiten la realización de tareas que no se podían automatizar en otro tipo de modelos, lo que ha llevado al desarrollo de avances significativos en el área de la inteligencia artificial e impactando de forma directa a las personas e industrias.\nConsiderando lo dicho anteriormente, es posible ver que las redes neuronales artificiales son una gran alternativa a la hora de enfrentar tareas relacionadas con el aprendizaje a partir de un conjunto de datos, encontrando patrones que puedan explicar el comportamiento de estos últimos respecto de alguna variable objetivo, con la finalidad de tomar una decisión después del entendimiento de dicho fenómeno. En este sentido, será utilizada una red neuronal para mejorar el resultado obtenido con el modelo de baja complejidad en el presente ejercicio.\n\n\nEste teorema establece que:\n“Cualquier función continua definida en un conjunto compacto puede ser aproximada arbitrariamente bien por una red neuronal feedforward con una sola capa oculta y un número suficiente de neuronas, utilizando funciones de activación no lineales”\nLo anterior significa que las funciones de activación no lineales son esenciales para que las redes neuronales puedan aproximar funciones complejas. Si bien el teorema garantiza que una sola capa oculta con suficientes neuronas puede aproximar cualquier función continua en un conjunto compacto, en la práctica, aumentar el número de capas suele ser más eficiente para modelar problemas complejos.\n\n\n\nIlustración de los resultados obtenidos mediantes funciones no lineales comparadas con las funciones lineales.\n\n\n\n\n\nLas redes neuronales están compuestas por un conjunto de nodos, que vendrían siendo las neuronas artificiales, repartidos en capas que pertenecen a alguna de las siguientes tres categorías, con información obtenida de Cloudflare (2025) y ParoleDevs (n.d.):\n\nCapa de entrada: esta capa tiene conexión con el “mundo exterior” a la red neuronal artificial, recibiendo los datos iniciales que serán procesados por ella.\nCapa de salida: esta capa proporciona el resultado del procesamiento realizado por la red neuronal, comúnmente como una predicción o una clasificación (lo cual se ve internamente en términos de probabilidad).\nCapas ocultas: una o más capas que se encuentran entre las dos mencionadas anteriormente, realizando el procesamiento y extracción de características de los datos. Este análisis se realiza de menor a mayor profundidad, pues cada capa extrae los patrones más significativos de los datos que recibió como entrada y los envía a una capa superior para que sean vistos con más detalle.\n\nAhora bien, es conveniente conocer los elementos que componen a cada uno de los nodos que interactúan en las capas anteriormente mencionadas, pues de esta manera será posible comprender la importancia del correcto diseño de la arquitectura de una red neuronal artificial. De acuerdo con Burgos (n.d.), estos elementos son:\nEntrada: los datos que recibe la neurona artificial del exterior o de otras neuronas, se representa como un vector \\(x = (x_1, x_2, ..., x_n)\\).\nPesos sinápticos: representan los factores de importancia \\(w_{ij}\\) que se le asignan a las entradas que cada neurona recibió de su anterior compañera. Son valores numéricos que se modifican durante el entrenamiento del modelo y poseen una vital importancia en el desempeño de este mismo frente al conjunto de datos del que está aprendiendo.\nRegla de propagación: una operación que se aplica de forma primordial a los datos de entrada y los pesos para calcular el posible valor de la salida de la neurona artificial; generalmente es una suma ponderada pero también pueden ser otras clases de operaciones.\nFunción de activación capa de entrada: el valor obtenido con la regla de propagación se procesa con a través de esta función, a fin de obtener el verdadero resultado de salida de la neurona. Existe una gran variedad de funciones que se eligen de acuerdo con el objetivo de entrenamiento de la red neuronal artificial, entre las cuales se encuentran las siguientes:\n\nIdentidad.\n\nLa función de identidad es una función lineal que devuelve el mismo valor de entrada como salida: \\[ f(x) = x \\]\n\nEscalón.\n\nLa función de escalón devuelve un valor binario dependiendo de si la entrada supera un umbral ( ): \\[ f(x) =\n\\begin{cases}\n1 & \\text{si } x \\geq \\theta \\\\\n0 & \\text{si } x &lt; \\theta\n\\end{cases} \\]\n\nLineal a tramos.\n\nLa función lineal a tramos aplica una transformación lineal dentro de un rango específico: \\[ f(x) =\n\\begin{cases}\n0 & \\text{si } x \\leq 0 \\\\\nx & \\text{si } 0 &lt; x \\leq 1 \\\\\n1 & \\text{si } x &gt; 1\n\\end{cases} \\]\n\nSigmoide. La función sigmoide suaviza la salida en un rango entre 0 y 1: \\[ f(x) = \\frac{1}{1 + e^{-x}} \\]\nGaussiana. La función gaussiana calcula una salida basada en la forma de una campana, con una media () y desviación estándar (): \\[ f(x) = e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} \\]\nSinusoidal. La función sinusoidal genera una salida oscilatoria basada en una onda sinusoidal: \\[ f(x) = \\sin(x) \\]\n\nSalida: resultado \\(y_i\\) del procedimiento aplicado sobre los datos de entrada.\nFunción de activación capa de salida:\n\nSoftmax: Permite convertir un conjunto de valores en probabilidades que suman 1, su principal uso se encuentra en problemas de clasificación multiclase.\n\n\\[\n\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n\\]\n\nCross-entropy: Mide la diferencia entre las predicciones \\(\\hat{y_i}\\) y la real \\(y\\), para el caso de clasificación lo hace de la siguiente manera:\n\n\\[\n\\text{Cross-Entropy Loss} = - \\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n\\]\n\nSparse Cross-Entropy Loss : Es una variante de Cross-Entropy que no requiere codificación one-hot, sino que trabaja directamente con índices de las clases verdaderas.\n\n\\[\n\\text{Sparse Cross-Entropy Loss} = - \\log(\\hat{y}_{c})\n\\]\n\nFocal loss: Es una extensión de Cross-Entropy que aplica un factor de penalización para enfocarse más en ejemplos mal clasificados. Es especialmente útil para casos de datasets desbalanceados.\n\n\\[\n\\text{Focal Loss} = - \\alpha_t (1 - p_t)^\\gamma \\log(p_t)\n\\]\nDonde: \\[\np_t = \\hat{y}_c\n\\]\n\n\n\nTeniendo en cuenta las particularidades de la arquitectura de las redes neuronales artificiales, a continuación se detallan algunos tipos diferentes de modelos, clasificados según su diseño, así como sus correspondientes aplicaciones en diferentes campos de la academia y la industria.\n\nRedes neuronales artificiales perceptrón: tienen la arquitectura más sencilla, compuesta por nodos con una única función de activación, suelen utilizarse para tareas de clasificación binaria.\nRedes neuronales artificiales multicapa: su arquitectura está conformada por capas de neuronas artificiales interconectadas y son utilizadas para tareas más complejas como toma de decisiones y clasificación multiclase.\nRedes neuronales artificiales convolucionales: estas redes están especialmente diseñadas para realizar tareas relacionadas con el reconocimiento de imágenes, pues utilizan filtros convolucionales para identificar patrones y características especiales en cada pixel.\nRedes neuronales artificiales recurrentes: suelen ser empleadas para tareas como reconocimiento de voz, traducción automática y generación de texto por su capacidad para procesar datos secuenciales, donde toda la información está relacionada entre sí y posee un contexto común para explicarse.\n\n\n\n\nAlgunas de las aplicaciones de las redes neuronales en la actualidad incluyen las siguientes:\n\nReconocimiento de imágenes: las redes neuronales pueden ser utilizadas para identificar personas y objetos en imágenes y videos.\nProcesamiento del lenguaje natural: las redes neuronales pueden utilizarse en tareas de comprensión del lenguaje como la traducción automática, la generación de texto y el reconocimiento de voz.\nToma de decisiones: las redes neuronales pueden ser herramientas de ayuda para la toma de decisiones en situaciones complejas tales como el análisis financiero, que es el caso del presente ejercicio y el diagnóstico médico, entre otras.\nSistemas de recomendación: las redes neuronales pueden ser empleadas para generar recomendaciones personalizadas con base en las preferencias del usuario en diferentes plataformas de streaming, comercio electrónico y redes sociales. Profe Digital (n.d.)"
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html#construcción-del-modelo-de-aprendizaje-automático",
    "href": "posts/modelos-riesgo-credito/index.html#construcción-del-modelo-de-aprendizaje-automático",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "",
    "text": "Después de haber jugado con el dataset en la sección anterior para los análisis descriptivos y exploratorios, pasamos a realizar el pre procesamiento de los datos necesario para que la arquitectura de la red neuronal sea capaz de recibirlos y además ayudar a mejorar su rendimiento. Iniciamos dividiendo el conjunto de datos en entrenamiento, validación y test para evitar cualquier tipo de data leakage durante el preprocesamiento.\n\n\nUtilizamos tres estrategias para la clasificación de las variables categóricas según su naturaleza\n\nOrdinal Encoder: Esta técnica se aplicó cuando las variables categóricas presentaban un orden natural. La codificación numérica asignada reflejaba este orden, asegurando que los valores fueran representativos de su jerarquía inherente.\nLabel Encoder: Se empleó en variables categóricas binarias. Este enfoque evitó imponer un orden ficticio entre los valores, lo que podría generar sesgos al interpretar una relación inexistente entre las categorías.\nOne Hot Encoding: Diseñada para variables categóricas sin un orden natural y con más de dos niveles. Cada categoría fue representada mediante un vector binario, donde un valor de 1 indica pertenencia a una categoría específica y e asigna 0 a las demás. Se prestó especial atención al número de niveles en cada variable. En casos con muchas categorías, esta técnica podría haber generado una matriz de alta dimensionalidad, aumentando los requerimientos computacionales y complicando el entrenamiento de la red neuronal. Para evitar estos problemas, se evaluó cuidadosamente la viabilidad de aplicar este método en cada caso.\n\n\n\n\nLa técnica de imputación de datos faltantes elegidas fue Iterative Imputer para las variables numéricas debido a que muestra mejores capacidades en manejar relaciones complejas que otros métodos de imputación como lo son la media o similares, gracias a que considera todo el dataset de manera conjunta en lugar de una sola columna. Para el caso de variables catgóricas se utilizo la imputación mediante mediana.\n\n\n\nUtilizamos StandardScaler debido a que normaliza las características centrando su media en 0 y escalando según la desviación estándar, lo cual es crucial en redes neuronales para garantizar estabilidad numérica y mejorar la eficiencia del entrenamiento.\nEsto previene problemas como:\n\nGradiente explosivo: Valores extremos en las entradas producen gradientes excesivamente grandes, causando desbordamientos numéricos y actualizaciones erráticas de pesos.\nGradiente desvaneciente: Gradientes extremadamente pequeños ralentizan la convergencia, dificultando el aprendizaje efectivo.\n\nLa fórmula utilizada por StandardScaler es:\n\\[\nX' = \\frac{X - \\mu}{\\sigma}\n\\]\ndonde:\n\n\\(X\\): Valor original.\n\\(u\\): Media de los datos.\n\\(sigma\\): Desviación estándar de los datos.\n\nEste método asegura que las características tengan una varianza de 1 y estén centradas en 0, permitiendo que funciones de activación como sigmoid y tanh operen eficientemente.\n\n\n\nEl análisis descriptivo mostró que la variable respuesta del dataset está altamente desbalanceada, lo cual representa un reto significativo al crear el modelo. Un modelo entrenado en estas condiciones puede tender a predecir únicamente la clase mayoritaria, generando métricas como el accuracy con valores engañosamente altos, pero sin reflejar una verdadera capacidad predictiva. Para abordar este problema, utilizaremos las siguientes técnicas:\n\nSobremuestreo y Submuestreo: Esta estrategia combina el aumento de las clases minoritarias mediante sobremuestreo y la reducción de las clases mayoritarias mediante submuestreo. El objetivo es equilibrar la cantidad de datos entre las clases, incentivando al modelo a aprender las características de todas las clases y mejorando sus métricas al minimizar la función de pérdida. Esto fue utilizado para el modelo con todas las clases.\n\n\n\n\nIlustración del funcionamiento de las técnicas de sobremuestreo y submuestreo. Tomado de (https://www.datasciencecentral.com/handling-imbalanced-data-sets-in-supervised-learning-using-family/)\n\n\n\nAgrupamiento de las clases: En esta estrategia agrupamos algunas de las clases con una menor cantidad de datos, esto debido a que como se verá más adelante son clases que tienen tan pocos datos que predecirlas es altamente complejo, y que pone en evidencia además las limitaciones de técnicas de sobremuestreo y submuestreo en la presencia de clases altamente desbalanceadas.\n\n\n\n\n\n\n\nDado el desbalance de la variable objetivo, utilizaremos métricas diseñadas para proporcionar una evaluación más equitativa del modelo:\n\nF1-Score Macro: A diferencia de métricas como el accuracy, que tienden a favorecer la clase mayoritaria en datasets desbalanceados, el F1-Score Macro asigna igual importancia a todas las clases, independientemente del número de muestras. Esto nos brinda una evaluación más realista del desempeño del modelo.\n\n\n\n\nPara abordar el desbalance de clases durante el entrenamiento, utilizaremos técnicas como:\n\nFocal Loss: Esta función de pérdida está diseñada específicamente para problemas de clasificación desbalanceados. Su objetivo es priorizar las clases minoritarias al reducir la importancia de las predicciones correctamente clasificadas para las clases mayoritarias. Esto ayuda al modelo a concentrarse más en aprender las características de las clases menos representadas.\nPesos de las Clases: En algunos casos, asignar pesos inversamente proporcionales al tamaño de cada clase en la función de pérdida puede ser una estrategia complementaria para equilibrar la importancia de las clases en el modelo.\n\n\n\n\n\nEarly Stopping: Permite reducir los tiempos de entrenamiento al monitorear una métrica, y dado un parámetro de paciencia que indica cuantas Epoch esperar, detiene el entrenamiento si la mejora después de cumplida la paciencia no es lo suficientemente significativa para justificar seguir entrenando.\nReduce Learning Rate on Plateu: Ayuda a mantener la capacidad de mejora durante el entrenamiento, los cálculos del gradiente, que dependen de la tasa de aprendizaje pueden no ser capaces de llegar al mínimo de la función de pérdida, por lo que este callback reduce la tasa de entrenamiento si para una cantidad de Epochs dada, no ha habida una mejoría en los resultados, esto permite tener un aprendizaje con capacidad de mejoría a través de las Epochs.\n\n\n\n\nLas capas definidas en el modelo fueron las siguiente:\n\n\n\nInput(shape=(X_train_bal.shape[1],)):\n\nDefine el tamaño de la entrada, igual al número de características en el dataset balanceado \\(X_{train\\_bal}\\).\n\nEs la capa inicial que recibe los datos de entrada para ser procesados por las siguientes capas.\n\n\n\n\n\n\n\nDense(128, activation=‘relu’, kernel_regularizer=l2(1e-4)):\n\nContiene 128 neuronas con activación ReLU, que introduce no linealidades y permite al modelo aprender patrones complejos.\n\nUtiliza un regularizador \\(L_2\\) con un valor de \\(1 \\times 10^{-4}\\) para prevenir el sobreajuste al penalizar pesos grandes.\n\n\nBatchNormalization():\n\nNormaliza la salida de la capa densa para estabilizar el entrenamiento y acelerar la convergencia.\n\n\nDropout(0.2):\n\nDesactiva aleatoriamente el 20% de las neuronas durante el entrenamiento para mejorar la generalización y reducir el riesgo de sobreajuste.\n\n\n\n\n\n\n\nDense(64, activation=‘relu’, kernel_regularizer=l2(1e-4)):\n\nReduce el número de neuronas a 64 para aprender características más específicas.\n\nConserva el mismo esquema de regularización \\(L_2\\) y activación ReLU.\n\n\nBatchNormalization():\n\nAsegura que las distribuciones de activaciones estén centradas durante el entrenamiento.\n\n\nDropout(0.2):\n\nMantiene el mismo porcentaje de desactivación que la capa anterior para seguir controlando el sobreajuste.\n\n\n\n\n\n\n\nDense(32, activation=‘relu’, kernel_regularizer=l2(1e-4)):\n\nReduce aún más el número de neuronas a 32, capturando características específicas de alto nivel.\n\nSigue utilizando activación ReLU y regularización \\(L_2\\).\n\n\nBatchNormalization():\n\nContinua normalizando las activaciones para estabilizar el aprendizaje.\n\n\nDropout(0.2):\n\nPermite que el modelo siga generalizando bien al reducir el riesgo de sobreajuste.\n\n\n\n\n\n\n\nDense(num_classes, activation=‘softmax’):\n\nContiene \\(num_{classes}\\) neuronas, donde cada neurona representa una clase de la variable objetivo.\n\nUsa la activación Softmax para calcular probabilidades de pertenencia para cada clase, asegurando que la suma de las probabilidades sea igual a 1.\n\n\n\n\n\n\n\n\nRegularización y Generalización:\n\nLa regularización \\(L_2\\) y Dropout en cada capa oculta ayudan a prevenir el sobreajuste, especialmente relevante dado el desbalance inicial del dataset.\n\nNormalización y Estabilidad:\n\nBatchNormalization estabiliza el aprendizaje al controlar las distribuciones de activaciones en cada capa, acelerando la convergencia.\n\nArquitectura Progresiva:\n\nLa reducción progresiva de neuronas en las capas ocultas (128 → 64 → 32) permite al modelo capturar primero características generales y luego refinarlas a características específicas.\n\nCapacidad para Multiclase:\n\nLa capa de salida con Softmax asegura que el modelo sea adecuado para problemas de clasificación multiclase, produciendo distribuciones de probabilidad por clase."
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html#conclusiones-y-aprendizajes-a-partir-del-modelo",
    "href": "posts/modelos-riesgo-credito/index.html#conclusiones-y-aprendizajes-a-partir-del-modelo",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "",
    "text": "Matriz de confusión"
  },
  {
    "objectID": "posts/modelos-riesgo-credito/index.html#puesta-en-producción-del-modelo",
    "href": "posts/modelos-riesgo-credito/index.html#puesta-en-producción-del-modelo",
    "title": "Modelos de riesgo de crédito con Redes Neuronales Artificiales",
    "section": "",
    "text": "Debido a la naturaleza del proyecto, tareas como lo son la monitoría del modelo se dejan como futuras mejorías, nos centraremos específicamente en dos.\n\n\nSe utilizó el framework de FastAPI (Ramírez 2018) para convertir el modelo una API que pudiera realizar predicciones pasandole la información de cada usuario. En el GitHub se encuentra el archivo con el código necesario para lograr este resultado."
  }
]